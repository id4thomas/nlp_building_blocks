# Tokenizer (NLTK)

## Word Tokenize
split() doesn't take into account punctuation


## Reference
[1] https://towardsdatascience.com/getting-started-with-text-analysis-in-python-ca13590eb4f7