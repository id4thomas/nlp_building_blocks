{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pltrdy/rouge\n",
    "from rouge import Rouge\n",
    "\n",
    "# https://github.com/li-plus/rouge-metric\n",
    "from rouge_metric import PyRouge\n",
    "\n",
    "# https://huggingface.co/metrics/rouge\n",
    "from datasets import load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input\n",
    "preds=[\"Model output 1\",\"Model output 2\",\"Model output 3\"]\n",
    "\n",
    "# Single Reference for each sample\n",
    "references=[\"Reference 1\",\"Reference 2\",\"Reference 3\"]\n",
    "\n",
    "# Multiple reference for each sample\n",
    "multiple_references=[\n",
    "\t[\"Sample 1 Reference 1\",\"Sample 1 Reference 2\",\"Sample 1 Reference 3\"],\n",
    "\t[\"Sample 2 Reference 1\",\"Sample 2 Reference 2\",\"Sample 2 Reference 3\"],\n",
    "\t[\"Sample 3 Reference 1\",\"Sample 3 Reference 2\",\"Sample 3 Reference 3\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.5, 'p': 0.3333333333333333, 'f': 0.3999999952000001}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.5, 'p': 0.3333333333333333, 'f': 0.3999999952000001}}\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores=rouge.get_scores(preds, references, avg=True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.10000000000000002, 'p': 0.030303030303030304, 'f': 0.04651162790697676}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-4': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.10000000000000002, 'p': 0.030303030303030304, 'f': 0.04651162790697676}, 'rouge-w-1.2': {'r': 0.14677992676220694, 'p': 0.045190953800397234, 'f': 0.06910553173165694}, 'rouge-s*': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-su*': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate document-wise ROUGE scores\n",
    "# skip_gap: The maximum gap between two words in skip-bigram\n",
    "# mode: 'average', 'individual'\n",
    "rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
    "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True#, skip_gap=4\n",
    "\t\t\t\t,mode='average')\n",
    "scores=scores = rouge.evaluate(preds, references)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rougeL': AggregateScore(low=Score(precision=0.3333333333333333, recall=0.5, fmeasure=0.4000000000000001), mid=Score(precision=0.3333333333333333, recall=0.5, fmeasure=0.4000000000000001), high=Score(precision=0.3333333333333333, recall=0.5, fmeasure=0.4000000000000001))}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")\n",
    "scores=metric.compute(predictions=preds, references=references, rouge_types=[\"rougeL\"])\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490463624bb20166a8667b7fa728dcad49f92cff15a6e94f417ad6118e23fbcd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('comet2020': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
