{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count-based Representation Methods\n",
    "* Bag-of-Words\n",
    "    * Binary\n",
    "    * Count\n",
    "* TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.0.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: None\n",
      "Author-email: None\n",
      "License: new BSD\n",
      "Location: /home/tslab/anaconda3/envs/comet2020/lib/python3.8/site-packages\n",
      "Requires: threadpoolctl, numpy, scipy, joblib\n",
      "Required-by: seqeval, sentence-transformers, flair, allennlp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Corpus from sklearn documentation\n",
    "train_corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "test_corpus = [\n",
    "    'This is the fourth document.',\n",
    "    'This document is the one.',\n",
    "    'This document is new.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vector_results(corpus,vector,vocab,is_float=False):\n",
    "    for doc,vec in zip(corpus,vector):\n",
    "        print(doc,vec)\n",
    "        for word,val in zip(vocab,vec):\n",
    "            if is_float:\n",
    "                print(\"{}:{:.3f}\".format(word,val),end=\"\\t\")\n",
    "            else:\n",
    "                print(\"{}:{}\".format(word,val),end=\"\\t\")\n",
    "        print(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words\n",
    "## Binary\n",
    "Each column (corresponds to a n-gram in vocab) is 1 if it exists in sentence and 0 otherwise.<br>\n",
    "Used CountVectorizer with parameter binary=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vectors\n",
      "This is the first document. [0 1 1 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:1\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is the second document. [0 1 0 1 0 1 1 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:0\tsecond:1\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "And this is the third one. [1 0 0 1 1 0 1 1 1]\n",
      "and:1\tdocument:0\tfirst:0\tis:1\tone:1\tsecond:0\tthe:1\tthird:1\tthis:1\t\n",
      "\n",
      "Is this the first document? [0 1 1 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:1\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "Test Vectors\n",
      "This is the fourth document. [0 1 0 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is the one. [0 1 0 1 1 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:1\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is new. [0 1 0 1 0 0 0 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:0\tsecond:0\tthe:0\tthird:0\tthis:1\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OneHot Using Count Vectorizer\n",
    "#binary=True reports non-zero as 1\n",
    "cv = CountVectorizer(binary=True)\n",
    "\n",
    "train_cv=cv.fit_transform(train_corpus).toarray()\n",
    "vocab=cv.get_feature_names_out()\n",
    "print(\"Train Vectors\")\n",
    "print_vector_results(train_corpus,train_cv,vocab)\n",
    "\n",
    "test_cv=cv.transform(test_corpus).toarray()\n",
    "print(\"Test Vectors\")\n",
    "print_vector_results(test_corpus,test_cv,vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count\n",
    "Columns of Term-Document Matrix used as Document Vectors<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "['This', 'is', 'the', 'first', 'document']\n",
      "Train Vectors\n",
      "This is the first document. [0 1 1 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:1\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is the second document. [0 2 0 1 0 1 1 0 1]\n",
      "and:0\tdocument:2\tfirst:0\tis:1\tone:0\tsecond:1\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "And this is the third one. [1 0 0 1 1 0 1 1 1]\n",
      "and:1\tdocument:0\tfirst:0\tis:1\tone:1\tsecond:0\tthe:1\tthird:1\tthis:1\t\n",
      "\n",
      "Is this the first document? [0 1 1 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:1\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "Test Vectors\n",
      "This is the fourth document. [0 1 0 1 0 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:0\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is the one. [0 1 0 1 1 0 1 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:1\tsecond:0\tthe:1\tthird:0\tthis:1\t\n",
      "\n",
      "This document is new. [0 1 0 1 0 0 0 0 1]\n",
      "and:0\tdocument:1\tfirst:0\tis:1\tone:0\tsecond:0\tthe:0\tthird:0\tthis:1\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "\n",
    "#Unigram\n",
    "print(\"Unigram\")\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#cv tokenizer\n",
    "cv_tokenizer=cv.build_tokenizer()\n",
    "print(cv_tokenizer(train_corpus[0]))\n",
    "\n",
    "train_cv=cv.fit_transform(train_corpus).toarray()\n",
    "vocab=cv.get_feature_names_out()\n",
    "print(\"Train Vectors\")\n",
    "print_vector_results(train_corpus,train_cv,vocab)\n",
    "\n",
    "test_cv=cv.transform(test_corpus).toarray()\n",
    "print(\"Test Vectors\")\n",
    "print_vector_results(test_corpus,test_cv,vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vectors\n",
      "This is the first document. [0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      "and this:0\tdocument is:0\tfirst document:1\tis the:1\tis this:0\tsecond document:0\tthe first:1\tthe second:0\tthe third:0\tthird one:0\tthis document:0\tthis is:1\tthis the:0\t\n",
      "\n",
      "This document is the second document. [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      "and this:0\tdocument is:1\tfirst document:0\tis the:1\tis this:0\tsecond document:1\tthe first:0\tthe second:1\tthe third:0\tthird one:0\tthis document:1\tthis is:0\tthis the:0\t\n",
      "\n",
      "And this is the third one. [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "and this:1\tdocument is:0\tfirst document:0\tis the:1\tis this:0\tsecond document:0\tthe first:0\tthe second:0\tthe third:1\tthird one:1\tthis document:0\tthis is:1\tthis the:0\t\n",
      "\n",
      "Is this the first document? [0 0 1 0 1 0 1 0 0 0 0 0 1]\n",
      "and this:0\tdocument is:0\tfirst document:1\tis the:0\tis this:1\tsecond document:0\tthe first:1\tthe second:0\tthe third:0\tthird one:0\tthis document:0\tthis is:0\tthis the:1\t\n",
      "\n",
      "Test Vectors\n",
      "This is the fourth document. [0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "and this:0\tdocument is:0\tfirst document:0\tis the:1\tis this:0\tsecond document:0\tthe first:0\tthe second:0\tthe third:0\tthird one:0\tthis document:0\tthis is:1\tthis the:0\t\n",
      "\n",
      "This document is the one. [0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
      "and this:0\tdocument is:1\tfirst document:0\tis the:1\tis this:0\tsecond document:0\tthe first:0\tthe second:0\tthe third:0\tthird one:0\tthis document:1\tthis is:0\tthis the:0\t\n",
      "\n",
      "This document is new. [0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "and this:0\tdocument is:1\tfirst document:0\tis the:0\tis this:0\tsecond document:0\tthe first:0\tthe second:0\tthe third:0\tthird one:0\tthis document:1\tthis is:0\tthis the:0\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "train_cv=cv.fit_transform(train_corpus).toarray()\n",
    "vocab=cv.get_feature_names_out()\n",
    "print(\"Train Vectors\")\n",
    "print_vector_results(train_corpus,train_cv,vocab)\n",
    "\n",
    "test_cv=cv.transform(test_corpus).toarray()\n",
    "print(\"Test Vectors\")\n",
    "print_vector_results(test_corpus,test_cv,vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer\n",
    "TfidfVectorizer is same as applying TfidfTransformer to CountVectorizer<br>\n",
    "IDF value of the train corpus is used for transforming test documents<br>\n",
    "\n",
    "### norm\n",
    "By default <i>norm</i> parameter is set to 'l2' -> Sum of squares of elements of vector equals to 1.<br>\n",
    "This means dot product of 'l2' normalized vector equals to their <b>cosine similarity</b><br>\n",
    "'l1' normalization makes sum of absolute element values to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF\n",
      "This is the first document. [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      " 0.38408524 0.         0.38408524]\n",
      "and:0.000\tdocument:0.470\tfirst:0.580\tis:0.384\tone:0.000\tsecond:0.000\tthe:0.384\tthird:0.000\tthis:0.384\t\n",
      "\n",
      "This document is the second document. [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      " 0.28108867 0.         0.28108867]\n",
      "and:0.000\tdocument:0.688\tfirst:0.000\tis:0.281\tone:0.000\tsecond:0.539\tthe:0.281\tthird:0.000\tthis:0.281\t\n",
      "\n",
      "And this is the third one. [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      " 0.26710379 0.51184851 0.26710379]\n",
      "and:0.512\tdocument:0.000\tfirst:0.000\tis:0.267\tone:0.512\tsecond:0.000\tthe:0.267\tthird:0.512\tthis:0.267\t\n",
      "\n",
      "Is this the first document? [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      " 0.38408524 0.         0.38408524]\n",
      "and:0.000\tdocument:0.470\tfirst:0.580\tis:0.384\tone:0.000\tsecond:0.000\tthe:0.384\tthird:0.000\tthis:0.384\t\n",
      "\n",
      "Test TFIDF\n",
      "This is the fourth document. [0.         0.57684669 0.         0.47160997 0.         0.\n",
      " 0.47160997 0.         0.47160997]\n",
      "and:0.000\tdocument:0.577\tfirst:0.000\tis:0.472\tone:0.000\tsecond:0.000\tthe:0.472\tthird:0.000\tthis:0.472\t\n",
      "\n",
      "This document is the one. [0.         0.42796959 0.         0.34989318 0.67049706 0.\n",
      " 0.34989318 0.         0.34989318]\n",
      "and:0.000\tdocument:0.428\tfirst:0.000\tis:0.350\tone:0.670\tsecond:0.000\tthe:0.350\tthird:0.000\tthis:0.350\t\n",
      "\n",
      "This document is new. [0.         0.65416415 0.         0.53482206 0.         0.\n",
      " 0.         0.         0.53482206]\n",
      "and:0.000\tdocument:0.654\tfirst:0.000\tis:0.535\tone:0.000\tsecond:0.000\tthe:0.000\tthird:0.000\tthis:0.535\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "train_tfidf=tfidf_vec.fit_transform(train_corpus).toarray()\n",
    "vocab=tfidf_vec.get_feature_names_out()\n",
    "print(\"Train TFIDF\")\n",
    "print_vector_results(train_corpus,train_tfidf,vocab,is_float=True)\n",
    "\n",
    "test_tfidf=tfidf_vec.transform(test_corpus).toarray()\n",
    "print(\"Test TFIDF\")\n",
    "print_vector_results(test_corpus,test_tfidf,vocab,is_float=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF\n",
      "This is the first document. [0.         0.         0.52303503 0.42344193 0.         0.\n",
      " 0.52303503 0.         0.         0.         0.         0.52303503\n",
      " 0.        ]\n",
      "and this:0.000\tdocument is:0.000\tfirst document:0.523\tis the:0.423\tis this:0.000\tsecond document:0.000\tthe first:0.523\tthe second:0.000\tthe third:0.000\tthird one:0.000\tthis document:0.000\tthis is:0.523\tthis the:0.000\t\n",
      "\n",
      "This document is the second document. [0.         0.47633035 0.         0.30403549 0.         0.47633035\n",
      " 0.         0.47633035 0.         0.         0.47633035 0.\n",
      " 0.        ]\n",
      "and this:0.000\tdocument is:0.476\tfirst document:0.000\tis the:0.304\tis this:0.000\tsecond document:0.476\tthe first:0.000\tthe second:0.476\tthe third:0.000\tthird one:0.000\tthis document:0.476\tthis is:0.000\tthis the:0.000\t\n",
      "\n",
      "And this is the third one. [0.49819711 0.         0.         0.31799276 0.         0.\n",
      " 0.         0.         0.49819711 0.49819711 0.         0.39278432\n",
      " 0.        ]\n",
      "and this:0.498\tdocument is:0.000\tfirst document:0.000\tis the:0.318\tis this:0.000\tsecond document:0.000\tthe first:0.000\tthe second:0.000\tthe third:0.498\tthird one:0.498\tthis document:0.000\tthis is:0.393\tthis the:0.000\t\n",
      "\n",
      "Is this the first document? [0.         0.         0.43779123 0.         0.55528266 0.\n",
      " 0.43779123 0.         0.         0.         0.         0.\n",
      " 0.55528266]\n",
      "and this:0.000\tdocument is:0.000\tfirst document:0.438\tis the:0.000\tis this:0.555\tsecond document:0.000\tthe first:0.438\tthe second:0.000\tthe third:0.000\tthird one:0.000\tthis document:0.000\tthis is:0.000\tthis the:0.555\t\n",
      "\n",
      "Test TFIDF\n",
      "This is the fourth document. [0.         0.         0.         0.62922751 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.77722116\n",
      " 0.        ]\n",
      "and this:0.000\tdocument is:0.000\tfirst document:0.000\tis the:0.629\tis this:0.000\tsecond document:0.000\tthe first:0.000\tthe second:0.000\tthe third:0.000\tthird one:0.000\tthis document:0.000\tthis is:0.777\tthis the:0.000\t\n",
      "\n",
      "This document is the one. [0.         0.64450299 0.         0.41137791 0.         0.\n",
      " 0.         0.         0.         0.         0.64450299 0.\n",
      " 0.        ]\n",
      "and this:0.000\tdocument is:0.645\tfirst document:0.000\tis the:0.411\tis this:0.000\tsecond document:0.000\tthe first:0.000\tthe second:0.000\tthe third:0.000\tthird one:0.000\tthis document:0.645\tthis is:0.000\tthis the:0.000\t\n",
      "\n",
      "This document is new. [0.         0.70710678 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.70710678 0.\n",
      " 0.        ]\n",
      "and this:0.000\tdocument is:0.707\tfirst document:0.000\tis the:0.000\tis this:0.000\tsecond document:0.000\tthe first:0.000\tthe second:0.000\tthe third:0.000\tthird one:0.000\tthis document:0.707\tthis is:0.000\tthis the:0.000\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "train_tfidf=tfidf_vec.fit_transform(train_corpus).toarray()\n",
    "vocab=tfidf_vec.get_feature_names_out()\n",
    "print(\"Train TFIDF\")\n",
    "print_vector_results(train_corpus,train_tfidf,vocab,is_float=True)\n",
    "\n",
    "test_tfidf=tfidf_vec.transform(test_corpus).toarray()\n",
    "print(\"Test TFIDF\")\n",
    "print_vector_results(test_corpus,test_tfidf,vocab,is_float=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF\n",
      "This is the first document. [0.         0.21331533 0.26348688 0.17439926 0.         0.\n",
      " 0.17439926 0.         0.17439926]\n",
      "and:0.000\tdocument:0.213\tfirst:0.263\tis:0.174\tone:0.000\tsecond:0.000\tthe:0.174\tthird:0.000\tthis:0.174\t\n",
      "\n",
      "This document is the second document. [0.         0.33225959 0.         0.13582199 0.         0.26027443\n",
      " 0.13582199 0.         0.13582199]\n",
      "and:0.000\tdocument:0.332\tfirst:0.000\tis:0.136\tone:0.000\tsecond:0.260\tthe:0.136\tthird:0.000\tthis:0.136\t\n",
      "\n",
      "And this is the third one. [0.21903289 0.         0.         0.11430045 0.21903289 0.\n",
      " 0.11430045 0.21903289 0.11430045]\n",
      "and:0.219\tdocument:0.000\tfirst:0.000\tis:0.114\tone:0.219\tsecond:0.000\tthe:0.114\tthird:0.219\tthis:0.114\t\n",
      "\n",
      "Is this the first document? [0.         0.21331533 0.26348688 0.17439926 0.         0.\n",
      " 0.17439926 0.         0.17439926]\n",
      "and:0.000\tdocument:0.213\tfirst:0.263\tis:0.174\tone:0.000\tsecond:0.000\tthe:0.174\tthird:0.000\tthis:0.174\t\n",
      "\n",
      "Test TFIDF\n",
      "This is the fourth document. [0.         0.28962869 0.         0.23679044 0.         0.\n",
      " 0.23679044 0.         0.23679044]\n",
      "and:0.000\tdocument:0.290\tfirst:0.000\tis:0.237\tone:0.000\tsecond:0.000\tthe:0.237\tthird:0.000\tthis:0.237\t\n",
      "\n",
      "This document is the one. [0.         0.1992274  0.         0.16288146 0.31212823 0.\n",
      " 0.16288146 0.         0.16288146]\n",
      "and:0.000\tdocument:0.199\tfirst:0.000\tis:0.163\tone:0.312\tsecond:0.000\tthe:0.163\tthird:0.000\tthis:0.163\t\n",
      "\n",
      "This document is new. [0.         0.37948777 0.         0.31025612 0.         0.\n",
      " 0.         0.         0.31025612]\n",
      "and:0.000\tdocument:0.379\tfirst:0.000\tis:0.310\tone:0.000\tsecond:0.000\tthe:0.000\tthird:0.000\tthis:0.310\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#L1 Norm of Tf-idf Vectorizer\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vec = TfidfVectorizer(norm='l1')\n",
    "\n",
    "train_tfidf=tfidf_vec.fit_transform(train_corpus).toarray()\n",
    "vocab=tfidf_vec.get_feature_names_out()\n",
    "print(\"Train TFIDF\")\n",
    "print_vector_results(train_corpus,train_tfidf,vocab,is_float=True)\n",
    "\n",
    "test_tfidf=tfidf_vec.transform(test_corpus).toarray()\n",
    "print(\"Test TFIDF\")\n",
    "print_vector_results(test_corpus,test_tfidf,vocab,is_float=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490463624bb20166a8667b7fa728dcad49f92cff15a6e94f417ad6118e23fbcd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('comet2020': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
