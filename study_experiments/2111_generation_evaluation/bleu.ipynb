{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If preds, refs given as sentences\n",
    "# Prepare for calculation - Tokenize\n",
    "#Receive sentences -> Tokenize\n",
    "preds_tokenized=[pred.split() for pred in preds]\n",
    "\n",
    "#Check if multi-reference\n",
    "if isinstance(refs[0], str):\n",
    "    #Single Reference\n",
    "    # print(\"Single-Ref\")\n",
    "    refs_tokenized=[[ref.split()] for ref in refs]\n",
    "else:\n",
    "    #Multi-reference\n",
    "    # print(\"Multi-Ref\")\n",
    "    refs_tokenized=[[ref_sent.split() for ref_sent in ref] for ref in refs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-reference Example from NLTK\n",
    "hyp1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which',\n",
    "        'ensures', 'that', 'the', 'military', 'always',\n",
    "        'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "\n",
    "ref1a = ['It', 'is', 'a', 'guide', 'to', 'action', 'that',\n",
    "        'ensures', 'that', 'the', 'military', 'will', 'forever',\n",
    "        'heed', 'Party', 'commands']\n",
    "\n",
    "ref1b = ['It', 'is', 'the', 'guiding', 'principle', 'which',\n",
    "        'guarantees', 'the', 'military', 'forces', 'always',\n",
    "        'being', 'under', 'the', 'command', 'of', 'the', 'Party']\n",
    "\n",
    "ref1c = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the',\n",
    "        'army', 'always', 'to', 'heed', 'the', 'directions',\n",
    "        'of', 'the', 'party']\n",
    "\n",
    "hyp2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was',\n",
    "        'interested', 'in', 'world', 'history']\n",
    "ref2a = ['he', 'was', 'interested', 'in', 'world', 'history',\n",
    "        'because', 'he', 'read', 'the', 'book']\n",
    "\n",
    "refs = [[ref1a, ref1b, ref1c], [ref2a]]\n",
    "preds = [hyp1, hyp2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Datasets - BLEU\n",
    "Implementation from https://github.com/tensorflow/nmt/blob/master/nmt/scripts/bleu.py\n",
    "\n",
    "Documentation Example\n",
    "```\n",
    "Computes BLEU score of translated segments against one or more references.\n",
    "Args:\n",
    "    predictions: list of translations to score.\n",
    "        Each translation should be tokenized into a list of tokens.\n",
    "    references: list of lists of references for each translation.\n",
    "        Each reference should be tokenized into a list of tokens.\n",
    "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "Returns:\n",
    "    'bleu': bleu score,\n",
    "    'precisions': geometric mean of n-gram precisions,\n",
    "    'brevity_penalty': brevity penalty,\n",
    "    'length_ratio': ratio of lengths,\n",
    "    'translation_length': translation_length,\n",
    "    'reference_length': reference_length\n",
    "Examples:\n",
    "    >>> predictions = [\n",
    "    ...     [\"hello\", \"there\", \"general\", \"kenobi\"],                             # tokenized prediction of the first sample\n",
    "    ...     [\"foo\", \"bar\", \"foobar\"]                                             # tokenized prediction of the second sample\n",
    "    ... ]\n",
    "    >>> references = [\n",
    "    ...     [[\"hello\", \"there\", \"general\", \"kenobi\"], [\"hello\", \"there\", \"!\"]],  # tokenized references for the first sample (2 references)\n",
    "    ...     [[\"foo\", \"bar\", \"foobar\"]]                                           # tokenized references for the second sample (1 reference)\n",
    "    ... ]\n",
    "    >>> bleu = datasets.load_metric(\"bleu\")\n",
    "    >>> results = bleu.compute(predictions=predictions, references=references)\n",
    "    >>> print(results[\"bleu\"])\n",
    "    1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface datasets implementation\n",
    "# Implementation from https://github.com/tensorflow/nmt/blob/master/nmt/scripts/bleu.py\n",
    "bleu = datasets.load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.5920778868801042, 'precisions': [0.9655172413793104, 0.7037037037037037, 0.52, 0.34782608695652173], 'brevity_penalty': 1.0, 'length_ratio': 1.0740740740740742, 'translation_length': 29, 'reference_length': 27}\n"
     ]
    }
   ],
   "source": [
    "max_order=4\n",
    "smooth=False\n",
    "scores=bleu.compute(predictions=preds, references=refs, max_order=max_order, smooth=smooth)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK BLEU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920778868801042\n"
     ]
    }
   ],
   "source": [
    "# NLTK Corpus BLEU\n",
    "order_weights=[\n",
    "    (1,0,0,0),\n",
    "    (0.5,0.5,0,0),\n",
    "    # (0.33,0.33,0.33,0),\n",
    "    (1./3,1./3,1./3,0),\n",
    "    (0.25,0.25,0.25,0.25)\n",
    "]\n",
    "\n",
    "max_order=4\n",
    "\n",
    "# corpus_bleu Params\n",
    "# smoothing_function=None,\n",
    "# auto_reweigh=False,\n",
    "scores=corpus_bleu(refs, preds, weights=order_weights[max_order-1])\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490463624bb20166a8667b7fa728dcad49f92cff15a6e94f417ad6118e23fbcd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('comet2020': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
