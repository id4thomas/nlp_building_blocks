{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultipleNegativesRankingLoss\n",
    "* sentence_transformers MultipleNegativesRankingLoss [[link]](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss)\n",
    "* 한 배치 내에서 postive 외 나머지 샘플을 negative로 간주하는 방법\n",
    "    * great loss function if you only have positive pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.3.1, however, your version is 3.3.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/Users/id4thomas/models/text_embedders/ModernBERT-korean-large-preview\"\n",
    "model = SentenceTransformer(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultipleNegativesRankingLoss(\n",
       "  (model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 8192, 'do_lower_case': False}) with Transformer model: ModernBertModel \n",
       "    (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  )\n",
       "  (cross_entropy_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict({\n",
    "    \"anchor\": [\"It's nice weather outside today.\", \"He drove to work.\"],\n",
    "    \"positive\": [\"It's so sunny.\", \"He took the car to the office.\"],\n",
    "})\n",
    "loss_fn = losses.MultipleNegativesRankingLoss(model)\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    loss=loss_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = trainer.get_eval_dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anchor_input_ids': tensor([[50281,  1147,   434,  5322,  8588,  3345,  3063,    15, 50282],\n",
      "        [50281,  1328, 12668,   281,   789,    15, 50282, 50283, 50283]],\n",
      "       device='mps:0'), 'anchor_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0]], device='mps:0'), 'positive_input_ids': tensor([[50281,  1147,   434,   594, 32650,    15, 50282, 50283, 50283, 50283],\n",
      "        [50281,  1328,  2335,   253,  1113,   281,   253,  3906,    15, 50282]],\n",
      "       device='mps:0'), 'positive_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}\n",
      "{'anchor_input_ids': tensor([[50281,  1147,   434,  5322,  8588,  3345,  3063,    15, 50282],\n",
      "        [50281,  1328, 12668,   281,   789,    15, 50282, 50283, 50283]],\n",
      "       device='mps:0'), 'anchor_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0]], device='mps:0'), 'positive_input_ids': tensor([[50281,  1147,   434,   594, 32650,    15, 50282, 50283, 50283, 50283],\n",
      "        [50281,  1328,  2335,   253,  1113,   281,   253,  3906,    15, 50282]],\n",
      "       device='mps:0'), 'positive_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}\n",
      "[{'input_ids': tensor([[50281,  1147,   434,  5322,  8588,  3345,  3063,    15, 50282],\n",
      "        [50281,  1328, 12668,   281,   789,    15, 50282, 50283, 50283]],\n",
      "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0]], device='mps:0')}, {'input_ids': tensor([[50281,  1147,   434,   594, 32650,    15, 50282, 50283, 50283, 50283],\n",
      "        [50281,  1328,  2335,   253,  1113,   281,   253,  3906,    15, 50282]],\n",
      "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}] None\n",
      "tensor(0.3206, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x in dataloader:\n",
    "    print(x)\n",
    "    inputs = trainer._prepare_inputs(x)\n",
    "    print(inputs)\n",
    "    features, labels = trainer.collect_features(inputs)\n",
    "    print(features, labels)\n",
    "    ## MultipleNegativesRankingLoss doesn't use 'labels'\n",
    "    loss = loss_fn(features, labels)\n",
    "    print(loss)\n",
    "    # loss, logits, labels = trainer.prediction_step(model, x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
