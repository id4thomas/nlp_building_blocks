# 2024.04.11
## ReFT: Representation Finetuning for Language Models
* https://arxiv.org/abs/2404.03592
* https://github.com/stanfordnlp/pyreft
* Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations
	* DAS 나온 논문
* [추가 정리 자료](details/240411_reft.md)
## LLM을 인코더로 활용: LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders
* https://arxiv.org/abs/2404.05961
* https://twitter.com/sivareddyg/status/1777865011630669845
	* https://github.com/McGill-NLP/llm2vec