# 2024.04.09
## huggingface tgi, tei apache 라이센스 다시 전환
* text-embeddings-inference:
	* https://github.com/huggingface/text-embeddings-inference
## stanford RAG 강의
	* https://youtu.be/mE7IDf2SmJg?si=461k1qYNEJ_TpiiU
	* 언급한 Dense retriever 연구들
		* naver - splade
			* https://github.com/naver/splade
			* https://huggingface.co/naver/efficient-splade-VI-BT-large-query
		* dragon - Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation
			* https://arxiv.org/abs/2402.07092
## gemma 1.1 릴리즈
* https://twitter.com/robdadashi/status/1777317210836312233
* 변경사항들
	* multi-turn 버그 수정
	* 'Sure' 줄임
	* RL 알고리즘 변경
	* itemize 된 결과 내는 특성이 있다
	* bf16 아래로 가면 품질 많이 떨어진다
	*  f“<start_of_turn>\n{prompt}<end_of_turn>\n<start_of_turn>model\n” 잘 지키는게 좋다
## qwen 1.5 32b모델
* https://twitter.com/huybery/status/1776255803282088056
	* https://huggingface.co/Qwen/Qwen1.5-32B
* qwen 1.5 모델 
	* 0.5B, 1.8B, 4B, 7B, 14B, 32B and 72B dense models
	* MoE model of 14B with 2.7B activated
	* 32K context length