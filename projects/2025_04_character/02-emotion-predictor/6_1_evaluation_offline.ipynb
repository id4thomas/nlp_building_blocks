{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b854817",
   "metadata": {},
   "source": [
    "# Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1572cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import json\n",
    "import os\n",
    "from typing import Optional, Dict, Any, List\n",
    "import yaml\n",
    "\n",
    "import outlines\n",
    "from outlines import models, generate\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bc1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationshipStatus(str, Enum):\n",
    "    na = \"na\"\n",
    "    low = \"low\"\n",
    "    medium = \"medium\"\n",
    "    high = \"high\"\n",
    "    \n",
    "class EmotionLabel(BaseModel):\n",
    "    joy: RelationshipStatus\n",
    "    trust: RelationshipStatus\n",
    "    fear: RelationshipStatus\n",
    "    surprise: RelationshipStatus\n",
    "    sadness: RelationshipStatus\n",
    "    disgust: RelationshipStatus\n",
    "    anger: RelationshipStatus\n",
    "    anticipation: RelationshipStatus\n",
    "    \n",
    "    # class Config:\n",
    "    #     extra = Extra.forbid\n",
    "    #     use_enum_values = True\n",
    "        \n",
    "class EntryResult(BaseModel):\n",
    "    emotion: EmotionLabel\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2298d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = \"try1\"\n",
    "with open(f\"prompts/{prompt_name}.yaml\", \"r\") as f:\n",
    "    prompt_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "SYSTEM_MESSAGE = prompt_dict['system']\n",
    "USER_TEMPLATE = prompt_dict['user']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828b497",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aff6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 16) Index(['uid', 'original_idx', 'original_src', 'original_relation',\n",
      "       'original_tgt', 'source', 'character', 'joy', 'trust', 'fear',\n",
      "       'surprise', 'sadness', 'disgust', 'anger', 'anticipation', 'reason'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "llm_model = \"gpt-4.1-mini-2025-04-14\"\n",
    "df = pd.read_csv(f\"data/comet/test_{llm_model}.tsv\", sep=\"\\t\")\n",
    "df = df.sample(10)\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_messages(row):\n",
    "    user_message = USER_TEMPLATE.format(\n",
    "        source=row['source'],\n",
    "        character=row['character']\n",
    "    )\n",
    "    assistant_message = json.dumps(\n",
    "        {\n",
    "            \"emotion\": {\n",
    "                \"joy\": row['joy'],\n",
    "                \"trust\": row['trust'],\n",
    "                \"fear\": row['fear'],\n",
    "                \"surprise\": row['surprise'],\n",
    "                \"sadness\": row['sadness'],\n",
    "                \"disgust\": row['disgust'],\n",
    "                \"anger\": row['anger'],\n",
    "                \"anticipation\": row['anticipation']\n",
    "            },\n",
    "            \"reason\": row['reason']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_message}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd67443",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = [\n",
    "    make_messages(df.iloc[i]) for i in range(df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedfbcf",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fecca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3de70e0e70043339d069edf2ad6bc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE MODEL LOADED\n"
     ]
    }
   ],
   "source": [
    "## Load Pretrained Model\n",
    "run_name = \"250421-01-qwen2_5-3b-mini-try1\"\n",
    "model_dir = f\"weights/{run_name}/best\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.padding_side = \"left\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir, torch_dtype=torch.bfloat16\n",
    ")\n",
    "model.eval()\n",
    "print(\"BASE MODEL LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ce91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines_model = models.Transformers(model, tokenizer,)\n",
    "generator = outlines.generate.json(outlines_model, EntryResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366205b2",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f796ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:04<00:00, 101.62s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "predictions = []\n",
    "for i in tqdm(range(0, len(all_messages), batch_size)):\n",
    "    batch = all_messages[i:i+batch_size]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        batch,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    prediction = generator(text)\n",
    "    predictions.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7725c454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.na: 'na'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.medium: 'medium'>, sadness=<RelationshipStatus.low: 'low'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.high: 'high'>, anticipation=<RelationshipStatus.na: 'na'>), reason='Rachel feels angry because confronting the boyfriend revealed the extent of his disrespect towards her friend.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.na: 'na'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason='Other children show no strong emotional reaction to seeing the animals because it is part of their routine day school activity.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.low: 'low'>, trust=<RelationshipStatus.medium: 'medium'>, fear=<RelationshipStatus.low: 'low'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.medium: 'medium'>), reason='Ethan feels relieved because the deferral means he still has a possibility while waiting reduces immediate rejection.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.na: 'na'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.low: 'low'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.high: 'high'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason='Michael feels regret and sadness as he realized his lateness caused issues and inconvenience to his colleague.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.medium: 'medium'>, trust=<RelationshipStatus.high: 'high'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason=\"Michael feels Borderline because Sophia’s support in getting his driver's license with his mom's help gave him a sense of accomplishment and reliability.\"),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.na: 'na'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.low: 'low'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.medium: 'medium'>), reason='Olivia feels curious because the scent of fresh bread sparked her interest and prompted her to explore further.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.high: 'high'>, trust=<RelationshipStatus.medium: 'medium'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason='Liam feels very happy because he appreciates the gifts and beauty the world has given him.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.na: 'na'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.low: 'low'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason=\"Hannah feels exhausted after the noisy party because she can't sustain her energy levels.\"),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.high: 'high'>, trust=<RelationshipStatus.na: 'na'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.low: 'low'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.na: 'na'>), reason='Emma is entirely satisfied and appreciative of the new art exhibit and sculptures she experienced.'),\n",
       " EntryResult(emotion=EmotionLabel(joy=<RelationshipStatus.medium: 'medium'>, trust=<RelationshipStatus.high: 'high'>, fear=<RelationshipStatus.na: 'na'>, surprise=<RelationshipStatus.na: 'na'>, sadness=<RelationshipStatus.na: 'na'>, disgust=<RelationshipStatus.na: 'na'>, anger=<RelationshipStatus.na: 'na'>, anticipation=<RelationshipStatus.medium: 'medium'>), reason=\"Tyler's friends feel happy and supportive because they encourage him and look forward to his performance.\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c12c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"na\", \"low\", \"medium\", \"high\"]\n",
    "emotion_cols = [\"joy\", \"trust\", \"fear\", \"surprise\", \"sadness\", \"disgust\", \"anger\", \"anticipation\"]\n",
    "\n",
    "reports = {}\n",
    "for col in emotion_cols:\n",
    "    y_true = df[col].tolist()\n",
    "    y_pred = [getattr(pred.emotion, col).value for pred in predictions]\n",
    "    reports[col] = classification_report(\n",
    "        y_true, \n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2377116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['na' 'low' 'medium' 'high']\n",
      "{'low', 'medium', 'na', 'high'}\n",
      "Classification report for joy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       0.80      1.00      0.89         4\n",
      "         low       1.00      0.50      0.67         2\n",
      "      medium       1.00      0.67      0.80         3\n",
      "        high       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.82      0.79      0.76        10\n",
      "weighted avg       0.87      0.80      0.80        10\n",
      "\n",
      "['na' 'medium' 'high']\n",
      "{'medium', 'na', 'high'}\n",
      "Classification report for trust:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00         6\n",
      "         low       0.00      0.00      0.00         0\n",
      "      medium       1.00      1.00      1.00         2\n",
      "        high       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.75      0.75      0.75        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "['low' 'na']\n",
      "{'low', 'na'}\n",
      "Classification report for fear:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       0.88      0.88      0.88         8\n",
      "         low       0.50      0.50      0.50         2\n",
      "      medium       0.00      0.00      0.00         0\n",
      "        high       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.34      0.34      0.34        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n",
      "['medium' 'na' 'low']\n",
      "{'low', 'medium', 'na'}\n",
      "Classification report for surprise:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00         7\n",
      "         low       1.00      1.00      1.00         2\n",
      "      medium       1.00      1.00      1.00         1\n",
      "        high       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.75      0.75      0.75        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "['low' 'na' 'medium']\n",
      "{'low', 'na', 'high'}\n",
      "Classification report for sadness:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00         7\n",
      "         low       1.00      1.00      1.00         2\n",
      "      medium       0.00      0.00      0.00         1\n",
      "        high       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.50      0.50      0.50        10\n",
      "weighted avg       0.90      0.90      0.90        10\n",
      "\n",
      "['na']\n",
      "{'na'}\n",
      "Classification report for disgust:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00        10\n",
      "         low       0.00      0.00      0.00         0\n",
      "      medium       0.00      0.00      0.00         0\n",
      "        high       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.25      0.25      0.25        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "['high' 'na']\n",
      "{'na', 'high'}\n",
      "Classification report for anger:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00         9\n",
      "         low       0.00      0.00      0.00         0\n",
      "      medium       0.00      0.00      0.00         0\n",
      "        high       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.50      0.50      0.50        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "['na' 'medium']\n",
      "{'medium', 'na'}\n",
      "Classification report for anticipation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          na       1.00      1.00      1.00         7\n",
      "         low       0.00      0.00      0.00         0\n",
      "      medium       1.00      1.00      1.00         3\n",
      "        high       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.50      0.50      0.50        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/users/yrsong/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# labels = [\"na\", \"low\", \"medium\", \"high\"]\n",
    "# for column in [\"joy\", \"trust\", \"fear\", \"surprise\", \"sadness\", \"disgust\", \"anger\", \"anticipation\"]:\n",
    "#     y_true = df[column].tolist()\n",
    "#     print(df[column].unique())\n",
    "#     y_pred = [getattr(pred.emotion, column).value for pred in predictions]\n",
    "#     print(f\"Classification report for {column}:\")\n",
    "#     print(classification_report(y_true, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74dbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
