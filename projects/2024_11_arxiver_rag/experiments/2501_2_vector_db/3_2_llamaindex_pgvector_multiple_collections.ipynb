{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class EnvSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"../.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    embedding_base_url: str\n",
    "    embedding_api_key: str\n",
    "    embedding_model: str\n",
    "    embedding_model_dir: str\n",
    "    \n",
    "    sample_data_dir: str\n",
    "    pipeline_src_dir: str\n",
    "settings = EnvSettings()\n",
    "\n",
    "import sys\n",
    "sys.path.append(settings.pipeline_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgvector_llamaindex\n"
     ]
    }
   ],
   "source": [
    "class DBSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"database/pgvector_llamaindex/.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    postgres_user: str\n",
    "    postgres_password: str\n",
    "    postgres_db: str\n",
    "    postgres_url: str\n",
    "    postgres_port: str\n",
    "\n",
    "db_settings = DBSettings()\n",
    "print(db_settings.postgres_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Embedder & VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.text_embeddings_inference import (\n",
    "    TextEmbeddingsInference,\n",
    ")\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "from sqlalchemy import make_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/embeddings/text_embedding_inference/\n",
    "embed_model = TextEmbeddingsInference(\n",
    "    model_name=settings.embedding_model,\n",
    "    base_url=settings.embedding_base_url,\n",
    "    timeout=60,\n",
    "    embed_batch_size=10,\n",
    ")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: pgvector_llamaindex\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# connection_string = \"postgresql://{}:{}@localhost:{}/{}\".format(\n",
    "connection_string = \"postgresql://{}:{}@localhost:{}/{}\".format(\n",
    "    db_settings.postgres_user,\n",
    "    db_settings.postgres_password,\n",
    "    db_settings.postgres_port,\n",
    "    db_settings.postgres_db\n",
    ")\n",
    "\n",
    "db_name = db_settings.postgres_db\n",
    "print(f\"DB: {db_name}\")\n",
    "conn = psycopg2.connect(connection_string)\n",
    "conn.autocommit=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize vector store instance\n",
    "url = make_url(connection_string)\n",
    "\n",
    "## hnsw indexing config\n",
    "hnsw_config = {\n",
    "    \"hnsw_m\": 16,\n",
    "    \"hnsw_ef_construction\": 64,\n",
    "    \"hnsw_ef_search\": 40,\n",
    "    \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Multiple vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store1 = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"test_documents\",\n",
    "    embed_dim=1024,  #bge-m3\n",
    "    hnsw_kwargs=hnsw_config,\n",
    ")\n",
    "\n",
    "## create storage context\n",
    "storage_context1 = StorageContext.from_defaults(vector_store=vector_store1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store2 = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"test_documents2\",\n",
    "    embed_dim=1024,  #bge-m3\n",
    "    hnsw_kwargs=hnsw_config,\n",
    ")\n",
    "\n",
    "## create storage context\n",
    "storage_context2 = StorageContext.from_defaults(vector_store=vector_store2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert Documents\n",
    "from llama_index.core import Document\n",
    "document1 = Document(\n",
    "    text = \"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata = {\"source\": \"tweet\"},\n",
    "    text_template='{content}'\n",
    ")\n",
    "\n",
    "document2 = Document(\n",
    "    text = \"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata = {\"source\": \"news\"},\n",
    "    text_template='{content}'\n",
    ")\n",
    "documents = [document1, document2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6c78a184db4d30939d04be19d2fef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a554e3ce494df8b73f8d9b21d4d703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Insert to storage1\n",
    "index1 = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context1, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x172376dd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d119f3668240eb92ce50a0dfb6d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5f4a6e92454b5db13d7fac65fb4897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x1738a5210>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Insert to storage2\n",
    "index2 = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context2, show_progress=True\n",
    ")\n",
    "index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='face84da-6e95-41a0-9500-49125f81ad62', embedding=None, metadata={'source': 'tweet'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='220fc440-7be5-4661-9fbb-1234856a0ee6', node_type='4', metadata={'source': 'tweet'}, hash='c211cf902096529c230ab1394516787d54390c9228e4f376fa12fa2c9699a6d9')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.', mimetype='text/plain', start_char_idx=0, end_char_idx=76, metadata_seperator='\\n', text_template='{content}'), score=0.37611465142790657),\n",
       " NodeWithScore(node=TextNode(id_='ff4293ac-9c8c-4fdd-9017-f55af542ff92', embedding=None, metadata={'source': 'news'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4b31a89b-e5bd-4d08-959c-1cdff8a6dd59', node_type='4', metadata={'source': 'news'}, hash='bc10f715e156bdaa19bc3ba95c1a166cbc6df58a67d90e04641c3dc4ed6eb91a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.', mimetype='text/plain', start_char_idx=0, end_char_idx=84, metadata_seperator='\\n', text_template='{content}'), score=0.3248268768294533)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check Retrieval\n",
    "retriever_args = {\"similarity_top_k\": 10}\n",
    "retriever = index1.as_retriever(**retriever_args)\n",
    "## Simple query\n",
    "query = \"LangChain provides abstractions to make working with LLMs easy\"\n",
    "nodes = retriever.retrieve(query)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='526e091b-a15b-4966-9c2e-dd5e29407bf8', embedding=None, metadata={'source': 'tweet'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='220fc440-7be5-4661-9fbb-1234856a0ee6', node_type='4', metadata={'source': 'tweet'}, hash='c211cf902096529c230ab1394516787d54390c9228e4f376fa12fa2c9699a6d9')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.', mimetype='text/plain', start_char_idx=0, end_char_idx=76, metadata_seperator='\\n', text_template='{content}'), score=0.37611465142790657),\n",
       " NodeWithScore(node=TextNode(id_='d785bc7e-44b0-495e-b4af-7c274e5c18db', embedding=None, metadata={'source': 'news'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4b31a89b-e5bd-4d08-959c-1cdff8a6dd59', node_type='4', metadata={'source': 'news'}, hash='bc10f715e156bdaa19bc3ba95c1a166cbc6df58a67d90e04641c3dc4ed6eb91a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.', mimetype='text/plain', start_char_idx=0, end_char_idx=84, metadata_seperator='\\n', text_template='{content}'), score=0.3248268768294533)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check Retrieval\n",
    "retriever_args = {\"similarity_top_k\": 10}\n",
    "retriever = index2.as_retriever(**retriever_args)\n",
    "## Simple query\n",
    "query = \"LangChain provides abstractions to make working with LLMs easy\"\n",
    "nodes = retriever.retrieve(query)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Schemas in the Database:\n",
      "  - public\n",
      "  - information_schema\n",
      "  - pg_catalog\n",
      "  - pg_toast\n",
      "\n",
      "Table: public.data_test_documents\n",
      "  - Column: id\n",
      "    Data Type: bigint\n",
      "    Nullable:  NO\n",
      "    Default:   nextval('data_test_documents_id_seq'::regclass)\n",
      "  - Column: text\n",
      "    Data Type: character varying\n",
      "    Nullable:  NO\n",
      "    Default:   None\n",
      "  - Column: metadata_\n",
      "    Data Type: json\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "  - Column: node_id\n",
      "    Data Type: character varying\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "  - Column: embedding\n",
      "    Data Type: USER-DEFINED\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "\n",
      "Table: public.data_test_documents2\n",
      "  - Column: id\n",
      "    Data Type: bigint\n",
      "    Nullable:  NO\n",
      "    Default:   nextval('data_test_documents2_id_seq'::regclass)\n",
      "  - Column: text\n",
      "    Data Type: character varying\n",
      "    Nullable:  NO\n",
      "    Default:   None\n",
      "  - Column: metadata_\n",
      "    Data Type: json\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "  - Column: node_id\n",
      "    Data Type: character varying\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "  - Column: embedding\n",
      "    Data Type: USER-DEFINED\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "\n",
      "Table: public.paper_information\n",
      "  - Column: id\n",
      "    Data Type: integer\n",
      "    Nullable:  NO\n",
      "    Default:   nextval('paper_information_id_seq'::regclass)\n",
      "  - Column: created_at\n",
      "    Data Type: timestamp without time zone\n",
      "    Nullable:  YES\n",
      "    Default:   now()\n",
      "  - Column: updated_at\n",
      "    Data Type: timestamp without time zone\n",
      "    Nullable:  YES\n",
      "    Default:   now()\n",
      "  - Column: paper_id\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   None\n",
      "  - Column: published_date\n",
      "    Data Type: timestamp without time zone\n",
      "    Nullable:  YES\n",
      "    Default:   now()\n",
      "  - Column: title\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   None\n",
      "  - Column: authors\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   ''::text\n",
      "  - Column: link\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   ''::text\n",
      "\n",
      "Table: public.paper_status\n",
      "  - Column: id\n",
      "    Data Type: integer\n",
      "    Nullable:  NO\n",
      "    Default:   nextval('paper_status_id_seq'::regclass)\n",
      "  - Column: created_at\n",
      "    Data Type: timestamp without time zone\n",
      "    Nullable:  YES\n",
      "    Default:   now()\n",
      "  - Column: updated_at\n",
      "    Data Type: timestamp without time zone\n",
      "    Nullable:  YES\n",
      "    Default:   now()\n",
      "  - Column: paper_information_id\n",
      "    Data Type: integer\n",
      "    Nullable:  YES\n",
      "    Default:   None\n",
      "  - Column: file_extension\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   'pdf'::text\n",
      "  - Column: parse_status\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   'PENDING'::text\n",
      "  - Column: extract_status\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   'PENDING'::text\n",
      "  - Column: split_status\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   'PENDING'::text\n",
      "  - Column: embed_status\n",
      "    Data Type: text\n",
      "    Nullable:  NO\n",
      "    Default:   'PENDING'::text\n"
     ]
    }
   ],
   "source": [
    "## Check DB Schema\n",
    "conn = psycopg2.connect(connection_string)\n",
    "with conn.cursor() as cur:\n",
    "    # --- Print out all schema names ---\n",
    "    print(\"All Schemas in the Database:\")\n",
    "    cur.execute(\"SELECT schema_name FROM information_schema.schemata;\")\n",
    "    schemas = cur.fetchall()\n",
    "    for schema in schemas:\n",
    "        print(f\"  - {schema[0]}\")\n",
    "        \n",
    "    ## Print table schemas\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_schema, table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema NOT IN ('information_schema', 'pg_catalog')\n",
    "        ORDER BY table_schema, table_name;\n",
    "    \"\"\")\n",
    "    tables = cur.fetchall()\n",
    "\n",
    "    # 3. Print the schema (columns) of each table\n",
    "    for schema_name, table_name in tables:\n",
    "        print(f\"\\nTable: {schema_name}.{table_name}\")\n",
    "        \n",
    "        # Fetch column details from information_schema.columns\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT column_name, data_type, is_nullable, column_default\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = %s\n",
    "            AND table_name   = %s\n",
    "            ORDER BY ordinal_position;\n",
    "        \"\"\", (schema_name, table_name))\n",
    "        \n",
    "        columns = cur.fetchall()\n",
    "        if not columns:\n",
    "            print(\"  (No columns found)\")\n",
    "        else:\n",
    "            for col_name, col_type, is_nullable, default_val in columns:\n",
    "                print(f\"  - Column: {col_name}\")\n",
    "                print(f\"    Data Type: {col_type}\")\n",
    "                print(f\"    Nullable:  {is_nullable}\")\n",
    "                print(f\"    Default:   {default_val}\")\n",
    "\n",
    "    cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
