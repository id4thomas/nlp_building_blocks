{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import Field\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baai/bge-m3\n"
     ]
    }
   ],
   "source": [
    "class Settings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"../.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    embedding_base_url: str\n",
    "    embedding_api_key: str\n",
    "    embedding_model: str\n",
    "\n",
    "settings = Settings()\n",
    "print(settings.embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgvector_langchain\n"
     ]
    }
   ],
   "source": [
    "class DBSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"database/pgvector_langchain/.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    postgres_user: str\n",
    "    postgres_password: str\n",
    "    postgres_db: str\n",
    "    postgres_url: str\n",
    "    postgres_port: str\n",
    "\n",
    "db_settings = DBSettings()\n",
    "print(db_settings.postgres_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Embedder & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Embedder\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"{}/v1/\".format(settings.embedding_base_url)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=settings.embedding_model,\n",
    "    api_key=settings.embedding_api_key\n",
    ")\n",
    "vectors = embeddings.embed_documents([\"hello\", \"goodbye\"])\n",
    "len(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare Connection\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# use psycopg3\n",
    "connection = \"postgresql+psycopg://{}:{}@localhost:{}/{}\".format(\n",
    "    db_settings.postgres_user,\n",
    "    db_settings.postgres_password,\n",
    "    db_settings.postgres_port,\n",
    "    db_settings.postgres_db\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 2 Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c332e63d-fc81-402c-bf62-99418a4d1345', '30a011d9-aabd-425b-a2f8-09fa3e203c1b']\n",
      "['ca53bd93-4704-4f5a-8578-8261ea064339', '084bd6d1-6289-46c2-80a3-897cfd03a1f6']\n"
     ]
    }
   ],
   "source": [
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "documents = [document_1, document_2]\n",
    "uuids_1 = [str(uuid4()) for _ in range(len(documents))]\n",
    "print(uuids_1)\n",
    "uuids_2 = [str(uuid4()) for _ in range(len(documents))]\n",
    "print(uuids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_postgres.vectorstores.PGVector object at 0x1247e83d0>\n",
      "<langchain_postgres.vectorstores.PGVector object at 0x1247e87f0>\n"
     ]
    }
   ],
   "source": [
    "from langchain_postgres.vectorstores import PGVector\n",
    "## collection 1\n",
    "collection1_name = \"demo_collection\"\n",
    "collection1_vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection1_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "print(collection1_vector_store)\n",
    "\n",
    "## collection2\n",
    "collection2_name = \"demo_collection2\"\n",
    "collection2_vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection2_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "print(collection2_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert to Collection1\n",
    "collection1_ids = collection1_vector_store.add_documents(documents=documents, ids=uuids_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert to Collection2\n",
    "collection2_ids = collection2_vector_store.add_documents(documents=documents, ids=uuids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c332e63d-fc81-402c-bf62-99418a4d1345', '30a011d9-aabd-425b-a2f8-09fa3e203c1b']\n",
      "['ca53bd93-4704-4f5a-8578-8261ea064339', '084bd6d1-6289-46c2-80a3-897cfd03a1f6']\n"
     ]
    }
   ],
   "source": [
    "print(collection1_ids)\n",
    "print(collection2_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Retrieval Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import (\n",
    "    Session,\n",
    "    declarative_base,\n",
    "    relationship,\n",
    "    scoped_session,\n",
    "    sessionmaker,\n",
    ")\n",
    "from sqlalchemy import create_engine, Column, String, JSON, ForeignKey, Index, select\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pgvector.sqlalchemy import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/0c7skj2154q4844jqxlw3yxr0000gn/T/ipykernel_99602/3914548120.py:2: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "# Define the Base and Engine\n",
    "Base = declarative_base()\n",
    "engine = create_engine(connection)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# Define the Model\n",
    "class LangChainEmbedding(Base):\n",
    "    __tablename__ = \"langchain_pg_embedding\"\n",
    "\n",
    "    id = Column(String, primary_key=True)\n",
    "    collection_id = Column(UUID, ForeignKey(\"langchain_pg_collection.uuid\"))\n",
    "    embedding = Column(Vector(1024))  # Replace 1536 with your embedding dimension\n",
    "    document = Column(String)\n",
    "    cmetadata = Column(JSON)\n",
    "\n",
    "    # Index for vector similarity\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_embedding_vector\", \"embedding\", postgresql_using=\"ivfflat\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Similarity Search\n",
    "def search_similar_embeddings(query_vector, collection_id, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform similarity search on the langchain_pg_embedding table.\n",
    "    Args:\n",
    "        query_vector (list): The query embedding vector.\n",
    "        collection_id (str): The UUID of the collection to search within.\n",
    "        top_k (int): Number of top results to return.\n",
    "    Returns:\n",
    "        list: List of matching rows with similarity scores.\n",
    "    \"\"\"\n",
    "    with Session() as session:\n",
    "        # SQLAlchemy query\n",
    "        stmt = (\n",
    "            select(\n",
    "                LangChainEmbedding.id,\n",
    "                LangChainEmbedding.document,\n",
    "                LangChainEmbedding.cmetadata,\n",
    "                LangChainEmbedding.embedding.cosine_distance(query_vector).label(\"similarity\") # 0~2\n",
    "            )\n",
    "            .where(LangChainEmbedding.collection_id == collection_id)\n",
    "            .order_by(\"similarity\")\n",
    "            .limit(top_k)\n",
    "        )\n",
    "\n",
    "        results = session.execute(stmt).fetchall()\n",
    "\n",
    "    # Parse results\n",
    "    return [\n",
    "        {\n",
    "            \"id\": row.id,\n",
    "            \"document\": row.document,\n",
    "            \"cmetadata\": row.cmetadata,\n",
    "            \"similarity\": row.similarity,\n",
    "        }\n",
    "        for row in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "ID: f5de7a22-5f19-4ce3-a667-aec3f62744ac, Similarity: 1.021492688781572, Document: The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\n",
      "ID: 30a011d9-aabd-425b-a2f8-09fa3e203c1b, Similarity: 1.021492688781572, Document: The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\n",
      "ID: 1f5ee93e-30b5-4b97-aeb5-b6800303a751, Similarity: 1.0296706098358088, Document: I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\n",
      "ID: c332e63d-fc81-402c-bf62-99418a4d1345, Similarity: 1.0296706098358088, Document: I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "query_vector = [0.1]*1024\n",
    "print(len(query_vector))\n",
    "collection_id = \"054bd89a-e570-4fb4-8466-e7ff6cd644ea\"  # Replace with your collection UUID\n",
    "results = search_similar_embeddings(query_vector, collection_id)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"ID: {result['id']}, Similarity: {result['similarity']}, Document: {result['document']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_postgres.vectorstores._get_embedding_collection_store.<locals>.EmbeddingStore"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/api_reference/_modules/langchain_postgres/vectorstores.html#PGVector\n",
    "session_maker = scoped_session(sessionmaker(bind=collection1_vector_store._engine))\n",
    "collection1_vector_store.EmbeddingStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_maker() as session:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<contextlib._GeneratorContextManager object at 0x12d76aaa0>\n"
     ]
    }
   ],
   "source": [
    "session = collection1_vector_store._make_sync_session()\n",
    "with session:\n",
    "    print(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
