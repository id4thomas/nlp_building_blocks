{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class EnvSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"../.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    embedding_base_url: str\n",
    "    embedding_api_key: str\n",
    "    embedding_model: str\n",
    "    embedding_model_dir: str\n",
    "    \n",
    "    sample_data_dir: str\n",
    "    pipeline_src_dir: str\n",
    "settings = EnvSettings()\n",
    "\n",
    "import sys\n",
    "sys.path.append(settings.pipeline_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgvector_llamaindex\n"
     ]
    }
   ],
   "source": [
    "class DBSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\"database/.env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "    postgres_user: str\n",
    "    postgres_password: str\n",
    "    postgres_db: str\n",
    "    postgres_url: str\n",
    "    postgres_port: str\n",
    "\n",
    "db_settings = DBSettings()\n",
    "print(db_settings.postgres_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Embedding & VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.text_embeddings_inference import (\n",
    "    TextEmbeddingsInference,\n",
    ")\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "from sqlalchemy import make_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/embeddings/text_embedding_inference/\n",
    "embed_model = TextEmbeddingsInference(\n",
    "    model_name=settings.embedding_model,\n",
    "    base_url=settings.embedding_base_url,\n",
    "    timeout=60,\n",
    "    embed_batch_size=10,\n",
    ")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: pgvector_llamaindex\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# connection_string = \"postgresql://{}:{}@localhost:{}/{}\".format(\n",
    "connection_string = \"postgresql://{}:{}@localhost:{}/{}\".format(\n",
    "    db_settings.postgres_user,\n",
    "    db_settings.postgres_password,\n",
    "    db_settings.postgres_port,\n",
    "    db_settings.postgres_db\n",
    ")\n",
    "\n",
    "db_name = db_settings.postgres_db\n",
    "print(f\"DB: {db_name}\")\n",
    "conn = psycopg2.connect(connection_string)\n",
    "conn.autocommit=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize vector store instance\n",
    "url = make_url(connection_string)\n",
    "\n",
    "## hnsw indexing config\n",
    "hnsw_config = {\n",
    "    \"hnsw_m\": 16,\n",
    "    \"hnsw_ef_construction\": 64,\n",
    "    \"hnsw_ef_search\": 40,\n",
    "    \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Abstract Vectorstore\n",
    "* for embedding title+abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"paper_abstract\",\n",
    "    embed_dim=1024,  #bge-m3\n",
    "    hnsw_kwargs=hnsw_config,\n",
    ")\n",
    "\n",
    "## create storage context\n",
    "abstact_storage_context = StorageContext.from_defaults(vector_store=abstract_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7) Index(['id', 'title', 'abstract', 'authors', 'published_date', 'link',\n",
      "       'markdown'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Load Sample\n",
    "df = pd.read_parquet(settings.sample_data_dir)\n",
    "df = df.sample(100)\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                       2306.16925\n",
       "title             MIS-FM: 3D Medical Image Segmentation using Fo...\n",
       "abstract          Pretraining with large-scale 3D volumes has a ...\n",
       "authors           Guotai Wang, Jianghao Wu, Xiangde Luo, Xinglon...\n",
       "published_date                                 2023-06-29T13:22:13Z\n",
       "link                              http://arxiv.org/abs/2306.16925v1\n",
       "markdown          # MIS-FM: 3D Medical Image Segmentation using ...\n",
       "Name: 18077, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(settings.embedding_model_dir)\n",
    "def count_tokens(tokenizer, text):\n",
    "    return len(tokenizer(text)['input_ids'])\n",
    "\n",
    "count_tokens(tokenizer, 'hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_TEMPLATE = '''Title: {title}\n",
    "Abstract:\n",
    "{abstract}'''\n",
    "\n",
    "def format_abstract(title = \"\", abstract = \"\"):\n",
    "    formatted_abstract = copy.deepcopy(ABSTRACT_TEMPLATE)\n",
    "    return formatted_abstract.format(title=title, abstract=abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_abstracts = []\n",
    "for i in range(df.shape[0]):\n",
    "    formatted_abstract = format_abstract(\n",
    "        title = df.iloc[i][\"title\"],\n",
    "        abstract = df.iloc[i][\"abstract\"],\n",
    "    )\n",
    "    formatted_abstracts.append(formatted_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_abstract_num_tokens = [count_tokens(tokenizer, x) for x in formatted_abstracts]\n",
    "plt.hist(formatted_abstract_num_tokens, bins = 30)\n",
    "plt.title(\"Formatted Title+Abstract num_tokens (bge-m3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make llama-index Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-29T13:22:13Z'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"published_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 6, 29, 13, 22, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.iloc[0][\"published_date\"])\n",
    "datetime.strptime(df.iloc[0][\"published_date\"], '%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_documents = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    published_date = datetime.strptime(df.iloc[i][\"published_date\"], '%Y-%m-%dT%H:%M:%SZ')\n",
    "    document = Document(\n",
    "        text = formatted_abstracts[i],\n",
    "        metadata = {\n",
    "            \"paper_information_id\": i, ## mock id, use df row id\n",
    "            \"published_date\": published_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        },\n",
    "        text_template='{content}'\n",
    "    )\n",
    "    abstract_documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insert Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa6d3dd7e8049d5b1070b6a7ef2c50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e35b24a3ba04f7ca11344b09a429e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Must add at least one document to make index like this\n",
    "# abstact_storage_index = VectorStoreIndex(storage_context=abstact_storage_context)\n",
    "\n",
    "# Initialize index from documents\n",
    "abstact_storage_index = VectorStoreIndex.from_documents(\n",
    "    abstract_documents,\n",
    "    storage_context=abstact_storage_context,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_args = {\"similarity_top_k\": 10}\n",
    "retriever = abstact_storage_index.as_retriever(**retriever_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='7eb94f34-af50-4f8f-967a-6b779229ef2d', embedding=None, metadata={'paper_information_id': 4, 'published_date': '2023-08-25 19:35:58'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7eb5f76f-a9a4-43ed-9b14-77f26e097a9e', node_type='4', metadata={'paper_information_id': 4, 'published_date': '2023-08-25 19:35:58'}, hash='302d9152de24a6f6fdac54b594c9f83f506776238daab61b8ab92d02a0bd1ec4')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: Emulating Radiative Transfer with Artificial Neural Networks\\nAbstract:\\nForward-modeling observables from galaxy simulations enables direct\\ncomparisons between theory and observations. To generate synthetic spectral\\nenergy distributions (SEDs) that include dust absorption, re-emission, and\\nscattering, Monte Carlo radiative transfer is often used in post-processing on\\na galaxy-by-galaxy basis. However, this is computationally expensive,\\nespecially if one wants to make predictions for suites of many cosmological\\nsimulations. To alleviate this computational burden, we have developed a\\nradiative transfer emulator using an artificial neural network (ANN),\\nANNgelina, that can reliably predict SEDs of simulated galaxies using a small\\nnumber of integrated properties of the simulated galaxies: star formation rate,\\nstellar and dust masses, and mass-weighted metallicities of all star particles\\nand of only star particles with age <10 Myr. Here, we present the methodology\\nand quantify the accuracy of the predictions. We train the ANN on SEDs computed\\nfor galaxies from the IllustrisTNG project's TNG50 cosmological\\nmagnetohydrodynamical simulation. ANNgelina is able to predict the SEDs of\\nTNG50 galaxies in the ultraviolet (UV) to millimetre regime with a typical\\nmedian absolute error of ~7 per cent. The prediction error is the greatest in\\nthe UV, possibly due to the viewing-angle dependence being greatest in this\\nwavelength regime. Our results demonstrate that our ANN-based emulator is a\\npromising computationally inexpensive alternative for forward-modeling galaxy\\nSEDs from cosmological simulations.\", mimetype='text/plain', start_char_idx=0, end_char_idx=1617, metadata_seperator='\\n', text_template='{content}'), score=0.5374557331257223),\n",
       " NodeWithScore(node=TextNode(id_='e6c7a6b1-4d05-4cb4-8b30-4994abdba8bd', embedding=None, metadata={'paper_information_id': 97, 'published_date': '2023-10-01 18:50:29'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8688dfa5-a460-4d35-a1bc-f772479a0059', node_type='4', metadata={'paper_information_id': 97, 'published_date': '2023-10-01 18:50:29'}, hash='8f4eb7018b11d633f9d7d4b27213989723622bcca6297ac6fa839c09f0f127e6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Counterfactual Image Generation for adversarially robust and\\n  interpretable Classifiers\\nAbstract:\\nNeural Image Classifiers are effective but inherently hard to interpret and\\nsusceptible to adversarial attacks. Solutions to both problems exist, among\\nothers, in the form of counterfactual examples generation to enhance\\nexplainability or adversarially augment training datasets for improved\\nrobustness. However, existing methods exclusively address only one of the\\nissues. We propose a unified framework leveraging image-to-image translation\\nGenerative Adversarial Networks (GANs) to produce counterfactual samples that\\nhighlight salient regions for interpretability and act as adversarial samples\\nto augment the dataset for more robustness. This is achieved by combining the\\nclassifier and discriminator into a single model that attributes real images to\\ntheir respective classes and flags generated images as \"fake\". We assess the\\nmethod\\'s effectiveness by evaluating (i) the produced explainability masks on a\\nsemantic segmentation task for concrete cracks and (ii) the model\\'s resilience\\nagainst the Projected Gradient Descent (PGD) attack on a fruit defects\\ndetection problem. Our produced saliency maps are highly descriptive, achieving\\ncompetitive IoU values compared to classical segmentation models despite being\\ntrained exclusively on classification labels. Furthermore, the model exhibits\\nimproved robustness to adversarial attacks, and we show how the discriminator\\'s\\n\"fakeness\" value serves as an uncertainty measure of the predictions.', mimetype='text/plain', start_char_idx=0, end_char_idx=1556, metadata_seperator='\\n', text_template='{content}'), score=0.5299918967480607),\n",
       " NodeWithScore(node=TextNode(id_='a083c017-d3e6-401b-8902-43eebe40ff63', embedding=None, metadata={'paper_information_id': 17, 'published_date': '2023-07-17 11:55:20'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d679e788-c88e-46e0-b8d9-611e1a0bf7d9', node_type='4', metadata={'paper_information_id': 17, 'published_date': '2023-07-17 11:55:20'}, hash='ff7a0f23deeaf8b91c6741e78511203f9b6792a813635ad63d303c8d1826b4fb')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Active Learning for Object Detection with Non-Redundant Informative\\n  Sampling\\nAbstract:\\nCurating an informative and representative dataset is essential for enhancing\\nthe performance of 2D object detectors. We present a novel active learning\\nsampling strategy that addresses both the informativeness and diversity of the\\nselections. Our strategy integrates uncertainty and diversity-based selection\\nprinciples into a joint selection objective by measuring the collective\\ninformation score of the selected samples. Specifically, our proposed NORIS\\nalgorithm quantifies the impact of training with a sample on the\\ninformativeness of other similar samples. By exclusively selecting samples that\\nare simultaneously informative and distant from other highly informative\\nsamples, we effectively avoid redundancy while maintaining a high level of\\ninformativeness. Moreover, instead of utilizing whole image features to\\ncalculate distances between samples, we leverage features extracted from\\ndetected object regions within images to define object features. This allows us\\nto construct a dataset encompassing diverse object types, shapes, and angles.\\nExtensive experiments on object detection and image classification tasks\\ndemonstrate the effectiveness of our strategy over the state-of-the-art\\nbaselines. Specifically, our selection strategy achieves a 20% and 30%\\nreduction in labeling costs compared to random selection for PASCAL-VOC and\\nKITTI, respectively.', mimetype='text/plain', start_char_idx=0, end_char_idx=1462, metadata_seperator='\\n', text_template='{content}'), score=0.5222774147987366),\n",
       " NodeWithScore(node=TextNode(id_='c1af34c3-7b02-4370-b4f3-45ae41767851', embedding=None, metadata={'paper_information_id': 1, 'published_date': '2023-08-22 21:03:58'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c1b63ced-5357-40cd-92c4-1ae8bdc4894f', node_type='4', metadata={'paper_information_id': 1, 'published_date': '2023-08-22 21:03:58'}, hash='4b3632450e2ce00867ebb5349206fedd1ddd0f7be86c498e79267cbfe457d166')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: An extensible point-based method for data chart value detection\\nAbstract:\\nWe present an extensible method for identifying semantic points to reverse\\nengineer (i.e. extract the values of) data charts, particularly those in\\nscientific articles. Our method uses a point proposal network (akin to region\\nproposal networks for object detection) to directly predict the position of\\npoints of interest in a chart, and it is readily extensible to multiple chart\\ntypes and chart elements. We focus on complex bar charts in the scientific\\nliterature, on which our model is able to detect salient points with an\\naccuracy of 0.8705 F1 (@1.5-cell max deviation); it achieves 0.9810 F1 on\\nsynthetically-generated charts similar to those used in prior works. We also\\nexplore training exclusively on synthetic data with novel augmentations,\\nreaching surprisingly competent performance in this way (0.6621 F1) on real\\ncharts with widely varying appearance, and we further demonstrate our unchanged\\nmethod applied directly to synthetic pie charts (0.8343 F1). Datasets, trained\\nmodels, and evaluation code are available at\\nhttps://github.com/BNLNLP/PPN_model.', mimetype='text/plain', start_char_idx=0, end_char_idx=1148, metadata_seperator='\\n', text_template='{content}'), score=0.5082253672086051),\n",
       " NodeWithScore(node=TextNode(id_='f6d03f51-fda1-436f-b00f-6c91810e84d4', embedding=None, metadata={'paper_information_id': 86, 'published_date': '2023-04-22 09:35:51'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='40480af8-e670-44bb-9ca4-9e81517311d9', node_type='4', metadata={'paper_information_id': 86, 'published_date': '2023-04-22 09:35:51'}, hash='23c749497506a840f159b0063ea9595e45d0926e92bd314f81895962b867d157')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Learning Symbolic Representations Through Joint GEnerative and\\n  DIscriminative Training\\nAbstract:\\nWe introduce GEDI, a Bayesian framework that combines existing\\nself-supervised learning objectives with likelihood-based generative models.\\nThis framework leverages the benefits of both GEnerative and DIscriminative\\napproaches, resulting in improved symbolic representations over standalone\\nsolutions. Additionally, GEDI can be easily integrated and trained jointly with\\nexisting neuro-symbolic frameworks without the need for additional supervision\\nor costly pre-training steps. We demonstrate through experiments on real-world\\ndata, including SVHN, CIFAR10, and CIFAR100, that GEDI outperforms existing\\nself-supervised learning strategies in terms of clustering performance by a\\nsignificant margin. The symbolic component further allows it to leverage\\nknowledge in the form of logical constraints to improve performance in the\\nsmall data regime.', mimetype='text/plain', start_char_idx=0, end_char_idx=953, metadata_seperator='\\n', text_template='{content}'), score=0.5052429732535506),\n",
       " NodeWithScore(node=TextNode(id_='fb4a47f8-0ced-4e26-884a-de489d72f62e', embedding=None, metadata={'paper_information_id': 13, 'published_date': '2023-06-27 02:46:08'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d264db76-ab75-4a3a-a64f-fe1a0cc8d8d3', node_type='4', metadata={'paper_information_id': 13, 'published_date': '2023-06-27 02:46:08'}, hash='74dd6f38c4509f52b9fbde9a775a6cb4495195be8e65282b8386d54762c9c240')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: DSRM: Boost Textual Adversarial Training with Distribution Shift Risk\\n  Minimization\\nAbstract:\\nAdversarial training is one of the best-performing methods in improving the\\nrobustness of deep language models. However, robust models come at the cost of\\nhigh time consumption, as they require multi-step gradient ascents or word\\nsubstitutions to obtain adversarial samples. In addition, these generated\\nsamples are deficient in grammatical quality and semantic consistency, which\\nimpairs the effectiveness of adversarial training. To address these problems,\\nwe introduce a novel, effective procedure for instead adversarial training with\\nonly clean data. Our procedure, distribution shift risk minimization (DSRM),\\nestimates the adversarial loss by perturbing the input data's probability\\ndistribution rather than their embeddings. This formulation results in a robust\\nmodel that minimizes the expected global loss under adversarial attacks. Our\\napproach requires zero adversarial samples for training and reduces time\\nconsumption by up to 70\\\\% compared to current best-performing adversarial\\ntraining methods. Experiments demonstrate that DSRM considerably improves\\nBERT's resistance to textual adversarial attacks and achieves state-of-the-art\\nrobust accuracy on various benchmarks.\", mimetype='text/plain', start_char_idx=0, end_char_idx=1287, metadata_seperator='\\n', text_template='{content}'), score=0.5021710395812988),\n",
       " NodeWithScore(node=TextNode(id_='e55f77d6-4eb4-428a-ae93-7c0351f176e5', embedding=None, metadata={'paper_information_id': 47, 'published_date': '2023-04-24 13:24:00'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b3d61df3-d05b-4ce9-96eb-be1b693a666b', node_type='4', metadata={'paper_information_id': 47, 'published_date': '2023-04-24 13:24:00'}, hash='0e7488ad3314419c00b7a417d30f25a43e1b470204106479e236c36c48166d4e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: Quality-Diversity Optimisation on a Physical Robot Through\\n  Dynamics-Aware and Reset-Free Learning\\nAbstract:\\nLearning algorithms, like Quality-Diversity (QD), can be used to acquire\\nrepertoires of diverse robotics skills. This learning is commonly done via\\ncomputer simulation due to the large number of evaluations required. However,\\ntraining in a virtual environment generates a gap between simulation and\\nreality. Here, we build upon the Reset-Free QD (RF-QD) algorithm to learn\\ncontrollers directly on a physical robot. This method uses a dynamics model,\\nlearned from interactions between the robot and the environment, to predict the\\nrobot's behaviour and improve sample efficiency. A behaviour selection policy\\nfilters out uninteresting or unsafe policies predicted by the model. RF-QD also\\nincludes a recovery policy that returns the robot to a safe zone when it has\\nwalked outside of it, allowing continuous learning. We demonstrate that our\\nmethod enables a physical quadruped robot to learn a repertoire of behaviours\\nin two hours without human supervision. We successfully test the solution\\nrepertoire using a maze navigation task. Finally, we compare our approach to\\nthe MAP-Elites algorithm. We show that dynamics awareness and a recovery policy\\nare required for training on a physical robot for optimal archive generation.\\nVideo available at https://youtu.be/BgGNvIsRh7Q\", mimetype='text/plain', start_char_idx=0, end_char_idx=1392, metadata_seperator='\\n', text_template='{content}'), score=0.501980721950531),\n",
       " NodeWithScore(node=TextNode(id_='dacb3972-b204-41a5-9379-94a6ef891f6f', embedding=None, metadata={'paper_information_id': 53, 'published_date': '2023-06-18 15:50:57'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='acb9733f-8483-4ac1-9ff7-687107e0ff3e', node_type='4', metadata={'paper_information_id': 53, 'published_date': '2023-06-18 15:50:57'}, hash='f38cdada5440720f18f6731dcf7ac5dbd9aecf49749fbb67bfddab3074f89c90')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Acceleration in Policy Optimization\\nAbstract:\\nWe work towards a unifying paradigm for accelerating policy optimization\\nmethods in reinforcement learning (RL) by integrating foresight in the policy\\nimprovement step via optimistic and adaptive updates. Leveraging the connection\\nbetween policy iteration and policy gradient methods, we view policy\\noptimization algorithms as iteratively solving a sequence of surrogate\\nobjectives, local lower bounds on the original objective. We define optimism as\\npredictive modelling of the future behavior of a policy, and adaptivity as\\ntaking immediate and anticipatory corrective actions to mitigate accumulating\\nerrors from overshooting predictions or delayed responses to change. We use\\nthis shared lens to jointly express other well-known algorithms, including\\nmodel-based policy improvement based on forward search, and optimistic\\nmeta-learning algorithms. We analyze properties of this formulation, and show\\nconnections to other accelerated optimization algorithms. Then, we design an\\noptimistic policy gradient algorithm, adaptive via meta-gradient learning, and\\nempirically highlight several design choices pertaining to acceleration, in an\\nillustrative task.', mimetype='text/plain', start_char_idx=0, end_char_idx=1210, metadata_seperator='\\n', text_template='{content}'), score=0.4949085718502352),\n",
       " NodeWithScore(node=TextNode(id_='72d27886-3bf5-4d30-a3a6-52f31e59c3ae', embedding=None, metadata={'paper_information_id': 14, 'published_date': '2023-09-20 14:59:06'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0ad9984a-ba0c-4154-a12f-e37b9b743750', node_type='4', metadata={'paper_information_id': 14, 'published_date': '2023-09-20 14:59:06'}, hash='29cb1b4acec8fd4ff2fa94822c1848e0eeb8bae6cccaa8dc50eb917d032fb240')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Incremental Blockwise Beam Search for Simultaneous Speech Translation\\n  with Controllable Quality-Latency Tradeoff\\nAbstract:\\nBlockwise self-attentional encoder models have recently emerged as one\\npromising end-to-end approach to simultaneous speech translation. These models\\nemploy a blockwise beam search with hypothesis reliability scoring to determine\\nwhen to wait for more input speech before translating further. However, this\\nmethod maintains multiple hypotheses until the entire speech input is consumed\\n-- this scheme cannot directly show a single \\\\textit{incremental} translation\\nto users. Further, this method lacks mechanisms for \\\\textit{controlling} the\\nquality vs. latency tradeoff. We propose a modified incremental blockwise beam\\nsearch incorporating local agreement or hold-$n$ policies for quality-latency\\ncontrol. We apply our framework to models trained for online or offline\\ntranslation and demonstrate that both types can be effectively used in online\\nmode.\\n  Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing\\nlatency or 0.8-1.4 s latency improvement without changing quality.', mimetype='text/plain', start_char_idx=0, end_char_idx=1132, metadata_seperator='\\n', text_template='{content}'), score=0.4947289824485779),\n",
       " NodeWithScore(node=TextNode(id_='7b463ee3-bbc5-48ce-9a38-6603166c564c', embedding=None, metadata={'paper_information_id': 24, 'published_date': '2023-02-20 21:05:17'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0a7a25d9-8d9c-4d5d-aa08-ba715c2d3671', node_type='4', metadata={'paper_information_id': 24, 'published_date': '2023-02-20 21:05:17'}, hash='0583ae52c3435040c895d81d1024f2c629751495d379673bcab4f9940fda1d75')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: Hadamard Layer to Improve Semantic Segmentation\\nAbstract:\\nThe Hadamard Layer, a simple and computationally efficient way to improve\\nresults in semantic segmentation tasks, is presented. This layer has no free\\nparameters that require to be trained. Therefore it does not increase the\\nnumber of model parameters, and the extra computational cost is marginal.\\nExperimental results show that the new Hadamard layer substantially improves\\nthe performance of the investigated models (variants of the Pix2Pix model). The\\nperformance's improvement can be explained by the Hadamard layer forcing the\\nnetwork to produce an internal encoding of the classes so that all bins are\\nactive. Therefore, the network computation is more distributed. In a sort that\\nthe Hadamard layer requires that to change the predicted class, it is necessary\\nto modify $2^{k-1}$ bins, assuming $k$ bins in the encoding. A specific loss\\nfunction allows a stable and fast training convergence.\", mimetype='text/plain', start_char_idx=0, end_char_idx=965, metadata_seperator='\\n', text_template='{content}'), score=0.48583659614106534)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simple query\n",
    "query = \"Retrieval Augmented Generation\"\n",
    "nodes = retriever.retrieve(query)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0 - 0.537\n",
      "4 Emulating Radiative Transfer with Artificial Neural Networks\n",
      "Forward-modeling observables from galaxy simulations enables direct\n",
      "comparisons between theory and o\n",
      "------------------------------\n",
      "Result 1 - 0.530\n",
      "97 Counterfactual Image Generation for adversarially robust and\n",
      "  interpretable Classifiers\n",
      "Neural Image Classifiers are effective but inherently hard to interpret and\n",
      "susceptible to adversari\n",
      "------------------------------\n",
      "Result 2 - 0.522\n",
      "17 Active Learning for Object Detection with Non-Redundant Informative\n",
      "  Sampling\n",
      "Curating an informative and representative dataset is essential for enhancing\n",
      "the performance of 2D \n",
      "------------------------------\n",
      "Result 3 - 0.508\n",
      "1 An extensible point-based method for data chart value detection\n",
      "We present an extensible method for identifying semantic points to reverse\n",
      "engineer (i.e. extract th\n",
      "------------------------------\n",
      "Result 4 - 0.505\n",
      "86 Learning Symbolic Representations Through Joint GEnerative and\n",
      "  DIscriminative Training\n",
      "We introduce GEDI, a Bayesian framework that combines existing\n",
      "self-supervised learning objectives w\n",
      "------------------------------\n",
      "Result 5 - 0.502\n",
      "13 DSRM: Boost Textual Adversarial Training with Distribution Shift Risk\n",
      "  Minimization\n",
      "Adversarial training is one of the best-performing methods in improving the\n",
      "robustness of deep langu\n",
      "------------------------------\n",
      "Result 6 - 0.502\n",
      "47 Quality-Diversity Optimisation on a Physical Robot Through\n",
      "  Dynamics-Aware and Reset-Free Learning\n",
      "Learning algorithms, like Quality-Diversity (QD), can be used to acquire\n",
      "repertoires of diverse robo\n",
      "------------------------------\n",
      "Result 7 - 0.495\n",
      "53 Acceleration in Policy Optimization\n",
      "We work towards a unifying paradigm for accelerating policy optimization\n",
      "methods in reinforcement le\n",
      "------------------------------\n",
      "Result 8 - 0.495\n",
      "14 Incremental Blockwise Beam Search for Simultaneous Speech Translation\n",
      "  with Controllable Quality-Latency Tradeoff\n",
      "Blockwise self-attentional encoder models have recently emerged as one\n",
      "promising end-to-end approach\n",
      "------------------------------\n",
      "Result 9 - 0.486\n",
      "24 Hadamard Layer to Improve Semantic Segmentation\n",
      "The Hadamard Layer, a simple and computationally efficient way to improve\n",
      "results in semantic segmen\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes):\n",
    "    ## Score\n",
    "    score = node.score\n",
    "    ## Source\n",
    "    paper_info_id = node.metadata['paper_information_id']\n",
    "    title = df.iloc[paper_info_id][\"title\"]\n",
    "    abstract = df.iloc[paper_info_id][\"abstract\"]\n",
    "    print(\"Result {} - {:.3f}\".format(i, score))\n",
    "    print(paper_info_id, title)\n",
    "    print(abstract[:100])\n",
    "    print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
