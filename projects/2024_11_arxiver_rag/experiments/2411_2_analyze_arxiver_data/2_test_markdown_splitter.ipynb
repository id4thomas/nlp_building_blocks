{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(os.path.join(settings.data_dir, \"arxiver/data/train.parquet\"))\n",
    "# ## Sample 10k\n",
    "# df = df.sample(10000)\n",
    "# print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7) Index(['id', 'title', 'abstract', 'authors', 'published_date', 'link',\n",
      "       'markdown'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# df.to_parquet(\"sample.parquet\", index = None)\n",
    "df = pd.read_parquet(\"sample.parquet\")\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Splitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1. custom implementation\n",
    "* stack-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "This paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\(H_{2}\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.\n",
      "\n",
      "## I Introduction\n",
      "\n",
      "For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\(Q\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.\n",
      "\n",
      "Hence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.\n",
      "\n",
      "This paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.\n",
      "\n",
      "It is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\n",
      "the neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.\n",
      "\n",
      "Hence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\(H_{2}\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.\n",
      "\n",
      "## II Preliminaries\n",
      "\n",
      "We consider a nonlinear autonomous system:\n",
      "\n",
      "\\[\\dot{x}(t)=f(x(t)),\\quad y(t)=h(x(t)) \\tag{1}\\]\n",
      "\n",
      "where \\(x(t)\\in\\mathcal{X}\\subseteq\\mathbb{R}^{n}\\) is the vector of states and \\(y(t)\\in\\mathbb{R}^{m}\\) represents the outputs. For simplicity, we will consider \\(m=1\\). It is assumed that \\(f\\) and \\(h\\) are smooth on \\(\\mathcal{X}\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.\n",
      "\n",
      "### _KKL Observer_\n",
      "\n",
      "For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\n",
      "\n",
      "\\[\\dot{z}(t)=Az(t)+By(t),\\quad\\hat{x}(t)=T^{\\dagger}(z(t)). \\tag{2}\\]\n",
      "\n",
      "Here the observer states \\(z\\in\\mathbb{R}^{n_{z}}\\) has an LTI dynamics. The matrices \\(A\\) and \\(B\\) are chosen under the requirements of (i) controllability of \\((A,B)\\) should be controllable, (ii) Hurwitz property of \\(A\\), and (iii) sufficiently high dimension of \\(z\\) (\\(n_{z}\\)), which should be at least \\(n+1\\) if \\((A,B)\\) is complex [17] and at least \\(2n+1\\) if \\((A,B)\\) is real [29]. The mapping from the observer states \\(z\\) to the state estimates \\(\\hat{x}\\) is a static one, \\(T^{\\dagger}\\), which is the left-pseudoinverse of a nonlinear immersion \\(T\\) (i.e., a differentiable injection satisfying \\(T^{\\dagger}\\circ T=\\mathsf{id}\\)). This immersion \\(T\\) should satisfy the following PDE:\n",
      "\n",
      "\\[\\frac{\\partial T}{\\partial x}(x)f(x)=AT(x)+Bh(x),\\quad\\forall x\\in\\mathcal{X}, \\tag{3}\\]\n",
      "\n",
      "where \\(\\partial T/\\partial x\\) denotes the Jacobian matrix of \\(T\\). It can be easily verified that under the above PDE, \\(dT(x)/dt=AT(x)+By\\), and thus \\(z-T(x)\\) has an exponentially decaying dynamics, as \\(A\\) is Hurwitz.\n",
      "\n",
      "The conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\(\\dot{x}=f(x)\\) at time \\(t\\) with initial condition \\(x(0)=\\xi\\) as \\(\\Phi_{t}(\\xi)\\). For any open set \\(\\mathcal{O}\\) in \\(\\mathcal{X}\\), denote the backward time instant after which the solution does not escape this region by \\(\\varsigma_{\\mathcal{O}}(\\xi)=\\inf\\{t|\\Phi_{t}(\\xi)\\in\\mathcal{O}\\}\\). Also denote \\(\\mathcal{O}+\\epsilon:=\\{\\xi+\\eta|\\xi\\in\\mathcal{O},\\|\\eta\\|<\\epsilon\\}\\).\n",
      "\n",
      "**Definition 1** (Backward distinguishability).: _The system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable if for any distinct \\(\\xi,\\xi^{\\prime}\\in\\mathcal{X}\\) there exists a negative \\(t>\\varsigma_{\\mathcal{O}+\\epsilon}(\\xi)\\wedge\\varsigma_{\\mathcal{O}+\\epsilon} (\\xi^{\\prime})\\) such that \\(h(\\Phi_{t}(\\xi))\\neq h(\\Phi_{t}(\\xi^{\\prime}))\\)._\n",
      "\n",
      "**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\(\\mathcal{O}\\subseteq\\bar{\\mathcal{X}}\\) and a positive constant \\(\\epsilon\\) such that the system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable. Then there exists a constant \\(\\rho>0\\) such that for all but a Lebesgue-zero-measure set of \\((A,B)\\in\\mathbb{R}^{(2n+1)\\times(2n+1)}\\times\\mathbb{R}^{(2n+1)}\\), if \\(A+\\rho I\\) Hurwitz, then there exists an immersion \\(T:\\mathcal{O}\\rightarrow\\mathbb{R}^{(2n+1)}\\) solving the PDEs (3)._\n",
      "\n",
      "The above theorem clarifies that as long as the spectrum of \\(A\\) is restricted to the left of \\(-\\rho+i\\mathbb{R}\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\((A,B)\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\(T^{\\dagger}\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.\n",
      "\n",
      "### _Lipschitz-Bounded Neural Networks_\n",
      "\n",
      "Consider a \\(\\nu\\)-layer neural network \\(\\hat{x}=S(z,\\theta)\\) with all parameters denoted as a single vector \\(\\theta\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\(\\sigma:\\mathbb{R}\\rightarrow\\mathbb{R}\\), with slope bounded in \\([0,1]\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\n",
      "\n",
      "\\[\\begin{split}& z^{\\ell+1}=\\sigma(W^{\\ell}z^{\\ell}+b^{\\ell}),\\ \\ \\ell=0,\\ldots,\\nu-1\\\\ & z^{0}=z,\\quad\\hat{x}=W^{\\nu}z^{\\nu}+b^{\\nu}.\\end{split} \\tag{4}\\]\n",
      "\n",
      "where \\(W^{0},\\ldots,W^{\\nu}\\) are the weight matrices and \\(b^{0},\\ldots,b^{\\nu}\\) are the biases. In total there are \\(\\nu\\) activation layers inserted between \\(\\nu+1\\) fully connected layers. \\(z\\) represents the inputs to the neural network and \\(\\hat{x}\\) is the output vector, as we will use such a neural network to approximate the \\(T^{\\dagger}\\) mapping in the KKL observer.\n",
      "\n",
      "Given a neural network with fixed parameters \\(\\theta=(W^{0},b^{0},\\ldots,W^{\\nu},b^{\\nu})\\), a rough estimate of the Lipschitz\n",
      "\n",
      "Fig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\n",
      "constant of \\(S\\) can be obviously obtained as\n",
      "\n",
      "\\[L_{S}(\\theta)=\\prod_{\\ell=0}^{\\nu}\\|W^{\\ell}\\|_{2}, \\tag{5}\\]\n",
      "\n",
      "where \\(\\|\\cdot\\|_{2}\\) for a matrix refers to its operator norm induced by the \\(\\ell_{2}\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\n",
      "\n",
      "The recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\n",
      "\n",
      "**Definition 2** (\\(1\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\(X\\in\\mathbb{R}^{d\\times d}\\), \\(Y\\in\\mathbb{R}^{c\\times d}\\), \\(s\\in\\mathbb{R}^{d}\\), and \\(b\\in\\mathbb{R}^{d}\\), a \\(1\\)-Lipschitz sandwich layer is defined as such a mapping \\(\\Xi:\\mathbb{R}^{c}\\rightarrow\\mathbb{R}^{d}\\) that maps any \\(h\\in\\mathbb{R}^{c}\\) into a \\(\\Xi(h;X,Y,s,b)\\in\\mathbb{R}^{d}\\) according to the following formulas:_\n",
      "\n",
      "\\[Z =X-X^{\\top}+Y^{\\top}Y,\\ \\Psi_{s}=\\mathrm{diag}(e^{s}) \\tag{6}\\] \\[M_{X,Y} =\\left[(I+Z)^{-1}(I-Z)\\right]^{\\top},\\] \\[N_{X,Y} =\\left[-2Y(I+Z)^{-1}\\right]^{\\top},\\] \\[\\Xi(h) =\\sqrt{2}M_{X,Y}^{\\top}\\Psi_{s}\\sigma(\\sqrt{2}\\Psi_{s}^{-1}N_{X, Y}h+b).\\]\n",
      "\n",
      "It turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\(1\\)[28, Theorem 3.3]. The mapping from the input \\(h\\) to the output \\(\\Xi(h)\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\((X,Y)\\) to \\((M,N)\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\n",
      "\n",
      "Thus, by stacking a number of such sandwich layers after a scaling by \\(\\sqrt{\\gamma}\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\(\\Xi\\) as in Equation (6)), a neural network with Lipschitz bound \\(\\gamma\\) can be obtained, for any provided \\(\\gamma>0\\).\n",
      "\n",
      "**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\(S(\\cdot|\\theta)\\), by a neural network in the following architecture:_\n",
      "\n",
      "\\[h^{0} =\\sqrt{\\gamma}z; \\tag{7}\\] \\[h^{\\ell+1} =\\Xi(h^{\\ell};X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}),\\ \\ell=0,1,\\ldots,\\nu-1;\\] \\[\\hat{x} =\\sqrt{\\gamma}N_{X^{\\nu},Y^{\\nu}}h^{\\nu}+b^{\\nu}.\\]\n",
      "\n",
      "_Here the parameters include_\n",
      "\n",
      "\\[\\theta=\\{X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}\\}_{\\ell=0}^{\\nu-1}\\cup\\{X^{\\nu}, Y^{\\nu},b^{\\nu}\\}\\]\n",
      "\n",
      "_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\(z\\) and \\(\\hat{x}\\), respectively._\n",
      "\n",
      "The above-defined Wang-Manchester network satisfies \\(\\|S(\\cdot|\\theta)\\|_{\\mathrm{Lip}}\\leq\\gamma\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.\n",
      "\n",
      "## III Analysis on the Generalized Loss\n",
      "\n",
      "Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.\n",
      "\n",
      "**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\(\\mathcal{F}\\) on \\(\\mathcal{X}\\). The distribution \\(\\mathcal{F}\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\(\\mathcal{F}\\)._\n",
      "\n",
      "Suppose that The LTI dynamics of the KKL observer, \\((A,B)\\), is fixed. Then the observer states can be simulated from this linear dynamics.\n",
      "\n",
      "**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\(y=h(x)\\), but instead containing a white noise of unknown covariance \\(\\sigma^{2}\\). In other words, the simulation from \\(y\\) to \\(z\\) is_\n",
      "\n",
      "\\[\\begin{split}&\\dot{z}=Ax+By+w,\\quad\\mathbb{E}[w(t)]=0,\\,\\forall t \\in\\mathbb{R}\\\\ &\\mathbb{E}[w(t)w(s)]=\\delta(t-s)\\sigma^{2},\\,\\forall t,s\\in \\mathbb{R}.\\end{split} \\tag{8}\\]\n",
      "\n",
      "In this way, the collected sample, denoted as \\(\\{(x(t_{i}),z(t_{i}))\\}_{i=1}^{m}=\\{(x_{i},z_{i})\\}_{i=1}^{m}\\), in fact satisfies the following relation:\n",
      "\n",
      "\\[z_{i}=\\bar{z}_{i}+v_{i},\\quad\\delta_{i}=\\int_{-\\infty}^{t_{i}}g(\\tau)w(t_{i}- \\tau)d\\tau. \\tag{9}\\]\n",
      "\n",
      "Here \\(g(\\tau)\\) is the impulse response of LTI system \\((A,B)\\); \\(\\bar{z}\\) is the value of \\(z(t_{i})\\) that would be otherwise obtained if there were no white noises in the output measurements.\n",
      "\n",
      "**Assumption 3** (Sufficient decay).: _After a significantly long time \\(t_{\\epsilon}\\), \\(\\|z-T(x)\\|\\leq\\epsilon\\) for a small enough \\(z\\). Here \\(T\\) is the nonlinear immersion map specified by (3)._\n",
      "\n",
      "Fig. 2: A sandwich layer and its parameters.\n",
      "Then, \\(\\|\\bar{z}_{i}-T(x_{i})\\|\\leq\\epsilon\\). Thus, we may write\n",
      "\n",
      "\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\prime},\\quad\\|v_{i}^{\\prime}\\|\\leq\\epsilon. \\tag{10}\\]\n",
      "\n",
      "Now we suppose that the sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{m}\\) is used to train a neural network \\(S(\\cdot|\\theta)\\), which gives the state observations \\(\\hat{x}_{i}=S(z_{i}|\\theta)\\), and that the resulting empirical loss, if defined as the average squared observation error, is\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta):=\\frac{1}{m}\\sum_{i=1}^{m}\\|\\hat{x}_{i}-x_{i}\\|^{2}. \\tag{11}\\]\n",
      "\n",
      "Then we get\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\left\\|S\\left(T(x_{i})+v_{i}+v_{i }^{\\prime}|\\theta\\right)-x_{i}\\right\\|^{2}. \\tag{12}\\]\n",
      "\n",
      "**Assumption 4**.: _Assume that the probability distribution \\(\\mathcal{F}\\) is supported by a compact set, i.e., if \\(x\\sim\\mathcal{F}\\), then \\(x\\) should be almost surely bounded._\n",
      "\n",
      "It follows that both \\(S(\\cdot|\\theta)\\) and \\(T\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\(L_{S}(\\theta)\\) and \\(L_{T}\\), respectively. We have\n",
      "\n",
      "\\[\\|S\\left(T(x_{i})+\\delta_{i}+\\delta_{i}^{\\prime}|\\theta\\right)-S\\left(T(x_{i}) |\\theta\\right)\\|\\leq L_{S}(\\theta)L_{T}(\\|v_{i}\\|+\\epsilon). \\tag{13}\\]\n",
      "\n",
      "Denote \\(D\\) as the essential upper bound of \\(\\|x\\|\\) on the distribution \\(\\mathcal{F}\\). As such, without loss of generality, let \\(S(T(0))=0\\). Then \\(\\|x-S(T(x))\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely. Combining the above two equations, we further get\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{14}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}(\\theta)L_{T}(L_{S}(\\theta)L _{T}+1)D(\\|v_{i}\\|+\\epsilon)\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}^{2}(\\theta)L_{T}^{2}(\\|v_{i} \\|+\\epsilon)^{2}.\\]\n",
      "\n",
      "That is,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{15}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}(L_{S}(\\theta)L_{T}+1)^{2}\\left(D+ \\|v_{i}\\|+\\epsilon\\right)(\\|v_{i}\\|+\\epsilon).\\]\n",
      "\n",
      "The left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\(z_{i}=T(x_{i})\\), \\(i=1,\\ldots,m\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{16}\\] \\[\\quad\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}+(D+2\\epsilon) \\left(\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)^{1/2}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Given that \\(v_{i}\\) is the response of LTI system \\((A,B)\\) to a white noise of covariance \\(\\sigma^{2}\\), \\(\\mathbb{E}(\\|v_{i}\\|^{2})=h^{2}\\sigma^{2}\\) where \\(h\\) is the \\(H_{2}\\)-norm of the system \\((A,B)\\) where \\(A\\) is Hurwitz. Therefore,\n",
      "\n",
      "\\[\\mathbb{E}\\left(\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)=h^{2}\\sigma^{2}. \\tag{17}\\]\n",
      "\n",
      "Let \\(\\alpha\\) be a small positive number. With confidence \\(1-\\alpha/2\\), a conservative estimation for its upper bound can be found according to Markov inequality:\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\leq\\frac{1}{1-\\alpha/2}h^{2}\\sigma^{2}. \\tag{18}\\]\n",
      "\n",
      "Therefore,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{19}\\] \\[\\quad\\left[\\frac{h^{2}\\sigma^{2}}{1-\\alpha/2}+(D+2\\epsilon)\\frac{ h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Finally, we note that for \\(x\\sim\\mathcal{F}\\), now that \\(\\|x-S(T(x)|\\theta)\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely, by Hoeffding's inequality, for any \\(\\varepsilon>0\\),\n",
      "\n",
      "\\[\\mathbb{P}\\bigg{(}\\bigg{|}\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{ i})|\\theta)\\|^{2}-\\mathbb{E}\\left(\\|x-S(T(x))\\|^{2}\\right)\\bigg{|} \\tag{20}\\] \\[\\geq(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\varepsilon\\bigg{)}\\leq 2\\exp \\left(-2m\\varepsilon^{2}\\right).\\]\n",
      "\n",
      "Thus, with confidence \\(1-\\alpha/2\\), we have\n",
      "\n",
      "\\[\\left|\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}- \\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right)\\bigg{|}\\right. \\tag{21}\\] \\[\\quad<(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m }}.\\]\n",
      "\n",
      "Combining (19) and (21), we have the following theorem.\n",
      "\n",
      "**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_\n",
      "\n",
      "\\[R_{S}(\\theta)=\\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right), \\tag{22}\\]\n",
      "\n",
      "_is related to the empirical loss as defined in (11) by_\n",
      "\n",
      "\\[R_{S}(\\theta)<\\hat{R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\Delta(h,\\sigma, \\alpha,\\epsilon). \\tag{23}\\]\n",
      "\n",
      "_with confidence \\(1-\\alpha\\) (\\(\\alpha\\in(0,1)\\)). Here_\n",
      "\n",
      "\\[\\Delta(h,\\sigma,\\alpha,\\epsilon)= D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m}}+\\frac{h^{2}\\sigma^{2}}{1- \\alpha/2} \\tag{24}\\] \\[+(D+2\\epsilon)\\frac{h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon.\\]\n",
      "\n",
      "The theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\(L_{S}(\\theta)\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\(\\sigma\\)\n",
      "and \\(\\epsilon\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\(\\|x-S(T(x)|\\theta)\\|\\), which acts as a coefficient before the Hoeffding term \\(\\sqrt{\\ln(4/\\alpha)/2m}\\), and (ii) the effect of noisy measurements on the observer states.\n",
      "\n",
      "**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\(L_{S}(\\theta)\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\((A,B)\\) along with the neural network \\(S(\\cdot|\\theta)\\), as the dependence of \\(L_{T}\\) on \\((A,B)\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\((A,B)\\) and the neural network._\n",
      "\n",
      "## IV Case Study\n",
      "\n",
      "Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:\n",
      "\n",
      "\\[\\dot{x}_{1} =10(x_{2}-x_{1}), \\tag{25}\\] \\[\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\] \\[\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\]\n",
      "\n",
      "Suppose that the measurement used for state observation is \\(y=x_{2}\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\(0.01\\). The LTI part of the KKL observer, \\(A=-\\mathrm{diag}(8,4,2,1)\\) and \\(B=[1,1,1,1]^{\\top}\\) are chosen. At the beginning of the observer simulation, \\(z(0)=0\\) is set as the initial condition; we simulate the dynamics until \\(t=500\\) and randomly collect \\(m=2000\\) time instants between \\(t=20\\) and \\(t=500\\) as the training data.\n",
      "\n",
      "Consider first the case with noiseless measurement (\\(\\sigma=0\\)). The sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{2000}\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\(z_{i}\\) indeed captures the structure of such a Lorenz attractor in a \\(4\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\(80\\%\\) of the sample under the mean-squares loss metric, and validate using the remaining \\(20\\%\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\(10^{-3}\\) is used for optimization. The number of epochs is empirically tuned to \\(300\\). The neural network has \\(2\\) hidden layers, each containing \\(8\\) neurons, resulting in \\(292\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\(1.5\\) seconds (for a randomly initialized network).\n",
      "\n",
      "Varying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.\n",
      "\n",
      "* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\(1000\\), the \\(L_{S}\\) after training does not exceed \\(300\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\n",
      "* When the Lipschitz bound is small, relaxing the restriction on \\(L_{S}\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\(L_{S}\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and\n",
      "\n",
      "Fig. 3: Sample collected from the Lorenz system.\n",
      "validation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\n",
      "* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\(\\sigma=1\\), a suitable choice can be \\(\\gamma=100\\), whereas at \\(\\sigma=5\\) and \\(\\sigma=10\\), \\(\\gamma\\) can be chosen as \\(30\\) and \\(10\\), respectively.\n",
      "\n",
      "Now suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\(\\sigma=0\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\(L_{S}\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\(\\sigma\\geq 3\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\n",
      "\n",
      "Finally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\(L_{S}=10\\), and applying it to environments with noise \\(\\sigma=0.1\\), \\(0.3\\), \\(1.0\\), \\(3.0\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\(10\\) time units. Naturally, when \\(\\sigma\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\(\\sigma\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\(3<t<4\\) or \\(8<t<9\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.\n",
      "\n",
      "## V Conclusions and Discussions\n",
      "\n",
      "This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.\n",
      "\n",
      "Fig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)\n",
      "\n",
      "Fig. 5: Errors of noiselessly trained observers in noisy environments.\n",
      "We implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.\n",
      "\n",
      "Also, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Sample\n",
    "'''\n",
    "Abstract is usually defined as\n",
    "'###### Abstract'\n",
    "'''\n",
    "idx = 0\n",
    "# idx = 15\n",
    "sample = df.iloc[idx]['markdown']\n",
    "# print(len(sample), sample[:200])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks'}, page_content='###### Abstract  \\nThis paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'I Introduction'}, page_content='For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\\\(Q\\\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.  \\nHence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.  \\nThis paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.  \\nIt is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\\nthe neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.  \\nHence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'II Preliminaries'}, page_content='We consider a nonlinear autonomous system:  \\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]  \\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.  \\n### _KKL Observer_  \\nFor nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as  \\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]  \\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:  \\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]  \\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.  \\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).  \\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._  \\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._  \\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.  \\n### _Lipschitz-Bounded Neural Networks_  \\nConsider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as  \\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]  \\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.  \\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz  \\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as  \\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]  \\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.  \\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].  \\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_  \\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]  \\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.  \\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).  \\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_  \\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]  \\n_Here the parameters include_  \\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]  \\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._  \\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'III Analysis on the Generalized Loss'}, page_content=\"Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.  \\n**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\\\(\\\\mathcal{F}\\\\)._  \\nSuppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. Then the observer states can be simulated from this linear dynamics.  \\n**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_  \\n\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall t \\\\in\\\\mathbb{R}\\\\\\\\ &\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in \\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]  \\nIn this way, the collected sample, denoted as \\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), in fact satisfies the following relation:  \\n\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- \\\\tau)d\\\\tau. \\\\tag{9}\\\\]  \\nHere \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); \\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise obtained if there were no white noises in the output measurements.  \\n**Assumption 3** (Sufficient decay).: _After a significantly long time \\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough \\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._  \\nFig. 2: A sandwich layer and its parameters.\\nThen, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may write  \\n\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. \\\\tag{10}\\\\]  \\nNow we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the resulting empirical loss, if defined as the average squared observation error, is  \\n\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. \\\\tag{11}\\\\]  \\nThen we get  \\n\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i }^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]  \\n**Assumption 4**.: _Assume that the probability distribution \\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if \\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._  \\nIt follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have  \\n\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) |\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). \\\\tag{13}\\\\]  \\nDenote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let \\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely. Combining the above two equations, we further get  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L _{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} \\\\|+\\\\epsilon)^{2}.\\\\]  \\nThat is,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ \\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]  \\nThe left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) \\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nGiven that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a white noise of covariance \\\\(\\\\sigma^{2}\\\\), \\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the \\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. Therefore,  \\n\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. \\\\tag{17}\\\\]  \\nLet \\\\(\\\\alpha\\\\) be a small positive number. With confidence \\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be found according to Markov inequality:  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. \\\\tag{18}\\\\]  \\nTherefore,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nFinally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),  \\n\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} \\\\tag{20}\\\\] \\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp \\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]  \\nThus, with confidence \\\\(1-\\\\alpha/2\\\\), we have  \\n\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- \\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. \\\\tag{21}\\\\] \\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m }}.\\\\]  \\nCombining (19) and (21), we have the following theorem.  \\n**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_  \\n\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), \\\\tag{22}\\\\]  \\n_is related to the empirical loss as defined in (11) by_  \\n\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, \\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]  \\n_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_  \\n\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- \\\\alpha/2} \\\\tag{24}\\\\] \\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]  \\nThe theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\\\(\\\\sigma\\\\)\\nand \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of noisy measurements on the observer states.  \\n**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\\\((A,B)\\\\) and the neural network._\"),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'IV Case Study'}, page_content='Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:  \\n\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\\\]  \\nSuppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, \\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and \\\\(t=500\\\\) as the training data.  \\nConsider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\\\(z_{i}\\\\) indeed captures the structure of such a Lorenz attractor in a \\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\\\(80\\\\%\\\\) of the sample under the mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) seconds (for a randomly initialized network).  \\nVarying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.  \\n* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\\\(1000\\\\), the \\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\\n* When the Lipschitz bound is small, relaxing the restriction on \\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and  \\nFig. 3: Sample collected from the Lorenz system.\\nvalidation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\\n* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at \\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as \\\\(30\\\\) and \\\\(10\\\\), respectively.  \\nNow suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq 3\\\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.  \\nFinally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or \\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'V Conclusions and Discussions'}, page_content=\"This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.  \\nFig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)  \\nFig. 5: Errors of noiselessly trained observers in noisy environments.\\nWe implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.  \\nAlso, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_splits = splitter.split_text(sample)\n",
    "print(len(sample_splits))\n",
    "sample_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_markdown_hierarchy(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "    # Define a pattern to match headers (from # to ######)\n",
    "    header_pattern = re.compile(r'^(#{1,6})\\s*(.*)$')\n",
    "\n",
    "    # Initialize the root of the hierarchy\n",
    "    root = {'children': []}\n",
    "    # Stack to keep track of the current hierarchy levels\n",
    "    stack = [{'level': 0, 'node': root}]\n",
    "    # Accumulate text for the current node\n",
    "    current_text = []\n",
    "\n",
    "    for line in lines:\n",
    "        header_match = header_pattern.match(line)\n",
    "        if header_match:\n",
    "            # If we have accumulated text, add it to the current node\n",
    "            if current_text:\n",
    "                # Join accumulated text and add to the last node's 'text'\n",
    "                stack[-1]['node'].setdefault('text', '')\n",
    "                if stack[-1]['node']['text']:\n",
    "                    stack[-1]['node']['text'] += '\\n'\n",
    "                stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "                current_text = []\n",
    "            # Extract header level and text\n",
    "            header_marks, header_text = header_match.groups()\n",
    "            level = len(header_marks)\n",
    "            # Pop the stack to find the correct parent level\n",
    "            while stack and stack[-1]['level'] >= level:\n",
    "                stack.pop()\n",
    "            # Create a new node for the header\n",
    "            node = {\n",
    "                'header': f'h{level}',\n",
    "                'value': header_text.strip(),\n",
    "                'children': []\n",
    "            }\n",
    "            # Add the new node to its parent's 'children'\n",
    "            stack[-1]['node']['children'].append(node) ## parent\n",
    "            # Push the new node onto the stack\n",
    "            stack.append({'level': level, 'node': node}) ## for accumulating potential children\n",
    "        else:\n",
    "            # Accumulate non-header lines\n",
    "            current_text.append(line)\n",
    "    # After processing all lines, add any remaining text\n",
    "    if current_text:\n",
    "        stack[-1]['node'].setdefault('text', '')\n",
    "        if stack[-1]['node']['text']:\n",
    "            stack[-1]['node']['text'] += '\\n'\n",
    "        stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "    # Return the hierarchy starting from the root's children\n",
    "    return root['children']\n",
    "hierarchical_structure = parse_markdown_hierarchy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'children': [{'children': [],\n",
      "                'header': 'h6',\n",
      "                'text': 'This paper focuses on the _model-free_ synthesis of state observers for '\n",
      "                        'nonlinear autonomous systems without knowing the governing equations. '\n",
      "                        'Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure '\n",
      "                        'is leveraged, where the outputs are fed into a linear time-invariant '\n",
      "                        '(LTI) system to obtain the observer states, which can be viewed as the '\n",
      "                        'states nonlinearly transformed by an immersion mapping, and a neural '\n",
      "                        'network is used to approximate the inverse of the nonlinear immersion and '\n",
      "                        'estimate the states. In view of the possible existence of noises in '\n",
      "                        'output measurements, this work proposes to impose an upper bound on the '\n",
      "                        'Lipschitz constant of the neural network for robust and safe observation. '\n",
      "                        'A relation that bounds the generalization loss of state observation '\n",
      "                        'according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI part in the KKL observer, is established, thus reducing the '\n",
      "                        'model-free observer synthesis problem to that of Lipschitz-bounded neural '\n",
      "                        'network training, for which a direct parameterization technique is used. '\n",
      "                        'The proposed approach is demonstrated on a chaotic Lorenz system.',\n",
      "                'value': 'Abstract'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'For nonlinear systems that arise from realistic engineering applications '\n",
      "                        'such as transport-reaction processes, modern control theory relies on '\n",
      "                        '_state-space representations_ for their modeling, analysis, and control '\n",
      "                        '[1, 2, 3]. Recent advances in nonlinear control have highlighted the role '\n",
      "                        'of data-driven (machine learning) techniques in identifying governing '\n",
      "                        'equations or underlying dynamical structures [4, 5, 6], analyzing system '\n",
      "                        'and control-theoretic properties [7, 8], and synthesizing model-free '\n",
      "                        'controllers [9, 10, 11]. In these efforts, it is often assumed that the '\n",
      "                        '_state_ information is available for analysis or control; for example, in '\n",
      "                        'reinforcement learning (RL) literature, it is common to apply stochastic '\n",
      "                        'first-order optimization to learn a value (cost) function or \\\\(Q\\\\) '\n",
      "                        'function based on temporal actions and state measurements. In many (if '\n",
      "                        'not most) control engineering applications, such as in chemical '\n",
      "                        'processes, however, it is more likely that the states are not '\n",
      "                        'measurable.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, for nonlinear control in a state-space framework, a _state '\n",
      "                        'observer_ is necessary, whereby the states are estimated based on input '\n",
      "                        'and output history [12]. A recent review on model-based approaches to '\n",
      "                        'synthesize state observers is found in Bernard, Andrieu, and Astolfi '\n",
      "                        '[13]. A classical form of state observer for linear systems is known as '\n",
      "                        'Luenberger observer [14], which an auxiliary linear time-invariant (LTI) '\n",
      "                        'system that uses the plant outputs as inputs and returns state estimates. '\n",
      "                        'The observer states are in fact a linear transform of the plant states '\n",
      "                        '[15]. The idea was extended to nonlinear systems in the seminal work of '\n",
      "                        'Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) '\n",
      "                        'observer (as named in Andrieu and Praly [17]) still uses an LTI system to '\n",
      "                        'convert plant outputs to observer states, which turn out to be the plant '\n",
      "                        'states transformed via a nonlinear immersion. Thus, the observer '\n",
      "                        'synthesis problem reduces to the determination of this nonlinear '\n",
      "                        'immersion and its inverse, via solving (model-based) partial differential '\n",
      "                        'equations (PDEs). Such a KKL observer was extended from autonomous to '\n",
      "                        'actuated systems in [18], where the LTI part is replaced by an '\n",
      "                        'input-affine one with an additional nonlinear drift term associated with '\n",
      "                        'the actuated inputs.\\n'\n",
      "                        '\\n'\n",
      "                        'This paper focuses on the _synthesis of KKL observer_ in a _model-free_ '\n",
      "                        'manner, without assuming prior knowledge on the plant dynamics. This is '\n",
      "                        'motivated by two reasons: (i) many nonlinear systems that involve complex '\n",
      "                        'kinetic or kinematic mechanisms are often hard to model accurately, and '\n",
      "                        '(ii) it can be challenging to solve the associated PDEs, especially in '\n",
      "                        'high-dimensional state space (in fact, there may not be well-posed '\n",
      "                        'boundary conditions). In the recent years, there have been several works '\n",
      "                        'that pioneered the use of neural networks in the observer problem. For '\n",
      "                        'example, Ramos et al. [19] first trained neural networks to approximate '\n",
      "                        'the inverse immersion map to reconstruct the actual states from observer '\n",
      "                        'states. Then, the optimization of pole placement was considered along '\n",
      "                        'with the training of inverse immersion in [20]. Niazi et al. [21] used '\n",
      "                        'physics-informed neural networks (PINNs) to approach a surrogate solution '\n",
      "                        'to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization '\n",
      "                        'problem to minimize the accumulated squared state observation error, '\n",
      "                        'whereby the optimality condition, through calculus of variations results '\n",
      "                        'in neural ODEs.\\n'\n",
      "                        '\\n'\n",
      "                        'It is commonly known that neural networks, when over-parameterized with '\n",
      "                        'large widths and depths, may cause a deteriorated capability of '\n",
      "                        'generalization. It has also been argued that neural networks can be '\n",
      "                        'fragile to adversarial attacks to the training data and thus must be '\n",
      "                        'equipped with a self-defense mechanisms that warranty robustness [23, '\n",
      "                        '24]. In particular, controlling the Lipschitz constant of the mapping '\n",
      "                        'specified by the neural network has been studied as a promising approach '\n",
      "                        '[25, 26, 27]. However, in these works, estimating and minimizing the '\n",
      "                        'Lipschitz constant requires the use of semidefinite programming routines, '\n",
      "                        'which has a high complexity when the number of neurons is large. An '\n",
      "                        'alternative way, called _direct paramterizaton_, as recently proposed in '\n",
      "                        'Wang and Manchester [28], is to translate the Lipschitz bound constraint '\n",
      "                        'into a special architecture of\\n'\n",
      "                        'the neural layers, thus allowing the use of typical back-propagation (BP) '\n",
      "                        'to train the network in an unconstrained way.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, in this work, the Wang-Manchester direct parameterization is '\n",
      "                        'adopted to train Lipschitz-bounded neural networks in a KKL state '\n",
      "                        'observer for any unknown nonlinear autonomous system. The paper '\n",
      "                        'establishes a relation between the generalized observation error and the '\n",
      "                        'Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI observer dynamics, under a typical white noise assumption on the '\n",
      "                        'plant outputs. Hence, by varying the Lipschitz bound, the optimal '\n",
      "                        'observer can be synthesized.',\n",
      "                'value': 'I Introduction'},\n",
      "               {'children': [{'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'For nonlinear systems, KKL observer generalizes the notion '\n",
      "                                      'of Luenberger observers that were restricted to linear '\n",
      "                                      'systems [14], providing a generic method for state '\n",
      "                                      'observation with mild assumptions to guarantee existence. '\n",
      "                                      'Specifically, the KKL observer for (1) is expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). '\n",
      "                                      '\\\\tag{2}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'Here the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has '\n",
      "                                      'an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are '\n",
      "                                      'chosen under the requirements of (i) controllability of '\n",
      "                                      '\\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property '\n",
      "                                      'of \\\\(A\\\\), and (iii) sufficiently high dimension of '\n",
      "                                      '\\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) '\n",
      "                                      'if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if '\n",
      "                                      '\\\\((A,B)\\\\) is real [29]. The mapping from the observer '\n",
      "                                      'states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a '\n",
      "                                      'static one, \\\\(T^{\\\\dagger}\\\\), which is the '\n",
      "                                      'left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., '\n",
      "                                      'a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ '\n",
      "                                      'T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy '\n",
      "                                      'the following PDE:\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\frac{\\\\partial T}{\\\\partial '\n",
      "                                      'x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, '\n",
      "                                      '\\\\tag{3}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian '\n",
      "                                      'matrix of \\\\(T\\\\). It can be easily verified that under the '\n",
      "                                      'above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) '\n",
      "                                      'has an exponentially decaying dynamics, as \\\\(A\\\\) is '\n",
      "                                      'Hurwitz.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The conditions for the existence of a KKL observer, namely '\n",
      "                                      'the solution to its defining PDE (3), have been established '\n",
      "                                      'based on the condition of backward distinguishability. In '\n",
      "                                      'below, we denote the solution to the ODEs '\n",
      "                                      '\\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition '\n",
      "                                      '\\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the '\n",
      "                                      'backward time instant after which the solution does not '\n",
      "                                      'escape this region by '\n",
      "                                      '\\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). '\n",
      "                                      'Also denote '\n",
      "                                      '\\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 1** (Backward distinguishability).: _The '\n",
      "                                      'system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward '\n",
      "                                      'distinguishable if for any distinct '\n",
      "                                      '\\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a '\n",
      "                                      'negative '\n",
      "                                      '\\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} '\n",
      "                                      '(\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq '\n",
      "                                      'h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Fact 1** (Existence of KKL observer, cf. Brivadis et al. '\n",
      "                                      '[29]).: _Assume that there is an open '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a '\n",
      "                                      'positive constant \\\\(\\\\epsilon\\\\) such that the system (1) '\n",
      "                                      'is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. '\n",
      "                                      'Then there exists a constant \\\\(\\\\rho>0\\\\) such that for '\n",
      "                                      'all but a Lebesgue-zero-measure set of '\n",
      "                                      '\\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), '\n",
      "                                      'if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion '\n",
      "                                      '\\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) '\n",
      "                                      'solving the PDEs (3)._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above theorem clarifies that as long as the spectrum of '\n",
      "                                      '\\\\(A\\\\) is restricted to the left of '\n",
      "                                      '\\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL '\n",
      "                                      'observer can be almost arbitrarily assigned. Once '\n",
      "                                      '\\\\((A,B)\\\\) are chosen, the remaining question for '\n",
      "                                      'synthesis a KKL observer (2) is to numerically determine '\n",
      "                                      'the solution. In view of the computational challenge in '\n",
      "                                      'directly solving the PDEs (3) and the recent trend of '\n",
      "                                      'handling the problem by neural approaches [19, 20, 21], '\n",
      "                                      'this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a '\n",
      "                                      'neural network. Yet, instead of using a vanilla multi-layer '\n",
      "                                      'perceptron architecture, a Lipschitz-bounded neural network '\n",
      "                                      'will be adopted, which safeguards the generalization '\n",
      "                                      'performance of state observation, which will be discussed '\n",
      "                                      'in SSIII. This overall idea is illustrated in Fig. 1.',\n",
      "                              'value': '_KKL Observer_'},\n",
      "                             {'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network '\n",
      "                                      '\\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as '\n",
      "                                      'a single vector \\\\(\\\\theta\\\\). Without loss of generality, '\n",
      "                                      'assume that the activation function (element-wise applied '\n",
      "                                      'to vectors) is '\n",
      "                                      '\\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with '\n",
      "                                      'slope bounded in \\\\([0,1]\\\\) (in this work, rectified '\n",
      "                                      'linear units (ReLU) are used to prevent gradient decay in '\n",
      "                                      'BP training). The neural network then can be expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\begin{split}& '\n",
      "                                      'z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ '\n",
      "                                      '\\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & '\n",
      "                                      'z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} '\n",
      "                                      '\\\\tag{4}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices '\n",
      "                                      'and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total '\n",
      "                                      'there are \\\\(\\\\nu\\\\) activation layers inserted between '\n",
      "                                      '\\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the '\n",
      "                                      'inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the '\n",
      "                                      'output vector, as we will use such a neural network to '\n",
      "                                      'approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL '\n",
      "                                      'observer.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Given a neural network with fixed parameters '\n",
      "                                      '\\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a '\n",
      "                                      'rough estimate of the Lipschitz\\n'\n",
      "                                      '\\n'\n",
      "                                      'Fig. 1: KKL observer with a Lipschitz-bounded neural '\n",
      "                                      'network to be trained.\\n'\n",
      "                                      'constant of \\\\(S\\\\) can be obviously obtained as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, '\n",
      "                                      '\\\\tag{5}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its '\n",
      "                                      'operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of '\n",
      "                                      'vectors, i.e., its largest singular value. To reduce the '\n",
      "                                      'conservativeness, Fazlyab et al. [25] leverages the '\n",
      "                                      'control-theoretic tool of integral quadratic constraints to '\n",
      "                                      'formulate the Lipschitz bound condition as a linear matrix '\n",
      "                                      'inequality, thus estimating the Lipschitz constants and '\n",
      "                                      'training Lipschitz-bounded neural networks through solving '\n",
      "                                      'semidefinite programming problems [27]. The pertinent '\n",
      "                                      'matrix size, however, proportionally scales with the total '\n",
      "                                      'number of neurons, which results in high computational '\n",
      "                                      'complexity unless the neural network is very small.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The recent work of Wang and Manchester [28] proposed a '\n",
      "                                      '_direct parameterization_ approach to accommodate Lipschitz '\n",
      "                                      'bound by a special design of the neural network '\n",
      "                                      'architecture instead of imposing extra parameter '\n",
      "                                      'constraints. By this approach, the training of neural '\n",
      "                                      'networks is an unconstrained optimization problem and is '\n",
      "                                      'thus amenable to the typical, computationally lightweight '\n",
      "                                      'back-propagation (BP) routine. Wang-Manchester direct '\n",
      "                                      'parameterization is conceptually related to, and arguably '\n",
      "                                      'motivated by, the theory of controller parameterization '\n",
      "                                      '[30, 31].\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. '\n",
      "                                      '[28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times '\n",
      "                                      'd}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), '\n",
      "                                      '\\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), '\n",
      "                                      'a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a '\n",
      "                                      'mapping '\n",
      "                                      '\\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that '\n",
      "                                      'maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a '\n",
      "                                      '\\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the '\n",
      "                                      'following formulas:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ '\n",
      "                                      '\\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} '\n",
      "                                      '=\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} '\n",
      "                                      '=\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) '\n",
      "                                      '=\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, '\n",
      "                                      'Y}h+b).\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'It turns out that the Lipschitz constant of the '\n",
      "                                      'above-defined sandwich layer is guaranteed to be upper '\n",
      "                                      'bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the '\n",
      "                                      'input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded '\n",
      "                                      'as comprising of an activation layer in the midst of two '\n",
      "                                      'fully connected layers with related parameters. The '\n",
      "                                      'operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the '\n",
      "                                      '_Cayley transform_. The structure and the parameters of a '\n",
      "                                      'sandwich layer is shown in Fig. 2.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Thus, by stacking a number of such sandwich layers after a '\n",
      "                                      'scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated '\n",
      "                                      'half-sandwich layer (meaning a layer containing only the '\n",
      "                                      'terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), '\n",
      "                                      'a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be '\n",
      "                                      'obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 3** (Wang-Manchester network).: _In this work, '\n",
      "                                      'we refer to Wang-Manchester network, '\n",
      "                                      '\\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the '\n",
      "                                      'following architecture:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} '\n",
      "                                      '=\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ '\n",
      "                                      '\\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} '\n",
      "                                      '=\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_Here the parameters include_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, '\n",
      "                                      'Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_which can be trained in an unconstrained way using '\n",
      "                                      'back-propagation. The inputs and outputs of the network are '\n",
      "                                      '\\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above-defined Wang-Manchester network satisfies '\n",
      "                                      '\\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). '\n",
      "                                      'In this work, the network is defined and trained with data '\n",
      "                                      'using PyTorch (version 2.0.1) on Google Colaboratory, which '\n",
      "                                      'allows the auto-differentiation of a user-defined loss '\n",
      "                                      'function with respect to the neural network parameters for '\n",
      "                                      'the parameters to be iteratively updated.',\n",
      "                              'value': '_Lipschitz-Bounded Neural Networks_'}],\n",
      "                'header': 'h2',\n",
      "                'text': 'We consider a nonlinear autonomous system:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'where \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector '\n",
      "                        'of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For '\n",
      "                        'simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and '\n",
      "                        '\\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and '\n",
      "                        'uniqueness of solution but unknown for model-based synthesis.',\n",
      "                'value': 'II Preliminaries'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Here we shall provide a justification for requiring a Lipschitz bound on '\n",
      "                        'the neural network. We will make the following standing assumptions on '\n",
      "                        'the training data collection procedure for subsequent analysis.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is '\n",
      "                        'collected from the system, whose initial state is sampled from a '\n",
      "                        'probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure '\n",
      "                        'of the Perron-Frobenius operator), so that any point of the trajectory '\n",
      "                        'comes from \\\\(\\\\mathcal{F}\\\\)._\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. '\n",
      "                        'Then the observer states can be simulated from this linear dynamics.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 2** (Noisy measurements).: _Assume that the input signal for '\n",
      "                        'this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead '\n",
      "                        'containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In '\n",
      "                        'other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall '\n",
      "                        't \\\\in\\\\mathbb{R}\\\\\\\\ '\n",
      "                        '&\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in '\n",
      "                        '\\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'In this way, the collected sample, denoted as '\n",
      "                        '\\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), '\n",
      "                        'in fact satisfies the following relation:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- '\n",
      "                        '\\\\tau)d\\\\tau. \\\\tag{9}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Here \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); '\n",
      "                        '\\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise '\n",
      "                        'obtained if there were no white noises in the output measurements.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 3** (Sufficient decay).: _After a significantly long time '\n",
      "                        '\\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough '\n",
      "                        '\\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 2: A sandwich layer and its parameters.\\n'\n",
      "                        'Then, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may '\n",
      "                        'write\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. '\n",
      "                        '\\\\tag{10}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Now we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is '\n",
      "                        'used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the '\n",
      "                        'state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the '\n",
      "                        'resulting empirical loss, if defined as the average squared observation '\n",
      "                        'error, is\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. '\n",
      "                        '\\\\tag{11}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Then we get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i '\n",
      "                        '}^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 4**.: _Assume that the probability distribution '\n",
      "                        '\\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if '\n",
      "                        '\\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._\\n'\n",
      "                        '\\n'\n",
      "                        'It follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be '\n",
      "                        'Lipschitz continuous. Denote their Lipschitz constants as '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) '\n",
      "                        '|\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). '\n",
      "                        '\\\\tag{13}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Denote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let '\n",
      "                        '\\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) '\n",
      "                        'almost surely. Combining the above two equations, we further get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L '\n",
      "                        '_{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} '\n",
      "                        '\\\\|+\\\\epsilon)^{2}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'That is,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ '\n",
      "                        '\\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The left-hand side gives an estimation of the empirical loss when '\n",
      "                        'observing the states from perfect output measurements (namely when '\n",
      "                        '\\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last '\n",
      "                        'term and applying Cauchy-Schwarz inequality, we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) '\n",
      "                        '\\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Given that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a '\n",
      "                        'white noise of covariance \\\\(\\\\sigma^{2}\\\\), '\n",
      "                        '\\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the '\n",
      "                        '\\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. '\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{17}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Let \\\\(\\\\alpha\\\\) be a small positive number. With confidence '\n",
      "                        '\\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be '\n",
      "                        'found according to Markov inequality:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{18}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ '\n",
      "                        'h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, '\n",
      "                        \"by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),\\n\"\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ '\n",
      "                        'i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} '\n",
      "                        '\\\\tag{20}\\\\] '\n",
      "                        '\\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp '\n",
      "                        '\\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Thus, with confidence \\\\(1-\\\\alpha/2\\\\), we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- '\n",
      "                        '\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. '\n",
      "                        '\\\\tag{21}\\\\] '\n",
      "                        '\\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m '\n",
      "                        '}}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Combining (19) and (21), we have the following theorem.\\n'\n",
      "                        '\\n'\n",
      "                        '**Theorem 1**.: _Under the afore-mentioned assumptions, the '\n",
      "                        'generalization loss, defined as_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), '\n",
      "                        '\\\\tag{22}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_is related to the empirical loss as defined in (11) by_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, '\n",
      "                        '\\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= '\n",
      "                        'D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- '\n",
      "                        '\\\\alpha/2} \\\\tag{24}\\\\] '\n",
      "                        '\\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The theorem shows that the Lipschitz constant of the neural network '\n",
      "                        'trained plays an important role in the generalized performance of the '\n",
      "                        'resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly '\n",
      "                        'that of amplifying the first and third terms defined on the right-hand '\n",
      "                        'side of (24), supposing that \\\\(\\\\sigma\\\\)\\n'\n",
      "                        'and \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise '\n",
      "                        'from (i) the overall upper bound of the observation error '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the '\n",
      "                        'Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of '\n",
      "                        'noisy measurements on the observer states.\\n'\n",
      "                        '\\n'\n",
      "                        '**Remark 1**.: _It is noted that the performance bound stated in the '\n",
      "                        'above theorem can be conservative. The conclusion that '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement '\n",
      "                        'noise should be considered as qualitative. The theorem also does not '\n",
      "                        'suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) '\n",
      "                        'along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence '\n",
      "                        'of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does '\n",
      "                        'not consider the problem of simultaneously training \\\\((A,B)\\\\) and the '\n",
      "                        'neural network._',\n",
      "                'value': 'III Analysis on the Generalized Loss'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Let us consider a Lorenz system in a 3-dimensional state space with '\n",
      "                        'chaotic behavior. The equation is written as:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} '\n",
      "                        '=x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} '\n",
      "                        '=10x_{1}x_{2}-(8/3)x_{3}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), '\n",
      "                        'where a white noise exists. We assign different values to the variance of '\n",
      "                        'the measurement noise and investigate how the resulting neural network '\n",
      "                        'should be chosen differently. To simulate the process we will use a '\n",
      "                        'sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, '\n",
      "                        '\\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are '\n",
      "                        'chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set '\n",
      "                        'as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and '\n",
      "                        'randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and '\n",
      "                        '\\\\(t=500\\\\) as the training data.\\n'\n",
      "                        '\\n'\n",
      "                        'Consider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The '\n",
      "                        'sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which '\n",
      "                        'shows that the data points are representative on the forward invariant '\n",
      "                        'set of the system, and that the observer states \\\\(z_{i}\\\\) indeed '\n",
      "                        'captures the structure of such a Lorenz attractor in a '\n",
      "                        '\\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network '\n",
      "                        'using a randomly selected \\\\(80\\\\%\\\\) of the sample under the '\n",
      "                        'mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) '\n",
      "                        'sample points. Stochastic gradient descent (SGD) algorithm with a '\n",
      "                        'learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of '\n",
      "                        'epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) '\n",
      "                        'hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) '\n",
      "                        'parameters to train in total. After training, the Lipschitz constant is '\n",
      "                        'evaluated a posteriori via the semidefinite programming approach of '\n",
      "                        'Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) '\n",
      "                        'seconds (for a randomly initialized network).\\n'\n",
      "                        '\\n'\n",
      "                        'Varying the prior bound on the Lipschitz constant, the resulting training '\n",
      "                        'loss, validation loss, and the posterior Lipschitz bound obtained from '\n",
      "                        'the same training conditions are illustrated in Fig. 4. The following '\n",
      "                        'observations can be made from these results.\\n'\n",
      "                        '\\n'\n",
      "                        '* As anticipated, as the set bound on the Lipschitz bound increases, the '\n",
      "                        'Lipschitz constant of the trained neural network becomes higher. The '\n",
      "                        'Lipschitz constants estimated a posteriori are lower than the prior bound '\n",
      "                        'on the Wang-Manchester network, validating the direct parameterization '\n",
      "                        'approach on constraining the slope. On the other hand, the actually '\n",
      "                        'posterior Lipschitz constant has an increasingly large lag behind the '\n",
      "                        'prior bound; for example, when the prior bound is \\\\(1000\\\\), the '\n",
      "                        '\\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that '\n",
      "                        'even for the training objective alone, there is a \"resistance\" to pursue '\n",
      "                        'the maximally possible Lipschitz constant.\\n'\n",
      "                        '* When the Lipschitz bound is small, relaxing the restriction on '\n",
      "                        '\\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the '\n",
      "                        'validation loss, showing that the Lipschitz bound is a bottleneck causing '\n",
      "                        'underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no '\n",
      "                        'longer exists; instead, overfitting will appear, with rising training '\n",
      "                        'and\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 3: Sample collected from the Lorenz system.\\n'\n",
      "                        'validation losses. The overfitting phenomenon is more significant when '\n",
      "                        'the noise is large. Thus, there should be optimal values to be set as the '\n",
      "                        'Lipschitz bound.\\n'\n",
      "                        '* Depending on the noise magnitude, the deviation of posterior Lipschitz '\n",
      "                        'constant from the prior bound and the emergence of overfitting phenomenon '\n",
      "                        'occur at different threshold values of the Lipschitz bound. Thus, the '\n",
      "                        'Lipschitz bound to be used for neural network training should be tuned '\n",
      "                        'differently as the noise intensity varies. For example, at '\n",
      "                        '\\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at '\n",
      "                        '\\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as '\n",
      "                        '\\\\(30\\\\) and \\\\(10\\\\), respectively.\\n'\n",
      "                        '\\n'\n",
      "                        'Now suppose that at the observer design stage, the Wang-Manchester '\n",
      "                        'network is trained by the simulated data from a perfect digital twin of '\n",
      "                        'the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network '\n",
      "                        'trained to observe the states of the physical system, the environment is '\n",
      "                        'noisy. In Fig. 5, the resulting loss (mean squared state observation '\n",
      "                        'error) is plotted against varying prior Lipschitz bounds under multiple '\n",
      "                        'values of the environment noise magnitude. It is seen that when the noise '\n",
      "                        'is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic '\n",
      "                        'decrease in the observation error within a large range. On the other '\n",
      "                        'hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq '\n",
      "                        '3\\\\)), the Lipschitz bound has a severe effect on the generalization '\n",
      "                        'loss, and since the achievable performance is restrictive, the '\n",
      "                        'fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, the performance of the state observer is examined. Consider '\n",
      "                        'using the network trained with noiseless simulation data under the prior '\n",
      "                        'Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with '\n",
      "                        'noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The '\n",
      "                        'trajectories of the three components of estimated states by the observer '\n",
      "                        'are plotted against the true states in Fig. 6, within a time horizon of '\n",
      "                        '\\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state '\n",
      "                        'estimates can well track the true states and capture the trends in the '\n",
      "                        'correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered '\n",
      "                        'and the signals constructed by the observer are more noisy, occasionally '\n",
      "                        'yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or '\n",
      "                        '\\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz '\n",
      "                        'attractor). Overall, the state estimates mollifies the true state '\n",
      "                        'trajectories, which is due to the structure of our KKL observer - a '\n",
      "                        'linear filter (LTI system) as the state dynamics and a Lipschitz-bounded '\n",
      "                        'neural network as the static output map.',\n",
      "                'value': 'IV Case Study'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'This work leverages the recent tools of Lipschitz-bounded neural networks '\n",
      "                        'for the synthesis of nonlinear state observers in a model-free setting. '\n",
      "                        'The observer, which has a Kazantzis-Kravaris structure, turns out to have '\n",
      "                        'a provable generalization performance that is related to the Lipschitz '\n",
      "                        'constant of the trained neural network (which represents the mapping from '\n",
      "                        'the observer states to the plant states). As such, by varying the '\n",
      "                        'Lipschitz bound and re-training the neural network, the optimal training '\n",
      "                        'result can yield the minimum generalized state observation error. The '\n",
      "                        'importance of bounding the Lipschitz constant has been demonstrated by a '\n",
      "                        'numerical case study on the Lorenz system.\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 4: Loss and Lipschitz constants under different prior Lipschitz '\n",
      "                        'bounds. (Blue wedges: training loss, blue circles: validation loss, green '\n",
      "                        'circles: prior Lipschitz bound; green wedges: posterior Lipschitz '\n",
      "                        'bound.)\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 5: Errors of noiselessly trained observers in noisy environments.\\n'\n",
      "                        'We implicitly assumed here that a simulator of the dynamics is available, '\n",
      "                        \"so that the true states' trajectories can be used to train the neural \"\n",
      "                        'network. However, such ground truth for supervised learning may not '\n",
      "                        'actually exist in real applications, i.e., only inputs and outputs are '\n",
      "                        'recorded, yet a state observation mechanism is still needed or desired '\n",
      "                        \"for feedback control. To this end, the author's recent work [32] proposed \"\n",
      "                        'a data-driven KKL observer by appending a kernel dimensionality reduction '\n",
      "                        'scheme to the LTI dynamics, thus obtaining estimates that are '\n",
      "                        'diffeomorphic to the states.\\n'\n",
      "                        '\\n'\n",
      "                        'Also, the current approach is yet restricted to autonomous systems. For '\n",
      "                        'control purposes, it should be further extended to non-autonomous ones, '\n",
      "                        'where the Bernard-Andrieu observer structure [18] is anticipated. Also, '\n",
      "                        'the application of such data-driven state observers to learning '\n",
      "                        'control-relevant properties of nonlinear dynamical systems and controller '\n",
      "                        'synthesis [33, 34] is undergoing active research.',\n",
      "                'value': 'V Conclusions and Discussions'}],\n",
      "  'header': 'h1',\n",
      "  'text': '',\n",
      "  'value': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural '\n",
      "           'Networks'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(hierarchical_structure, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_texts(node):\n",
    "    texts = [node[\"text\"]]\n",
    "    for child in node[\"children\"]:\n",
    "        texts.extend(get_node_texts(child))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 II Preliminaries 2\n",
      "h2 III Analysis on the Generalized Loss 0\n",
      "h2 IV Case Study 0\n",
      "h2 V Conclusions and Discussions 0\n"
     ]
    }
   ],
   "source": [
    "## Top Section\n",
    "top_section = hierarchical_structure[0]\n",
    "header_type = top_section[\"header\"]\n",
    "section_name = top_section[\"value\"]\n",
    "print(header_type, section_name)\n",
    "\n",
    "\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = []\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    if section_name.lower()==\"abstract\":\n",
    "        continue\n",
    "    \n",
    "    section_text = get_node_texts(section)\n",
    "    section_texts.append(section_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4958, 9149, 7740, 5915, 1977]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(\"\\n\".join(x)) for x in section_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': 'h2',\n",
       " 'value': 'II Preliminaries',\n",
       " 'children': [{'header': 'h3',\n",
       "   'value': '_KKL Observer_',\n",
       "   'children': [],\n",
       "   'text': 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.'},\n",
       "  {'header': 'h3',\n",
       "   'value': '_Lipschitz-Bounded Neural Networks_',\n",
       "   'children': [],\n",
       "   'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'}],\n",
       " 'text': 'We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_section[\"children\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.',\n",
       " 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.',\n",
       " 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_texts = get_node_texts(top_section[\"children\"][2])\n",
    "print(len(section_texts))\n",
    "section_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section count test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/10000 [00:00<00:01, 5070.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "has title 14, no title 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_sections = []\n",
    "has_title_count = 0\n",
    "no_title_count = 0\n",
    "\n",
    "for idx in tqdm(range(df.shape[0])):\n",
    "    text = df.iloc[idx]['markdown']\n",
    "    hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "    \n",
    "    # has H1 Title \n",
    "    if len(hierarchical_structure)==1 and hierarchical_structure[0]['header']=='h1':\n",
    "        has_title_count+=1\n",
    "        num_section = 0\n",
    "        top_section = hierarchical_structure[0]\n",
    "        for section in top_section[\"children\"]:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    elif len(hierarchical_structure)>1:\n",
    "        no_title_count+=1\n",
    "        print(idx)\n",
    "        break\n",
    "        num_section = 0\n",
    "        for section in hierarchical_structure:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    else:\n",
    "        print(\"ERR {} - {}\".format(idx, hierarchical_structure, len(hierarchical_structure)))\n",
    "        \n",
    "print(\"has title {}, no title {}\".format(has_title_count, no_title_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX 10 AVG 5.785714285714286 MIN 3\n"
     ]
    }
   ],
   "source": [
    "num_sections_np = np.array(num_sections)\n",
    "print(\"MAX {} AVG {} MIN {}\".format(num_sections_np.max(), num_sections_np.mean(), num_sections_np.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sections_np[num_sections_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_sections_np==2).nonzero()[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 Appendix A Complex representation of a real wave 0\n"
     ]
    }
   ],
   "source": [
    "# idx = 7843 ## 43 sections\n",
    "# https://arxiv.org/pdf/2308.03803\n",
    "\n",
    "idx = 27 ## 2 sections\n",
    "# https://arxiv.org/pdf/2301.09285\n",
    "text = df.iloc[idx]['markdown']\n",
    "# print(text)\n",
    "hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "print(len(hierarchical_structure[0]['children']))\n",
    "hierarchical_structure\n",
    "\n",
    "for section in hierarchical_structure[0][\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.hist(num_sections, bins = 50)\n",
    "plt.xlim(-1, 20)\n",
    "plt.title(\"Number of identitified sections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2. md2py based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from md2py import md2py, TreeOfContents\n",
    "from src.custom_md2py import md2py, TreeOfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs\n",
      "Depth: 3\n",
      "Heading: None\n",
      "Num children: 0\n",
      "[]\n",
      "------------------------------\n",
      "h6 Abstract\n",
      "Depth: 3\n",
      "Heading: 6\n",
      "Num children: 0\n",
      "[]\n",
      "------------------------------\n",
      "p Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over (8\\%) performance gains.\n",
      "Depth: 3\n",
      "Heading: None\n",
      "Num children: 0\n",
      "[]\n",
      "------------------------------\n",
      "h2 1 Introduction\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 4\n",
      "p\n",
      "While prevalent in the research community, automatic chart understanding remains a challenging problem due to its complex compositions of various shapes, lines, colors, and scene text. Although tremendous success is achieved in the V+L research, applying these existing methods to handle chart-related tasks is hard. Recent research ChartQA Masry et al. (2022) and Chart-to-Text Kantharaj et al. (2022) attempt to first convert chart images to their underlined tables and use the extracted tables to perform chart-related V+L task. As the extracted tables always have clean and organized structures, it makes extracting relevant information to solve downstream reasoning tasks much more accessible. Empirically, using tables yields promising results on both CQA and CS.\n",
      "p\n",
      "Despite valuing table as a significant ingredient for chart understanding, we have two main concerns about this approach: (1) Automatic table extraction is unreliable. Existing methods Luo et al. (2021); Kato et al. (2022) are often limited to work on a few particular types of chart images and do not generalize well. Moreover, the extracted table is likely to contain incorrect noisy predictions that potentially harm the performance of the following task. (2) In most cases, the whole table is optional for resolving the chart-related V+L task. As illus\n",
      "p\n",
      "We evaluate our ChartT5 on two tasks and benchmarks: ChartQA and Chart-to-Text. In ChartQA, ChartT5 outperforms all the non-pretraining methods that use extracted tables by at least (8\\%) performance gains. ChartT5 also beats the pre-training table-based methods, which demonstrates the effectiveness of the proposed pre-training strategies. On Chart-to-Text, ChartT5 consistly outperforms the existing SOTA on the content selection metrics Barzilay and Lapata (2005) which values the model's capability to extract the critical information from the chart.\n",
      "p\n",
      "In summary, our contributions are summarized below:\n",
      "[<p>While prevalent in the research community, automatic chart understanding remains a challenging problem due to its complex compositions of various shapes, lines, colors, and scene text. Although tremendous success is achieved in the V+L research, applying these existing methods to handle chart-related tasks is hard. Recent research ChartQA Masry et al. (2022) and Chart-to-Text Kantharaj et al. (2022) attempt to first convert chart images to their underlined tables and use the extracted tables to perform chart-related V+L task. As the extracted tables always have clean and organized structures, it makes extracting relevant information to solve downstream reasoning tasks much more accessible. Empirically, using tables yields promising results on both CQA and CS.</p>, <p>Despite valuing table as a significant ingredient for chart understanding, we have two main concerns about this approach: (1) Automatic table extraction is unreliable. Existing methods Luo et al. (2021); Kato et al. (2022) are often limited to work on a few particular types of chart images and do not generalize well. Moreover, the extracted table is likely to contain incorrect noisy predictions that potentially harm the performance of the following task. (2) In most cases, the whole table is optional for resolving the chart-related V+L task. As illus</p>, <p>We evaluate our ChartT5 on two tasks and benchmarks: ChartQA and Chart-to-Text. In ChartQA, ChartT5 outperforms all the non-pretraining methods that use extracted tables by at least (8\\%) performance gains. ChartT5 also beats the pre-training table-based methods, which demonstrates the effectiveness of the proposed pre-training strategies. On Chart-to-Text, ChartT5 consistly outperforms the existing SOTA on the content selection metrics Barzilay and Lapata (2005) which values the model's capability to extract the critical information from the chart.</p>, <p>In summary, our contributions are summarized below:</p>]\n",
      "------------------------------\n",
      "h2 2 Related Work\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 2\n",
      "h3\n",
      "Vision and Language Research on Charts\n",
      "h3\n",
      "Vision and Language Pre-training\n",
      "[<p>Researching chart understanding in V+L tasks is a popular field nowadays. The most prevalent problem is chart question answering (CQA) Kafle et al. (2018); Kahou et al. (2018); Methani et al. (2020); Masry et al. (2022); Chaudhry et al. (2020), where researchers build models to answer complex questions on chart images. Another popular one is chart summarization (CS) Kantharaj et al. (2022); Obeid and Hoque (2020), which requires machine learning models to create a summary of key insights conveyed by a chart. Hsu et al. (2021) collected a large-scale scientific figures captioning dataset from research papers where many images are chart plots.</p>, <p>There are two main approaches for chart vision and language tasks. The first approach adapts existing visual question answering (VQA) and image captioning models to CQA and CS tasks with some specialized designs for chart images Kafle et al. (2020); Singh and Shekhar (2020); Chaudhry et al. (2020); Kafle et al. (2018); Hsu et al. (2021); Spreafico and Carenini (2020). The other approach assumes the table data of charts is accessible from the dataset Kim et al. (2020); Masry (2021) or can be extracted from the chart images using vision to table techniques Methani et al. (2020); Masry et al. (2022); Kantharaj et al. (2022). Then, the researchers will either use a table-to-text generation model Kim et al. (2020); Masry (2021); Methani et al. (2020) or combine the embedding of tables and charts via a multi-modal fusion method to generate the text output Masry et al. (2022); Kantharaj et al. (2022). It is clear from these efforts that adding tables as the additional representation of charts will dramatically improve the model's capability to understand and interpret chart information.</p>, <p>Following the table-based approach, we also value the information provided by the underlined table data of chart images. However, instead of directly concatenating the extracted table into the chart understanding model, we facilitate our model with the capability to interpret the table data from chart images via pre-training on chart-table pairs.</p>, <p>Vision and language pre-training has received growing interest over the past few years. Researchers build transformer-based multi-modal fusion models and perform self-supervised learning on a large-scale corpus of image-text pairs to learn robust cross-modal representations that can benefit the performance of various downstream tasks Chen et al. (2020); Lu et al. (2019); Tan and Bansal (2019);\n",
      "Su et al., 2019; Li et al., 2020; Zhang et al., 2021).</p>, <p>While the pre-trained models achieve great success on tasks like VQA (Antol et al., 2015) and Image Captioning (Chen et al., 2015), they have only focused on the domain of natural images. However, chart understanding is still challenging for the existing vision and language methods due to their lack of knowledge of scene text and structured visual units such as \"bars\" and \"lines\".</p>, <h3>Vision and Language Research on Charts</h3>, <h3>Vision and Language Pre-training</h3>]\n",
      "------------------------------\n",
      "h2 3 Method\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 4\n",
      "p\n",
      "In this section, we first introduce the dataset for pre-training. We then go over our ChartT5 model architecture and pre-training objectives to predict masked tables from the chart and OCR information.\n",
      "h3\n",
      "Pre-training Dataset Collection\n",
      "h3\n",
      "Model Overview\n",
      "h3\n",
      "Pre-training Objectives\n",
      "[<p>To collect large-scale pairs of chart-table data, we collect synthetic data from existing chart question-answering corpora, including PlotQA (Methani et al., 2020), DVQA (Kafle et al., 2018), and FigureQA (Kahou et al., 2018). Specifically, DVQA and FigureQA render chart images from synthetic tables that are randomly generated from limited vocabularies. PlotQA first scrapes tables from online resources like World Bank Open Data and then synthesizes the charts from the scraped data, where the tables and charts contain more diverse language information. Our pre-training corpus consists of 495K chart-table pairs, which cover a diverse range of chart types. Our pre-training corpus contains three chart types: bar, line, and pie. The distribution of different chart types from the three chart question-answering benchmarks is summarized in table 1.</p>, <p>ChartT5 is an extension of the existing V+L Pre-training framework, VLT5 (Cho et al., 2021), an encoder-decoder architecture that unifies the vision-language tasks as text generation conditioned on multi-modal inputs. Given a chart image, we first extract the scene texts. For the synthetic chart images that are collected from DVQA (Kafle</p>, <p>\\begin{table}\n",
      "\\begin{tabular}{l|c c c|c} \\hline \\hline Type &amp; PlotQA &amp; DVQA &amp; FigureQA &amp; Total \\ \\hline Bar &amp; 142,587 &amp; 204,514 &amp; 40,000 &amp; 387,101 \\ Line &amp; 48,133 &amp; 0 &amp; 40,000 &amp; 88,133 \\ Pie &amp; 0 &amp; 0 &amp; 20,001 &amp; 20,001 \\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: Distribution of the three chart types: bar, line, and pie from different resources in the pre-training corpus.</p>, <p>Figure 2: An Overview of ChartT5. Given the input chart image and the extracted OCR tokens, ChartT5 predicts the masked values of the table in the output.\n",
      "et al., 2018), FigureQA (Kahou et al., 2018), and PlotQA (Methani et al., 2020), the ground-truth scene texts are available. The visual context is then represented as combining visual features extracted from the chart image and the language features obtained on the detected scene text. We then flat the paired table of the chart image into a string and extract the text features via the language encoder. The multi-modal features are then concatenated and fused via the multi-layer encoder, and the output hidden vectors can then be used for various pre-training tasks.</p>, <h4>3.2.1 Chart Image Encoder</h4>, <p>Footnote 1: These 15 categories are: Legends, yAxisTitle, ChartTitle, xAxisTitle, LegendPreview, PlotArea, yAxisLabel, xAxisLabel, LegendLabel, PieLabel, bar, pie, pieSlice, line, and dotLine.</p>, <h4>3.2.2 OCR Encoder</h4>, <p>After extracting the list of OCR words from the chart image, we obtain a set of OCR text embeddings (\\mathbf{o}={o_{1},o_{2},\\cdots,o_{l^{o}}}) via a learned word embedding layer. We also get each OCR token's 5-d position vector similar to the visual position vector from the OCR token's detected bounding box. We then obtain the position embedding vector using the shared projecting layer from the Chart Image Encoder. The shared position encoding mechanism between OCR tokens and chart object regions would help the model to capture their relative positional relations, which is a critical clue to predict the table data from the chart image. For example, the bar associated with an x-axis label should share a similar x-coordinate position in a vertical bar chart. The final OCR embedding vector is gained by summing up the OCR text token embeddings and the OCR position embedding.</p>, <h4>3.2.3 Language Encoder</h4>, <p>Following the setting of the original VLT5 (Cho et al., 2021), we add a prefix to the flattened underlying table to indicate different pre-training tasks. We then get the table token embeddings (\\mathbf{t}={t_{1},t_{2},\\cdots,t_{l^{t}}}) with a shared word embedding layer. We apply the original T5's (Raffel et al., 2020) relative position bias to obtain the position information of each token in the caption and the flattened table. We know that the tables have very different structures compared to natural language captions, and several efforts are exploring specialized position embeddings for tables (Yin et al., 2020; 1). We leave the exploration of the specialized table position embedding for chart table pre-training in the future.</p>, <p>Given the chart-table pairs, we propose Masked Header Prediction (MHP) and Masked Value Prediction (MHP) to teach the model to recover incomplete tables with the chart information. Specifically, this objective aims to predict a masked table token (t_{m}) with the remaining table info (t_{\\backslash m}) as well as the chart image region (\\mathbf{v}) and the scene text (\\mathbf{o}). Compared to the traditional masked language modeling applied to the natural language text, we adjust the table masking strategy based on two hypotheses: (1) We alternatively mask just the table headers or numerical table values, as we think interpreting these two types of information requires different skills. Predicting table headers requires retrieving the correct scene text, while predicting numerical table values depends more on the capability to conduct mathematic reasoning over both the visual elements and the scene text. Therefore, it is better to format them as two separate pre-training objectives. (2) We increase the masking rate from 15(\\%) to 45(\\%), as the masked table token has less dependence on the surrounding table values.</p>, <p>In this section, we first introduce the dataset for pre-training. We then go over our ChartT5 model architecture and pre-training objectives to predict masked tables from the chart and OCR information.</p>, <h3>Pre-training Dataset Collection</h3>, <h3>Model Overview</h3>, <h3>Pre-training Objectives</h3>]\n",
      "------------------------------\n",
      "h2 4 Experiment\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 5\n",
      "p\n",
      "In this section, We detailed our experiment setups to evaluate the proposed ChartT5 on two tasks: chart question answering and chart summarization. We then introduce the main results of the two evaluation tasks. Finally, we present the ablation study on chart-table pre-training and the two pre-training objectives.\n",
      "p\n",
      "We also applied warming-up for downstream fine-tuning to gradually increase the learning rate to the pick value during the first 5(\\%) of training epochs. After that, a linear decayed learning-rate scheduler gradually drops the learning rate for the remaining training. For CQA task, we set batch size as 24 and fine-tune ChartT5 for 60 epochs with a peak learning rate 2e-4 on 2 Nvidia TITAN RTX GPUs. The best checkpoint was saved as the one that achieves the highest accuracy on the validation\n",
      "split. On the CS task, we use batch size 20 and a peak learning rate 5e-5. On the Pew split, we fine-tune ChartT5for 20 epochs, and on Statista, we fine-tune ChartT5for 25 epochs. The best checkpoint is also saved as achieving the best BLEU score on the validation split. All the reported numbers are one-time runs.\n",
      "h3\n",
      "Main Results\n",
      "h3\n",
      "Ablation Study\n",
      "h3\n",
      "Qualitative Error Analysis\n",
      "[<p>We first compare ChartT5 to various state-of-the-art methods with or without pre-training on the two downstream tasks.</p>, <h4>4.1.1 Evaluation on CQA</h4>, <h4>4.1.2 Evaluation on Chart Summarization</h4>, <p>For the chart summarization task, we compare ChartT5 to the best non-pretraining approaches introduced in (Kantharaj et al., 2022). Given a chart image, The authors build the chart summarization models by extending the pre-trained language generation model T5 (Raffel et al., 2020) and BART(Lewis et al., 2019) whose generation processes are conditioned on: (1) a set of scene texts extracted by a trained OCR detector. (2) the ground truth table that is paired with the chart. The evaluation result is summarized in Table 3.</p>, <p>From Table 3, we can see that on Statista, ChartT5 outperforms all baseline methods on BLUE score, but only a slight improvement is achieved over the best baseline. On Pew, ChartT5 underperforms T5-OCR by almost 1.5 percent. The proposed ChartT5 also slightly underperforms against the baseline methods in CIDER on both datasets. However, ChartT5 consistently outperforms all baselines on content selection scores</p>, <p>We conduct ablation experiments to validate the effectiveness of chart-table pre-training and the pre-training objectives. We also evaluate the effectiveness of the proposed scene text copy mechanism.</p>, <h4>4.2.1 Chart-Table Pre-training</h4>, <p>We conduct detailed analyses on the effectiveness of chart-table pre-training. First, we measure the performance gain from the chart-table pre-training on the full test set of ChartQA data. We then study what type of questions benefit most from the chart-table pre-training by picking three subsets of questions that measure different capabilities of the model: (1) Human-written questions, (2) Machine-generated questions, and (3) Table covered questions, where the answers can be directly found in the ground truth tables. The results are summarized in Table 4. From Table 4, we find that after chart-table pre-training the model's performance on these three sets of questions is all improved. The most significant gain is obtained on machine-generated questions, which mainly focus on extractive-type questions. This indicates that chart-table pre-training benefits the model to localize and retrieve the requested information presented on Chart Image. The second biggest gain is achieved on table-cover questions, where the model demonstrates significant improvement in the capability of chart-to-table interpretation.</p>, <h4>4.2.2 Pre-training Objectives</h4>, <p>We validate the effectiveness of the two pre-training objectives, Masked Header Prediction and Masked Value Prediction. We remove one pre-training objective at a time and pre-train the ChartTSwith only one table prediction task. The pre-trained model</p>, <p>\\begin{table}\n",
      "\\begin{tabular}{l|c c c} \\hline \\hline  &amp; \\multicolumn{3}{c}{Question Types} \\  &amp; Human &amp; Augment &amp; Overall \\ \\hline Full &amp; 31.8 &amp; 74.4 &amp; 53.1 \\ - MVP &amp; 30.9 &amp; 73.7 &amp; 52.3 \\ - MHP &amp; 31.2 &amp; 68.3 &amp; 49.7 \\ - STC &amp; 30.8 &amp; 72.4 &amp; 51.6 \\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 5: Ablation Study on the two proposed pre-training objectives and the Scene Text Copy Mechanism (STC). The first row is the result of the full ChartT5 model. Then we remove one of the pre-training objectives and the scene-text-copy mechanism. We report the results of different ablation experiments on both human and machine-generated splits as well as the overall performance.\n",
      "is then fine-tuned and evaluated on the human and augmented split for comparison. The result is displayed in table 5. As can be seen from the table, removing Masked Value Prediction Loss has a negligible impact on the performance of ChartT5 on ChartQA dataset. There is a slightly more drop in human written questions which suggests that predicting table numerical values still has a miner positive impact on helping the model's mathematical reasoning. Remove Masked Header Prediction have a significant impact on the machine-generated question-answering accuracy. As expected, Masked header modeling mainly helps the model learn how to link the scene text to the table headers, which is a critical ability to extract relevant information given a specific query.</p>, <h4>4.2.3 Scene Text Copy</h4>, <p>We also validate the effectiveness of the scene-text-copy mechanism, where we train a ChartT5model by simply representing OCR tokens in their original text format. The model is fine-tuned and evaluated on the human and augmented split of the chartQA dataset to compare against the full ChartT5. The result is displayed in Table 5. Disabling the scene-text-copy mechanism leads to a 1.5(\\%) overall performance drop on ChartQA tasks. Specifically, it leads to more degradation on the augmented split than the human split, as scene-text-copy helps enhance the alignment between OCR and table values to benefit accurate information extraction from the chart.</p>, <p>We have manually analyzed model predictions to understand its limitation. We found that our model suffers most from noisy OCR detection and complex question that requires multi-hop reasoning.</p>, <p>In this section, We detailed our experiment setups to evaluate the proposed ChartT5 on two tasks: chart question answering and chart summarization. We then introduce the main results of the two evaluation tasks. Finally, we present the ablation study on chart-table pre-training and the two pre-training objectives.</p>, <p>We also applied warming-up for downstream fine-tuning to gradually increase the learning rate to the pick value during the first 5(\\%) of training epochs. After that, a linear decayed learning-rate scheduler gradually drops the learning rate for the remaining training. For CQA task, we set batch size as 24 and fine-tune ChartT5 for 60 epochs with a peak learning rate 2e-4 on 2 Nvidia TITAN RTX GPUs. The best checkpoint was saved as the one that achieves the highest accuracy on the validation\n",
      "split. On the CS task, we use batch size 20 and a peak learning rate 5e-5. On the Pew split, we fine-tune ChartT5for 20 epochs, and on Statista, we fine-tune ChartT5for 25 epochs. The best checkpoint is also saved as achieving the best BLEU score on the validation split. All the reported numbers are one-time runs.</p>, <h3>Main Results</h3>, <h3>Ablation Study</h3>, <h3>Qualitative Error Analysis</h3>]\n",
      "------------------------------\n",
      "h2 5 Conclusion\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 3\n",
      "p\n",
      "We propose ChartT5 to enhance the vision language model's ability to understand chart images via chart-table pre-training. The model learns to interpret the masked tables via our proposed masked header prediction and masked value prediction objectives. ChartT5 achieves significant improvement over table-based non-pretraining SOTA methods on the ChartQA dataset, especially on the extractive question sets. We also achieve a new SOTA Content Selection Score on the Chart-to-text summarization dataset. We conduct comprehensive ablation studies to identify the impact of chart-table pre-training, and we find that the proposed pre-training is extremely helpful to extract accurate\n",
      "p\n",
      "Figure 4: An error prediction from our model due to complex multi-hop reasoning\n",
      "p\n",
      "Figure 3: An error prediction from our model due to noisy OCR prediction\n",
      "information from the Chart. For future research directions, we believe it may also be meaningful to explore chart understanding under data-efficient settings Hsu et al. (2022); Zeng et al. (2023) and for evidence retrieval tasks Lu et al. (2022); Ji et al. (2023).\n",
      "[<p>We propose ChartT5 to enhance the vision language model's ability to understand chart images via chart-table pre-training. The model learns to interpret the masked tables via our proposed masked header prediction and masked value prediction objectives. ChartT5 achieves significant improvement over table-based non-pretraining SOTA methods on the ChartQA dataset, especially on the extractive question sets. We also achieve a new SOTA Content Selection Score on the Chart-to-text summarization dataset. We conduct comprehensive ablation studies to identify the impact of chart-table pre-training, and we find that the proposed pre-training is extremely helpful to extract accurate</p>, <p>Figure 4: An error prediction from our model due to complex multi-hop reasoning</p>, <p>Figure 3: An error prediction from our model due to noisy OCR prediction\n",
      "information from the Chart. For future research directions, we believe it may also be meaningful to explore chart understanding under data-efficient settings Hsu et al. (2022); Zeng et al. (2023) and for evidence retrieval tasks Lu et al. (2022); Ji et al. (2023).</p>]\n",
      "------------------------------\n",
      "h2 6 Limitations\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 1\n",
      "p\n",
      "Although introducing chart value prediction objective, it only provides minor improvement to the model's performance on doing complex reasoning. There is still a large room to improve the model's capability in math calculation. Our model also suffers from the noisy OCR prediction of off-the-shelf object detector, whose performance will depend highly on the extracted OCR text qualities. Another possible limitation of our approach is the quality of the pre-training data, which only contains synthetic images. Although the proposed model works fairly well on the ChartQA dataset, it is unclear if the improved performance can be generalized to other realistic chart images.\n",
      "[<p>Although introducing chart value prediction objective, it only provides minor improvement to the model's performance on doing complex reasoning. There is still a large room to improve the model's capability in math calculation. Our model also suffers from the noisy OCR prediction of off-the-shelf object detector, whose performance will depend highly on the extracted OCR text qualities. Another possible limitation of our approach is the quality of the pre-training data, which only contains synthetic images. Although the proposed model works fairly well on the ChartQA dataset, it is unclear if the improved performance can be generalized to other realistic chart images.</p>]\n",
      "------------------------------\n",
      "h2 7 Ethics Statement\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 1\n",
      "p\n",
      "When we collect the pre-training dataset, we ensure we respect the intellectual property of dataset sources. All the ChartQA dataset we used for the collection of chart-table pairs allows public access for research. To ensure the reproducibility of our experiment results, we provide details of the hyperparameter setting in our paper, and we will also publish our code later. Our models can mislead the public's understanding of chart content due to the potential bias from our training corpus. Therefore, we don't recommend using our model for any real-world decision on chart images.\n",
      "[<p>When we collect the pre-training dataset, we ensure we respect the intellectual property of dataset sources. All the ChartQA dataset we used for the collection of chart-table pairs allows public access for research. To ensure the reproducibility of our experiment results, we provide details of the hyperparameter setting in our paper, and we will also publish our code later. Our models can mislead the public's understanding of chart content due to the potential bias from our training corpus. Therefore, we don't recommend using our model for any real-world decision on chart images.</p>]\n",
      "------------------------------\n",
      "h2 Acknowledgement\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "Num children: 1\n",
      "p\n",
      "This research work is supported by U.S DARPA SemaFor Program No. HR001120C0123. The views and conclusions contained in this work only belong to the authors and should not represent the official policies implied by DARPA or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. We also thank Ahmed Masry and Shankar Kantharaj for providing us with ChartQA and Chart Summary-related data and baseline model outputs.\n",
      "[<p>This research work is supported by U.S DARPA SemaFor Program No. HR001120C0123. The views and conclusions contained in this work only belong to the authors and should not represent the official policies implied by DARPA or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. We also thank Ahmed Masry and Shankar Kantharaj for providing us with ChartQA and Chart Summary-related data and baseline model outputs.</p>]\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "src.custom_md2py.TreeOfContents"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test md2py\n",
    "idx = 0 # has title\n",
    "# [Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks]\n",
    "idx = 14 # has sections\n",
    "# [Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs,\n",
    "#  Abstract,\n",
    "#  Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over (8\\%) performance gains.,\n",
    "#  1 Introduction,\n",
    "#  2 Related Work,\n",
    "#  3 Method,\n",
    "#  4 Experiment,\n",
    "#  5 Conclusion,\n",
    "#  6 Limitations,\n",
    "#  7 Ethics Statement,\n",
    "#  Acknowledgement]\n",
    "\n",
    "sample = df.iloc[idx][\"markdown\"]\n",
    "toc = md2py(sample)\n",
    "toc.branches\n",
    "for child in toc.branches:\n",
    "    print(child.name, child.string)\n",
    "    print(\"Depth:\",child.depth)\n",
    "    print(\"Heading:\",TreeOfContents.getHeadingLevel(child))\n",
    "    print(\"Num children:\", len(child.branches))\n",
    "    for subchild in child.branches:\n",
    "        print(subchild.name)\n",
    "        print(subchild.string)\n",
    "    print(child.expandDescendants(child))\n",
    "    \n",
    "    print('-'*30)\n",
    "type(toc.branches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over \\(8\\%\\) performance gains.\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Chart figures serve as the visual summary of tabular data, which helps to convey rich context in various documents, such as scientific papers, textbooks, and technical news. An intelligent agent that can understand and communicate chart plots can lead to many useful applications. For example, a virtual doctor who knows how to answer the patient's question on a complex medical report or a reading assistant who can summarize the key findings from scientific papers in brief language. In the past few years, there has been a growing interest in our community to explore chart understanding in vision and language (V+L) tasks and many related benchmarks like Chart Question Answering **(CQA)**Masry et al. (2022); Kafle et al. (2018); Methani et al. (2020) and Chart Summarization **(CS)**Kantharaj et al. (2022) are introduced.\n",
      "\n",
      "While prevalent in the research community, automatic chart understanding remains a challenging problem due to its complex compositions of various shapes, lines, colors, and scene text. Although tremendous success is achieved in the V+L research, applying these existing methods to handle chart-related tasks is hard. Recent research ChartQA Masry et al. (2022) and Chart-to-Text Kantharaj et al. (2022) attempt to first convert chart images to their underlined tables and use the extracted tables to perform chart-related V+L task. As the extracted tables always have clean and organized structures, it makes extracting relevant information to solve downstream reasoning tasks much more accessible. Empirically, using tables yields promising results on both CQA and CS.\n",
      "\n",
      "Despite valuing table as a significant ingredient for chart understanding, we have two main concerns about this approach: (1) Automatic table extraction is unreliable. Existing methods Luo et al. (2021); Kato et al. (2022) are often limited to work on a few particular types of chart images and do not generalize well. Moreover, the extracted table is likely to contain incorrect noisy predictions that potentially harm the performance of the following task. (2) In most cases, the whole table is optional for resolving the chart-related V+L task. As illus\n",
      "\n",
      "Figure 1: A data sample from the ChartQA dataset. The corresponding chart table is displayed in the top right corner.\n",
      "trated in Fig 1, to answer the question _\"What is the value of India Bar\"_, the model just needs access to the second row to give the correct answer. In contrast, having redundant table information makes finding the relevant information challenging. To better leverage the table data, we argue that it is important to equip the V+L model with the capability to dynamically interpret the table value from the chart information.\n",
      "\n",
      "Therefore, in this paper, we propose **ChartT5**, an OCR-based image-to-text generation model pre-trained on a self-collected chart table pairs corpus. More specifically, ChartT5 learns how to uncover a masked table with two proposed pre-training objectives: Masked Header Prediction (MHP), and Masked Value Prediction (MVP). MHP helps improve the model's capability of linking scene text to the corresponding table headers. MVP requires the model to perform mathematical reasoning over chart structure units and the scene text to predict the correct data value.\n",
      "\n",
      "We evaluate our ChartT5 on two tasks and benchmarks: ChartQA and Chart-to-Text. In ChartQA, ChartT5 outperforms all the non-pretraining methods that use extracted tables by at least \\(8\\%\\) performance gains. ChartT5 also beats the pre-training table-based methods, which demonstrates the effectiveness of the proposed pre-training strategies. On Chart-to-Text, ChartT5 consistly outperforms the existing SOTA on the content selection metrics Barzilay and Lapata (2005) which values the model's capability to extract the critical information from the chart.\n",
      "\n",
      "In summary, our contributions are summarized below:\n",
      "\n",
      "* We propose chart-to-table pre-training for V+L model to learn the capability of interpreting table data from the chart.\n",
      "* We demonstrate that the pre-trained model consistently outperforms table-based methods on two chart understanding tasks.\n",
      "* We conduct comprehensive ablation studies to validate the effectiveness of chart-to-table pre-training and the proposed pre-training objectives.\n",
      "\n",
      "## 2 Related Work\n",
      "\n",
      "### Vision and Language Research on Charts\n",
      "\n",
      "Researching chart understanding in V+L tasks is a popular field nowadays. The most prevalent problem is chart question answering (CQA) Kafle et al. (2018); Kahou et al. (2018); Methani et al. (2020); Masry et al. (2022); Chaudhry et al. (2020), where researchers build models to answer complex questions on chart images. Another popular one is chart summarization (CS) Kantharaj et al. (2022); Obeid and Hoque (2020), which requires machine learning models to create a summary of key insights conveyed by a chart. Hsu et al. (2021) collected a large-scale scientific figures captioning dataset from research papers where many images are chart plots.\n",
      "\n",
      "There are two main approaches for chart vision and language tasks. The first approach adapts existing visual question answering (VQA) and image captioning models to CQA and CS tasks with some specialized designs for chart images Kafle et al. (2020); Singh and Shekhar (2020); Chaudhry et al. (2020); Kafle et al. (2018); Hsu et al. (2021); Spreafico and Carenini (2020). The other approach assumes the table data of charts is accessible from the dataset Kim et al. (2020); Masry (2021) or can be extracted from the chart images using vision to table techniques Methani et al. (2020); Masry et al. (2022); Kantharaj et al. (2022). Then, the researchers will either use a table-to-text generation model Kim et al. (2020); Masry (2021); Methani et al. (2020) or combine the embedding of tables and charts via a multi-modal fusion method to generate the text output Masry et al. (2022); Kantharaj et al. (2022). It is clear from these efforts that adding tables as the additional representation of charts will dramatically improve the model's capability to understand and interpret chart information.\n",
      "\n",
      "Following the table-based approach, we also value the information provided by the underlined table data of chart images. However, instead of directly concatenating the extracted table into the chart understanding model, we facilitate our model with the capability to interpret the table data from chart images via pre-training on chart-table pairs.\n",
      "\n",
      "### Vision and Language Pre-training\n",
      "\n",
      "Vision and language pre-training has received growing interest over the past few years. Researchers build transformer-based multi-modal fusion models and perform self-supervised learning on a large-scale corpus of image-text pairs to learn robust cross-modal representations that can benefit the performance of various downstream tasks Chen et al. (2020); Lu et al. (2019); Tan and Bansal (2019);\n",
      "Su et al., 2019; Li et al., 2020; Zhang et al., 2021).\n",
      "\n",
      "While the pre-trained models achieve great success on tasks like VQA (Antol et al., 2015) and Image Captioning (Chen et al., 2015), they have only focused on the domain of natural images. However, chart understanding is still challenging for the existing vision and language methods due to their lack of knowledge of scene text and structured visual units such as \"bars\" and \"lines\".\n",
      "\n",
      "To address the limitation of conventional vision and language pre-training, TAP (Yang et al., 2021) and PreSTU (Kil et al., 2022) propose OCR-based vision and language pre-training frameworks that focus on scene text understanding in natural images where they design various pre-training objectives around the extracted OCR texts. Most recently, Donut (Kim et al., 2022) and Pix2Struct (Lee et al., 2022) propose OCR-free pre-training frameworks, where the pre-trained model directly generates a text output from a raw image input. Donut focuses on document image (_e.g._, receipt) understanding, and Pix2Struct aims to handle broader types of synthetic images that contain visually-situated texts such as infographics and user interfaces via parsing web-page screenshots into their HTML Code. Different from these works, we take the first step to explore vision and language pre-training that focuses on chart image understanding. Specifically, we propose novel pre-training objectives to parse charts to their underlined tables.\n",
      "\n",
      "## 3 Method\n",
      "\n",
      "In this section, we first introduce the dataset for pre-training. We then go over our ChartT5 model architecture and pre-training objectives to predict masked tables from the chart and OCR information.\n",
      "\n",
      "### Pre-training Dataset Collection\n",
      "\n",
      "To collect large-scale pairs of chart-table data, we collect synthetic data from existing chart question-answering corpora, including PlotQA (Methani et al., 2020), DVQA (Kafle et al., 2018), and FigureQA (Kahou et al., 2018). Specifically, DVQA and FigureQA render chart images from synthetic tables that are randomly generated from limited vocabularies. PlotQA first scrapes tables from online resources like World Bank Open Data and then synthesizes the charts from the scraped data, where the tables and charts contain more diverse language information. Our pre-training corpus consists of 495K chart-table pairs, which cover a diverse range of chart types. Our pre-training corpus contains three chart types: bar, line, and pie. The distribution of different chart types from the three chart question-answering benchmarks is summarized in table 1.\n",
      "\n",
      "### Model Overview\n",
      "\n",
      "ChartT5 is an extension of the existing V+L Pre-training framework, VLT5 (Cho et al., 2021), an encoder-decoder architecture that unifies the vision-language tasks as text generation conditioned on multi-modal inputs. Given a chart image, we first extract the scene texts. For the synthetic chart images that are collected from DVQA (Kafle\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c c c|c} \\hline \\hline Type & PlotQA & DVQA & FigureQA & Total \\\\ \\hline Bar & 142,587 & 204,514 & 40,000 & 387,101 \\\\ Line & 48,133 & 0 & 40,000 & 88,133 \\\\ Pie & 0 & 0 & 20,001 & 20,001 \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: Distribution of the three chart types: bar, line, and pie from different resources in the pre-training corpus.\n",
      "\n",
      "Figure 2: An Overview of ChartT5. Given the input chart image and the extracted OCR tokens, ChartT5 predicts the masked values of the table in the output.\n",
      "et al., 2018), FigureQA (Kahou et al., 2018), and PlotQA (Methani et al., 2020), the ground-truth scene texts are available. The visual context is then represented as combining visual features extracted from the chart image and the language features obtained on the detected scene text. We then flat the paired table of the chart image into a string and extract the text features via the language encoder. The multi-modal features are then concatenated and fused via the multi-layer encoder, and the output hidden vectors can then be used for various pre-training tasks.\n",
      "\n",
      "#### 3.2.1 Chart Image Encoder\n",
      "\n",
      "Given an input chart image, to recognize the critical marks (_e.g._, bars and lines) of chart images, we first utilize a pre-trained Mask R-CNN object detector from (Masry et al., 2022) to extract the visual region features \\(\\mathbf{v}=\\{v_{1},v_{2},\\cdots,v_{l^{v}}\\}\\). Next, the chart object detector is trained on the synthetic chart images from the previous CQA datasets (Kahou et al., 2018; Kafle et al., 2018; Masry et al., 2022; Methani et al., 2020) which is defined to identify 15 chart-related objects1. For each detected object region, we also extract location features as a 5-d vector: \\([\\frac{x_{1}}{W},\\frac{y_{1}}{H},\\frac{x_{2}}{W},\\frac{y_{2}}{H},\\frac{(y_{2} -y_{1})(x_{2}-x_{1})}{W.H}]\\), which denotes the normalized top left coordinates, bottom right coordinates, and the normalized area of the detected region box. The position feature is then fed through fully-connected layers to be projected to the visual region feature embedding space. The final representation of the visual feature is obtained by summing up the projected region feature and corresponding location feature.\n",
      "\n",
      "Footnote 1: These 15 categories are: Legends, yAxisTitle, ChartTitle, xAxisTitle, LegendPreview, PlotArea, yAxisLabel, xAxisLabel, LegendLabel, PieLabel, bar, pie, pieSlice, line, and dotLine.\n",
      "\n",
      "#### 3.2.2 OCR Encoder\n",
      "\n",
      "After extracting the list of OCR words from the chart image, we obtain a set of OCR text embeddings \\(\\mathbf{o}=\\{o_{1},o_{2},\\cdots,o_{l^{o}}\\}\\) via a learned word embedding layer. We also get each OCR token's 5-d position vector similar to the visual position vector from the OCR token's detected bounding box. We then obtain the position embedding vector using the shared projecting layer from the Chart Image Encoder. The shared position encoding mechanism between OCR tokens and chart object regions would help the model to capture their relative positional relations, which is a critical clue to predict the table data from the chart image. For example, the bar associated with an x-axis label should share a similar x-coordinate position in a vertical bar chart. The final OCR embedding vector is gained by summing up the OCR text token embeddings and the OCR position embedding.\n",
      "\n",
      "#### 3.2.3 Language Encoder\n",
      "\n",
      "Following the setting of the original VLT5 (Cho et al., 2021), we add a prefix to the flattened underlying table to indicate different pre-training tasks. We then get the table token embeddings \\(\\mathbf{t}=\\{t_{1},t_{2},\\cdots,t_{l^{t}}\\}\\) with a shared word embedding layer. We apply the original T5's (Raffel et al., 2020) relative position bias to obtain the position information of each token in the caption and the flattened table. We know that the tables have very different structures compared to natural language captions, and several efforts are exploring specialized position embeddings for tables (Yin et al., 2020; 1). We leave the exploration of the specialized table position embedding for chart table pre-training in the future.\n",
      "\n",
      "**Scene Text Copy Mechanism.** A critical ingredient to the success of chart-to-table translation is the ability to predict the table headers from the corresponding OCR texts. For example, in the horizontal bar chart, the table column header is usually obtained from the x-axis labels, and the row header is often copied from the legend labels. Although presenting OCR text and the table to the model helps link the shared OCR tokens and table values, generating the correct table prediction from the corresponding OCR source is still challenging due to the large candidate token vocabulary. To encourage direct copy from the OCR text to the associated table cell value, we introduce OCR sentinel tokens \\(\\{<\\text{ocr\\_1}>,<\\text{ocr\\_2}>,\\cdots,<\\text{ocr\\_1}^{o}>\\}\\), which corresponds to the detected OCR texts. As illustrated in Figure 2, we replace each OCR token with a unique corresponding OCR sentinel token. Then, for every OCR token, we find if there is a matched existing table cell value. If a matched pair is found, we replace the table cell value with its paired OCR sentinel token. During pre-training, as all the plot images are synthesized from a paired table, the one-to-one scene text to table value mapping is already provided. With this prepossessing procedure, we successfully distinguish the table values that are copied from OCR tokens and those that need to be generated from the general token vocabularies, encouraging more accurate table pre\n",
      "diction from the relevant resources.\n",
      "\n",
      "### Pre-training Objectives\n",
      "\n",
      "Given the chart-table pairs, we propose Masked Header Prediction (MHP) and Masked Value Prediction (MHP) to teach the model to recover incomplete tables with the chart information. Specifically, this objective aims to predict a masked table token \\(t_{m}\\) with the remaining table info \\(t_{\\backslash m}\\) as well as the chart image region \\(\\mathbf{v}\\) and the scene text \\(\\mathbf{o}\\). Compared to the traditional masked language modeling applied to the natural language text, we adjust the table masking strategy based on two hypotheses: (1) We alternatively mask just the table headers or numerical table values, as we think interpreting these two types of information requires different skills. Predicting table headers requires retrieving the correct scene text, while predicting numerical table values depends more on the capability to conduct mathematic reasoning over both the visual elements and the scene text. Therefore, it is better to format them as two separate pre-training objectives. (2) We increase the masking rate from 15\\(\\%\\) to 45\\(\\%\\), as the masked table token has less dependence on the surrounding table values.\n",
      "\n",
      "## 4 Experiment\n",
      "\n",
      "In this section, We detailed our experiment setups to evaluate the proposed ChartT5 on two tasks: chart question answering and chart summarization. We then introduce the main results of the two evaluation tasks. Finally, we present the ablation study on chart-table pre-training and the two pre-training objectives.\n",
      "\n",
      "**Chart Question Answering.** Given a chart image and a query question, the goal for the model is to provide an accurate answer string by interpreting the provided chart image. For this task, we consider the ChartQA dataset Masry et al. (2022), which collects question-answer pairs on realistic chart images scraped from the internet. Their annotations are collected in two fashions: (1) Human-written question-answer pairs; and (2) machine-generated question-answer pairs derived from the human-written chart summaries. In total 32.7K question-answer pairs are collected on 21.9K scraped chart images, where about 9.6K question-and-answer pairs are human-written. Compared to the previously collected CQA datasets, ChartQA is more challenging to handle due to the diverse visual style from the realistic chart images and the complex language from human annotations. Following previous work Masry et al. (2022); Methani et al. (2020), we also apply the relaxed accuracy to measure the performance on the CQA task, which allows a minor inaccuracy on numerical value prediction (within 5\\(\\%\\) of the gold answer). For non-numerical answers, the prediction needs to be exactly matched to the gold-standard answer.\n",
      "\n",
      "**Chart Summarization.** Given a chart image, the target is to summarize the key insights of the chart in natural language. For this task, we evaluate our model on the most recently proposed Chart-to-Text benchmark Kantharaj et al. (2022), which collects roughly 36.5K chart images with one summary for each image. They split the collected charts into two sets: Statista and Pew, representing the two separate websites from which the chart plots come. The summaries in Statista are human-written which is well grounded on the chart image. Meanwhile, the summaries from Pew are automatically extracted from the news paragraphs surrounding the chart images. Pew is noisier and more challenging to handle. We follow Kantharaj et al. (2022) to split the two sets for training and testing. We adopt BLEU-4, Content Selection, and CIDER as the evaluation metrics to measure the quality of the generated summary following Kantharaj et al. (2022).\n",
      "\n",
      "**Implementation details.** We initialized our ChartT5 from T5\\({}_{\\text{base}}\\) and pre-trained on our self-collected corpus for 30 epochs with a batch size of 60. We used Adam optimizer Kingma and Ba (2015) with a linear warm-up for the first 5\\(\\%\\) training steps, and the peak learning rate is set as 1e-4. After warming up, a linear decayed learning-rate scheduler gradually drops the learning rate for the rest of the training steps. The pre-training experiments are conducted on 2 Nvidia TITAN RTX GPUs, and it roughly takes two days to accomplish the experiment. We kept the last checkpoint of each pre-training run as our final checkpoint for fine-tuning.\n",
      "\n",
      "We also applied warming-up for downstream fine-tuning to gradually increase the learning rate to the pick value during the first 5\\(\\%\\) of training epochs. After that, a linear decayed learning-rate scheduler gradually drops the learning rate for the remaining training. For CQA task, we set batch size as 24 and fine-tune ChartT5 for 60 epochs with a peak learning rate 2e-4 on 2 Nvidia TITAN RTX GPUs. The best checkpoint was saved as the one that achieves the highest accuracy on the validation\n",
      "split. On the CS task, we use batch size 20 and a peak learning rate 5e-5. On the Pew split, we fine-tune ChartT5for 20 epochs, and on Statista, we fine-tune ChartT5for 25 epochs. The best checkpoint is also saved as achieving the best BLEU score on the validation split. All the reported numbers are one-time runs.\n",
      "\n",
      "### Main Results\n",
      "\n",
      "We first compare ChartT5 to various state-of-the-art methods with or without pre-training on the two downstream tasks.\n",
      "\n",
      "#### 4.1.1 Evaluation on CQA\n",
      "\n",
      "We compare ChartT5 with SOTA non-pretraining and pre-training methods on CQA tasks. The best-performed non-pretraining baselines are introduced in (Masry et al., 2022). The authors first predict the table data from the chart image via an automatic data extraction tool (Luo et al., 2021). Then they extend various language-only models (T5, Tapas) and multi-modal models (VLT5, VisionTapas) to predict the answer conditioned on the extracted table. On the line of pre-training baselines, we compare to VLT5\\({}_{pre}\\) and VisionTapas\\({}_{pre}\\) which pre-trains VLT5 and Vision Tapas on PlotQA with the visual question answering tasks. We also compare chartT5 to the current SOTA method Pix2Struct which is pre-trained on 80 million webpage screenshots to HTML code parsing objectives. The result is summarized in Table 2.\n",
      "\n",
      "**Comparison to Non-Pretraining Method** Even without access to the predicted tables, ChartT5 has outperformed all non-pretraining methods by a large margin (a minimum 7.3\\(\\%\\) gain on the overall performance). ChartT5 also outperforms all non-pretraining baselines on the human-written questions and machine-generated questions. Although the predicted table covers 54\\(\\%\\) of the answers in the test data of ChartQA, simply feeding it as an input does not make the existing models fully leverage the valuable information. The significant improvement achieved by ChartT5 indicates the effectiveness of the proposed pre-training to help the model to obtain the relevant table information for chart understanding.\n",
      "\n",
      "**Comparison to Pre-training Method** Although the performance of VLT5 and VisionTapas is improved significantly by pre-training on additional CQA data, ChartT5 still outperform them by at least 1.3\\(\\%\\). Specifically, on machine-augmented questions, ChartT5 outperforms VLT5\\({}_{pre}\\) by 8\\(\\%\\). However, both visionTapas\\({}_{pre}\\) and VLT5\\({}_{pre}\\) achieve better accuracy on the human split, which means that the in-domain question answering objectives helps the model to improve the numerical reasoning capability. ChartT5 underperforms Pix2Struct by 2.3\\(\\%\\) on the overall test split. However, pix2struct is pre-trained on a more than 100 times larger pre-training corpus than the rest of the pre-training methods. Given the same scale of the pre-training dataset, we expect to gain additional performance improvement, and we leave this for future exploration.\n",
      "\n",
      "#### 4.1.2 Evaluation on Chart Summarization\n",
      "\n",
      "For the chart summarization task, we compare ChartT5 to the best non-pretraining approaches introduced in (Kantharaj et al., 2022). Given a chart image, The authors build the chart summarization models by extending the pre-trained language generation model T5 (Raffel et al., 2020) and BART(Lewis et al., 2019) whose generation processes are conditioned on: (1) a set of scene texts extracted by a trained OCR detector. (2) the ground truth table that is paired with the chart. The evaluation result is summarized in Table 3.\n",
      "\n",
      "From Table 3, we can see that on Statista, ChartT5 outperforms all baseline methods on BLUE score, but only a slight improvement is achieved over the best baseline. On Pew, ChartT5 underperforms T5-OCR by almost 1.5 percent. The proposed ChartT5 also slightly underperforms against the baseline methods in CIDER on both datasets. However, ChartT5 consistently outperforms all baselines on content selection scores\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c c c} \\hline \\hline \\multirow{2}{*}{Model} & \\multicolumn{3}{c}{ChartQA} \\\\  & Human & Augment & Overall \\\\ \\hline T5 & 25.12 & 56.96 & 41.56 \\\\ Tapas & 28.72 & 53.84 & 41.28 \\\\ VLT5 & 26.24 & 56.88 & 41.56 \\\\ VisionTapas & 29.60 & 61.44 & 45.52 \\\\ \\hline VLT5\\({}_{pre}\\) & **40.08** & 63.60 & 51.84 \\\\ VisionTapas\\({}_{pre}\\) & 32.56 & 61.60 & 47.08 \\\\ Pix2Struct & - & - & **56.00** \\\\ ChartT5 & 31.8 & **74.4** & 53.16 \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 2: Evaluation results on ChartQA. We report relaxed accuracy on the test split annotated by humans and that generated by the machine. In the last column, we report the overall accuracy by computing the mean values with human split and augment split.\n",
      "across both Statista and Pew sets. The under-performance on BLEU and CIDER indicates that Chart-table pre-training is limited to benefit high-quality natural language generation. However, the strong performance on content selection, which values the key information appearance in the generation, suggests the advantage of chart-table pre-training on extracting relevant chart information. Therefore, a potential direction to explore is combining different types of pre-training objectives, such as chart-to-text pre-training and chart-table pre-training goals, to facilitate the model with diverse strengths.\n",
      "\n",
      "### Ablation Study\n",
      "\n",
      "We conduct ablation experiments to validate the effectiveness of chart-table pre-training and the pre-training objectives. We also evaluate the effectiveness of the proposed scene text copy mechanism.\n",
      "\n",
      "#### 4.2.1 Chart-Table Pre-training\n",
      "\n",
      "We conduct detailed analyses on the effectiveness of chart-table pre-training. First, we measure the performance gain from the chart-table pre-training on the full test set of ChartQA data. We then study what type of questions benefit most from the chart-table pre-training by picking three subsets of questions that measure different capabilities of the model: (1) Human-written questions, (2) Machine-generated questions, and (3) Table covered questions, where the answers can be directly found in the ground truth tables. The results are summarized in Table 4. From Table 4, we find that after chart-table pre-training the model's performance on these three sets of questions is all improved. The most significant gain is obtained on machine-generated questions, which mainly focus on extractive-type questions. This indicates that chart-table pre-training benefits the model to localize and retrieve the requested information presented on Chart Image. The second biggest gain is achieved on table-cover questions, where the model demonstrates significant improvement in the capability of chart-to-table interpretation.\n",
      "\n",
      "#### 4.2.2 Pre-training Objectives\n",
      "\n",
      "We validate the effectiveness of the two pre-training objectives, Masked Header Prediction and Masked Value Prediction. We remove one pre-training objective at a time and pre-train the ChartTSwith only one table prediction task. The pre-trained model\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c c c} \\hline \\hline \\multirow{2}{*}{Pretraining?} & \\multicolumn{3}{c}{Question Types} \\\\  & Table & Human & Augment \\\\ \\hline No & 60.7 & 30.8 & 66.7 \\\\ Yes & **64.7** & **31.8** & **74.4** \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 4: Ablation Study on Chart Table Pre-training with ChartQA Dataset. We report results on three subsets of questions: Table cover questions, human-written questions, and machine-generated questions.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c c c|c c c} \\hline \\hline \\multirow{2}{*}{Model} & \\multicolumn{3}{c|}{Statista} & \\multicolumn{3}{c}{Pew} \\\\  & BLEU & CS & CIDER & BLEU & CS & CIDER \\\\ \\hline T5-OCR & 35.29 & 73.77 & 4.43 & **10.49** & 40.87 & **2.20** \\\\ BART-OCR & - & - & - & 9.09 & 39.99 & 1.97 \\\\ T5-TAB & 37.01 & 75.72 & **4.68** & - & - & - \\\\ BART-TAB & 36.36 & 77.14 & 4.40 & - & - & - \\\\ ChartT5 & **37.51** & **82.16** & 3.45 & 9.05 & **55.1** & 1.23 \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 3: Evaluation results on Chart Summarization. We display BLEU, CS and CIDER scores for the Pew and Statista Split. The ground truth table is not available to Pew thus the table-based method does not have results on Pew split.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c c c} \\hline \\hline  & \\multicolumn{3}{c}{Question Types} \\\\  & Human & Augment & Overall \\\\ \\hline Full & 31.8 & 74.4 & 53.1 \\\\ - MVP & 30.9 & 73.7 & 52.3 \\\\ - MHP & 31.2 & 68.3 & 49.7 \\\\ - STC & 30.8 & 72.4 & 51.6 \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 5: Ablation Study on the two proposed pre-training objectives and the Scene Text Copy Mechanism (STC). The first row is the result of the full ChartT5 model. Then we remove one of the pre-training objectives and the scene-text-copy mechanism. We report the results of different ablation experiments on both human and machine-generated splits as well as the overall performance.\n",
      "is then fine-tuned and evaluated on the human and augmented split for comparison. The result is displayed in table 5. As can be seen from the table, removing Masked Value Prediction Loss has a negligible impact on the performance of ChartT5 on ChartQA dataset. There is a slightly more drop in human written questions which suggests that predicting table numerical values still has a miner positive impact on helping the model's mathematical reasoning. Remove Masked Header Prediction have a significant impact on the machine-generated question-answering accuracy. As expected, Masked header modeling mainly helps the model learn how to link the scene text to the table headers, which is a critical ability to extract relevant information given a specific query.\n",
      "\n",
      "#### 4.2.3 Scene Text Copy\n",
      "\n",
      "We also validate the effectiveness of the scene-text-copy mechanism, where we train a ChartT5model by simply representing OCR tokens in their original text format. The model is fine-tuned and evaluated on the human and augmented split of the chartQA dataset to compare against the full ChartT5. The result is displayed in Table 5. Disabling the scene-text-copy mechanism leads to a 1.5\\(\\%\\) overall performance drop on ChartQA tasks. Specifically, it leads to more degradation on the augmented split than the human split, as scene-text-copy helps enhance the alignment between OCR and table values to benefit accurate information extraction from the chart.\n",
      "\n",
      "### Qualitative Error Analysis\n",
      "\n",
      "We have manually analyzed model predictions to understand its limitation. We found that our model suffers most from noisy OCR detection and complex question that requires multi-hop reasoning.\n",
      "\n",
      "**Noisy OCR Prediction.** As an OCR-based model, ChartT5 often suffers from a wrong OCR detection. An example is shown in Figure 3; the model localizes the right scene text \"1.18\" to answer the question, but the OCR text is mistakenly detected as \"1:18\". To further understand the limitation of OCR detection, we randomly sample 20K PlotQA test split and compare the performance of our model using detected OCRs against Ground Truth OCRs. We observe a 5\\(\\%\\) performance drop when using detected OCRs. We can improve the OCR detector for future work by training on a large Plot scene-text detection benchmark. Another promising direction is to attempt OCR-free end-to-end plot recognition method like Pix2Struct (Lee et al., 2022).\n",
      "\n",
      "**Multi-Hop Reasoning.** Our model is also quite vulnerable to handling complex questions requiring multi-hop reasoning. An example is shown in Figure 4; the model cannot perform the complex logic reasoning to add the stats of the two smallest bars and compare that to the large bar. We will consider exploring pre-training on the mathematic reasoning datasets to address this limitation.\n",
      "\n",
      "## 5 Conclusion\n",
      "\n",
      "We propose ChartT5 to enhance the vision language model's ability to understand chart images via chart-table pre-training. The model learns to interpret the masked tables via our proposed masked header prediction and masked value prediction objectives. ChartT5 achieves significant improvement over table-based non-pretraining SOTA methods on the ChartQA dataset, especially on the extractive question sets. We also achieve a new SOTA Content Selection Score on the Chart-to-text summarization dataset. We conduct comprehensive ablation studies to identify the impact of chart-table pre-training, and we find that the proposed pre-training is extremely helpful to extract accurate\n",
      "\n",
      "Figure 4: An error prediction from our model due to complex multi-hop reasoning\n",
      "\n",
      "Figure 3: An error prediction from our model due to noisy OCR prediction\n",
      "information from the Chart. For future research directions, we believe it may also be meaningful to explore chart understanding under data-efficient settings Hsu et al. (2022); Zeng et al. (2023) and for evidence retrieval tasks Lu et al. (2022); Ji et al. (2023).\n",
      "\n",
      "## 6 Limitations\n",
      "\n",
      "Although introducing chart value prediction objective, it only provides minor improvement to the model's performance on doing complex reasoning. There is still a large room to improve the model's capability in math calculation. Our model also suffers from the noisy OCR prediction of off-the-shelf object detector, whose performance will depend highly on the extracted OCR text qualities. Another possible limitation of our approach is the quality of the pre-training data, which only contains synthetic images. Although the proposed model works fairly well on the ChartQA dataset, it is unclear if the improved performance can be generalized to other realistic chart images.\n",
      "\n",
      "## 7 Ethics Statement\n",
      "\n",
      "When we collect the pre-training dataset, we ensure we respect the intellectual property of dataset sources. All the ChartQA dataset we used for the collection of chart-table pairs allows public access for research. To ensure the reproducibility of our experiment results, we provide details of the hyperparameter setting in our paper, and we will also publish our code later. Our models can mislead the public's understanding of chart content due to the potential bias from our training corpus. Therefore, we don't recommend using our model for any real-world decision on chart images.\n",
      "\n",
      "## Acknowledgement\n",
      "\n",
      "This research work is supported by U.S DARPA SemaFor Program No. HR001120C0123. The views and conclusions contained in this work only belong to the authors and should not represent the official policies implied by DARPA or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. We also thank Ahmed Masry and Shankar Kantharaj for providing us with ChartQA and Chart Summary-related data and baseline model outputs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
