{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(os.path.join(settings.data_dir, \"arxiver/data/train.parquet\"))\n",
    "# ## Sample 10k\n",
    "# df = df.sample(10000)\n",
    "# print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7) Index(['id', 'title', 'abstract', 'authors', 'published_date', 'link',\n",
      "       'markdown'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# df.to_parquet(\"sample.parquet\", index = None)\n",
    "df = pd.read_parquet(\"sample.parquet\")\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Splitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1. custom implementation\n",
    "* stack-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "This paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\(H_{2}\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.\n",
      "\n",
      "## I Introduction\n",
      "\n",
      "For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\(Q\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.\n",
      "\n",
      "Hence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.\n",
      "\n",
      "This paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.\n",
      "\n",
      "It is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\n",
      "the neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.\n",
      "\n",
      "Hence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\(H_{2}\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.\n",
      "\n",
      "## II Preliminaries\n",
      "\n",
      "We consider a nonlinear autonomous system:\n",
      "\n",
      "\\[\\dot{x}(t)=f(x(t)),\\quad y(t)=h(x(t)) \\tag{1}\\]\n",
      "\n",
      "where \\(x(t)\\in\\mathcal{X}\\subseteq\\mathbb{R}^{n}\\) is the vector of states and \\(y(t)\\in\\mathbb{R}^{m}\\) represents the outputs. For simplicity, we will consider \\(m=1\\). It is assumed that \\(f\\) and \\(h\\) are smooth on \\(\\mathcal{X}\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.\n",
      "\n",
      "### _KKL Observer_\n",
      "\n",
      "For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\n",
      "\n",
      "\\[\\dot{z}(t)=Az(t)+By(t),\\quad\\hat{x}(t)=T^{\\dagger}(z(t)). \\tag{2}\\]\n",
      "\n",
      "Here the observer states \\(z\\in\\mathbb{R}^{n_{z}}\\) has an LTI dynamics. The matrices \\(A\\) and \\(B\\) are chosen under the requirements of (i) controllability of \\((A,B)\\) should be controllable, (ii) Hurwitz property of \\(A\\), and (iii) sufficiently high dimension of \\(z\\) (\\(n_{z}\\)), which should be at least \\(n+1\\) if \\((A,B)\\) is complex [17] and at least \\(2n+1\\) if \\((A,B)\\) is real [29]. The mapping from the observer states \\(z\\) to the state estimates \\(\\hat{x}\\) is a static one, \\(T^{\\dagger}\\), which is the left-pseudoinverse of a nonlinear immersion \\(T\\) (i.e., a differentiable injection satisfying \\(T^{\\dagger}\\circ T=\\mathsf{id}\\)). This immersion \\(T\\) should satisfy the following PDE:\n",
      "\n",
      "\\[\\frac{\\partial T}{\\partial x}(x)f(x)=AT(x)+Bh(x),\\quad\\forall x\\in\\mathcal{X}, \\tag{3}\\]\n",
      "\n",
      "where \\(\\partial T/\\partial x\\) denotes the Jacobian matrix of \\(T\\). It can be easily verified that under the above PDE, \\(dT(x)/dt=AT(x)+By\\), and thus \\(z-T(x)\\) has an exponentially decaying dynamics, as \\(A\\) is Hurwitz.\n",
      "\n",
      "The conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\(\\dot{x}=f(x)\\) at time \\(t\\) with initial condition \\(x(0)=\\xi\\) as \\(\\Phi_{t}(\\xi)\\). For any open set \\(\\mathcal{O}\\) in \\(\\mathcal{X}\\), denote the backward time instant after which the solution does not escape this region by \\(\\varsigma_{\\mathcal{O}}(\\xi)=\\inf\\{t|\\Phi_{t}(\\xi)\\in\\mathcal{O}\\}\\). Also denote \\(\\mathcal{O}+\\epsilon:=\\{\\xi+\\eta|\\xi\\in\\mathcal{O},\\|\\eta\\|<\\epsilon\\}\\).\n",
      "\n",
      "**Definition 1** (Backward distinguishability).: _The system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable if for any distinct \\(\\xi,\\xi^{\\prime}\\in\\mathcal{X}\\) there exists a negative \\(t>\\varsigma_{\\mathcal{O}+\\epsilon}(\\xi)\\wedge\\varsigma_{\\mathcal{O}+\\epsilon} (\\xi^{\\prime})\\) such that \\(h(\\Phi_{t}(\\xi))\\neq h(\\Phi_{t}(\\xi^{\\prime}))\\)._\n",
      "\n",
      "**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\(\\mathcal{O}\\subseteq\\bar{\\mathcal{X}}\\) and a positive constant \\(\\epsilon\\) such that the system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable. Then there exists a constant \\(\\rho>0\\) such that for all but a Lebesgue-zero-measure set of \\((A,B)\\in\\mathbb{R}^{(2n+1)\\times(2n+1)}\\times\\mathbb{R}^{(2n+1)}\\), if \\(A+\\rho I\\) Hurwitz, then there exists an immersion \\(T:\\mathcal{O}\\rightarrow\\mathbb{R}^{(2n+1)}\\) solving the PDEs (3)._\n",
      "\n",
      "The above theorem clarifies that as long as the spectrum of \\(A\\) is restricted to the left of \\(-\\rho+i\\mathbb{R}\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\((A,B)\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\(T^{\\dagger}\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.\n",
      "\n",
      "### _Lipschitz-Bounded Neural Networks_\n",
      "\n",
      "Consider a \\(\\nu\\)-layer neural network \\(\\hat{x}=S(z,\\theta)\\) with all parameters denoted as a single vector \\(\\theta\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\(\\sigma:\\mathbb{R}\\rightarrow\\mathbb{R}\\), with slope bounded in \\([0,1]\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\n",
      "\n",
      "\\[\\begin{split}& z^{\\ell+1}=\\sigma(W^{\\ell}z^{\\ell}+b^{\\ell}),\\ \\ \\ell=0,\\ldots,\\nu-1\\\\ & z^{0}=z,\\quad\\hat{x}=W^{\\nu}z^{\\nu}+b^{\\nu}.\\end{split} \\tag{4}\\]\n",
      "\n",
      "where \\(W^{0},\\ldots,W^{\\nu}\\) are the weight matrices and \\(b^{0},\\ldots,b^{\\nu}\\) are the biases. In total there are \\(\\nu\\) activation layers inserted between \\(\\nu+1\\) fully connected layers. \\(z\\) represents the inputs to the neural network and \\(\\hat{x}\\) is the output vector, as we will use such a neural network to approximate the \\(T^{\\dagger}\\) mapping in the KKL observer.\n",
      "\n",
      "Given a neural network with fixed parameters \\(\\theta=(W^{0},b^{0},\\ldots,W^{\\nu},b^{\\nu})\\), a rough estimate of the Lipschitz\n",
      "\n",
      "Fig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\n",
      "constant of \\(S\\) can be obviously obtained as\n",
      "\n",
      "\\[L_{S}(\\theta)=\\prod_{\\ell=0}^{\\nu}\\|W^{\\ell}\\|_{2}, \\tag{5}\\]\n",
      "\n",
      "where \\(\\|\\cdot\\|_{2}\\) for a matrix refers to its operator norm induced by the \\(\\ell_{2}\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\n",
      "\n",
      "The recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\n",
      "\n",
      "**Definition 2** (\\(1\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\(X\\in\\mathbb{R}^{d\\times d}\\), \\(Y\\in\\mathbb{R}^{c\\times d}\\), \\(s\\in\\mathbb{R}^{d}\\), and \\(b\\in\\mathbb{R}^{d}\\), a \\(1\\)-Lipschitz sandwich layer is defined as such a mapping \\(\\Xi:\\mathbb{R}^{c}\\rightarrow\\mathbb{R}^{d}\\) that maps any \\(h\\in\\mathbb{R}^{c}\\) into a \\(\\Xi(h;X,Y,s,b)\\in\\mathbb{R}^{d}\\) according to the following formulas:_\n",
      "\n",
      "\\[Z =X-X^{\\top}+Y^{\\top}Y,\\ \\Psi_{s}=\\mathrm{diag}(e^{s}) \\tag{6}\\] \\[M_{X,Y} =\\left[(I+Z)^{-1}(I-Z)\\right]^{\\top},\\] \\[N_{X,Y} =\\left[-2Y(I+Z)^{-1}\\right]^{\\top},\\] \\[\\Xi(h) =\\sqrt{2}M_{X,Y}^{\\top}\\Psi_{s}\\sigma(\\sqrt{2}\\Psi_{s}^{-1}N_{X, Y}h+b).\\]\n",
      "\n",
      "It turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\(1\\)[28, Theorem 3.3]. The mapping from the input \\(h\\) to the output \\(\\Xi(h)\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\((X,Y)\\) to \\((M,N)\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\n",
      "\n",
      "Thus, by stacking a number of such sandwich layers after a scaling by \\(\\sqrt{\\gamma}\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\(\\Xi\\) as in Equation (6)), a neural network with Lipschitz bound \\(\\gamma\\) can be obtained, for any provided \\(\\gamma>0\\).\n",
      "\n",
      "**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\(S(\\cdot|\\theta)\\), by a neural network in the following architecture:_\n",
      "\n",
      "\\[h^{0} =\\sqrt{\\gamma}z; \\tag{7}\\] \\[h^{\\ell+1} =\\Xi(h^{\\ell};X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}),\\ \\ell=0,1,\\ldots,\\nu-1;\\] \\[\\hat{x} =\\sqrt{\\gamma}N_{X^{\\nu},Y^{\\nu}}h^{\\nu}+b^{\\nu}.\\]\n",
      "\n",
      "_Here the parameters include_\n",
      "\n",
      "\\[\\theta=\\{X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}\\}_{\\ell=0}^{\\nu-1}\\cup\\{X^{\\nu}, Y^{\\nu},b^{\\nu}\\}\\]\n",
      "\n",
      "_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\(z\\) and \\(\\hat{x}\\), respectively._\n",
      "\n",
      "The above-defined Wang-Manchester network satisfies \\(\\|S(\\cdot|\\theta)\\|_{\\mathrm{Lip}}\\leq\\gamma\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.\n",
      "\n",
      "## III Analysis on the Generalized Loss\n",
      "\n",
      "Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.\n",
      "\n",
      "**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\(\\mathcal{F}\\) on \\(\\mathcal{X}\\). The distribution \\(\\mathcal{F}\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\(\\mathcal{F}\\)._\n",
      "\n",
      "Suppose that The LTI dynamics of the KKL observer, \\((A,B)\\), is fixed. Then the observer states can be simulated from this linear dynamics.\n",
      "\n",
      "**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\(y=h(x)\\), but instead containing a white noise of unknown covariance \\(\\sigma^{2}\\). In other words, the simulation from \\(y\\) to \\(z\\) is_\n",
      "\n",
      "\\[\\begin{split}&\\dot{z}=Ax+By+w,\\quad\\mathbb{E}[w(t)]=0,\\,\\forall t \\in\\mathbb{R}\\\\ &\\mathbb{E}[w(t)w(s)]=\\delta(t-s)\\sigma^{2},\\,\\forall t,s\\in \\mathbb{R}.\\end{split} \\tag{8}\\]\n",
      "\n",
      "In this way, the collected sample, denoted as \\(\\{(x(t_{i}),z(t_{i}))\\}_{i=1}^{m}=\\{(x_{i},z_{i})\\}_{i=1}^{m}\\), in fact satisfies the following relation:\n",
      "\n",
      "\\[z_{i}=\\bar{z}_{i}+v_{i},\\quad\\delta_{i}=\\int_{-\\infty}^{t_{i}}g(\\tau)w(t_{i}- \\tau)d\\tau. \\tag{9}\\]\n",
      "\n",
      "Here \\(g(\\tau)\\) is the impulse response of LTI system \\((A,B)\\); \\(\\bar{z}\\) is the value of \\(z(t_{i})\\) that would be otherwise obtained if there were no white noises in the output measurements.\n",
      "\n",
      "**Assumption 3** (Sufficient decay).: _After a significantly long time \\(t_{\\epsilon}\\), \\(\\|z-T(x)\\|\\leq\\epsilon\\) for a small enough \\(z\\). Here \\(T\\) is the nonlinear immersion map specified by (3)._\n",
      "\n",
      "Fig. 2: A sandwich layer and its parameters.\n",
      "Then, \\(\\|\\bar{z}_{i}-T(x_{i})\\|\\leq\\epsilon\\). Thus, we may write\n",
      "\n",
      "\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\prime},\\quad\\|v_{i}^{\\prime}\\|\\leq\\epsilon. \\tag{10}\\]\n",
      "\n",
      "Now we suppose that the sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{m}\\) is used to train a neural network \\(S(\\cdot|\\theta)\\), which gives the state observations \\(\\hat{x}_{i}=S(z_{i}|\\theta)\\), and that the resulting empirical loss, if defined as the average squared observation error, is\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta):=\\frac{1}{m}\\sum_{i=1}^{m}\\|\\hat{x}_{i}-x_{i}\\|^{2}. \\tag{11}\\]\n",
      "\n",
      "Then we get\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\left\\|S\\left(T(x_{i})+v_{i}+v_{i }^{\\prime}|\\theta\\right)-x_{i}\\right\\|^{2}. \\tag{12}\\]\n",
      "\n",
      "**Assumption 4**.: _Assume that the probability distribution \\(\\mathcal{F}\\) is supported by a compact set, i.e., if \\(x\\sim\\mathcal{F}\\), then \\(x\\) should be almost surely bounded._\n",
      "\n",
      "It follows that both \\(S(\\cdot|\\theta)\\) and \\(T\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\(L_{S}(\\theta)\\) and \\(L_{T}\\), respectively. We have\n",
      "\n",
      "\\[\\|S\\left(T(x_{i})+\\delta_{i}+\\delta_{i}^{\\prime}|\\theta\\right)-S\\left(T(x_{i}) |\\theta\\right)\\|\\leq L_{S}(\\theta)L_{T}(\\|v_{i}\\|+\\epsilon). \\tag{13}\\]\n",
      "\n",
      "Denote \\(D\\) as the essential upper bound of \\(\\|x\\|\\) on the distribution \\(\\mathcal{F}\\). As such, without loss of generality, let \\(S(T(0))=0\\). Then \\(\\|x-S(T(x))\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely. Combining the above two equations, we further get\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{14}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}(\\theta)L_{T}(L_{S}(\\theta)L _{T}+1)D(\\|v_{i}\\|+\\epsilon)\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}^{2}(\\theta)L_{T}^{2}(\\|v_{i} \\|+\\epsilon)^{2}.\\]\n",
      "\n",
      "That is,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{15}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}(L_{S}(\\theta)L_{T}+1)^{2}\\left(D+ \\|v_{i}\\|+\\epsilon\\right)(\\|v_{i}\\|+\\epsilon).\\]\n",
      "\n",
      "The left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\(z_{i}=T(x_{i})\\), \\(i=1,\\ldots,m\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{16}\\] \\[\\quad\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}+(D+2\\epsilon) \\left(\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)^{1/2}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Given that \\(v_{i}\\) is the response of LTI system \\((A,B)\\) to a white noise of covariance \\(\\sigma^{2}\\), \\(\\mathbb{E}(\\|v_{i}\\|^{2})=h^{2}\\sigma^{2}\\) where \\(h\\) is the \\(H_{2}\\)-norm of the system \\((A,B)\\) where \\(A\\) is Hurwitz. Therefore,\n",
      "\n",
      "\\[\\mathbb{E}\\left(\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)=h^{2}\\sigma^{2}. \\tag{17}\\]\n",
      "\n",
      "Let \\(\\alpha\\) be a small positive number. With confidence \\(1-\\alpha/2\\), a conservative estimation for its upper bound can be found according to Markov inequality:\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\leq\\frac{1}{1-\\alpha/2}h^{2}\\sigma^{2}. \\tag{18}\\]\n",
      "\n",
      "Therefore,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{19}\\] \\[\\quad\\left[\\frac{h^{2}\\sigma^{2}}{1-\\alpha/2}+(D+2\\epsilon)\\frac{ h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Finally, we note that for \\(x\\sim\\mathcal{F}\\), now that \\(\\|x-S(T(x)|\\theta)\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely, by Hoeffding's inequality, for any \\(\\varepsilon>0\\),\n",
      "\n",
      "\\[\\mathbb{P}\\bigg{(}\\bigg{|}\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{ i})|\\theta)\\|^{2}-\\mathbb{E}\\left(\\|x-S(T(x))\\|^{2}\\right)\\bigg{|} \\tag{20}\\] \\[\\geq(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\varepsilon\\bigg{)}\\leq 2\\exp \\left(-2m\\varepsilon^{2}\\right).\\]\n",
      "\n",
      "Thus, with confidence \\(1-\\alpha/2\\), we have\n",
      "\n",
      "\\[\\left|\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}- \\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right)\\bigg{|}\\right. \\tag{21}\\] \\[\\quad<(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m }}.\\]\n",
      "\n",
      "Combining (19) and (21), we have the following theorem.\n",
      "\n",
      "**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_\n",
      "\n",
      "\\[R_{S}(\\theta)=\\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right), \\tag{22}\\]\n",
      "\n",
      "_is related to the empirical loss as defined in (11) by_\n",
      "\n",
      "\\[R_{S}(\\theta)<\\hat{R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\Delta(h,\\sigma, \\alpha,\\epsilon). \\tag{23}\\]\n",
      "\n",
      "_with confidence \\(1-\\alpha\\) (\\(\\alpha\\in(0,1)\\)). Here_\n",
      "\n",
      "\\[\\Delta(h,\\sigma,\\alpha,\\epsilon)= D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m}}+\\frac{h^{2}\\sigma^{2}}{1- \\alpha/2} \\tag{24}\\] \\[+(D+2\\epsilon)\\frac{h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon.\\]\n",
      "\n",
      "The theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\(L_{S}(\\theta)\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\(\\sigma\\)\n",
      "and \\(\\epsilon\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\(\\|x-S(T(x)|\\theta)\\|\\), which acts as a coefficient before the Hoeffding term \\(\\sqrt{\\ln(4/\\alpha)/2m}\\), and (ii) the effect of noisy measurements on the observer states.\n",
      "\n",
      "**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\(L_{S}(\\theta)\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\((A,B)\\) along with the neural network \\(S(\\cdot|\\theta)\\), as the dependence of \\(L_{T}\\) on \\((A,B)\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\((A,B)\\) and the neural network._\n",
      "\n",
      "## IV Case Study\n",
      "\n",
      "Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:\n",
      "\n",
      "\\[\\dot{x}_{1} =10(x_{2}-x_{1}), \\tag{25}\\] \\[\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\] \\[\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\]\n",
      "\n",
      "Suppose that the measurement used for state observation is \\(y=x_{2}\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\(0.01\\). The LTI part of the KKL observer, \\(A=-\\mathrm{diag}(8,4,2,1)\\) and \\(B=[1,1,1,1]^{\\top}\\) are chosen. At the beginning of the observer simulation, \\(z(0)=0\\) is set as the initial condition; we simulate the dynamics until \\(t=500\\) and randomly collect \\(m=2000\\) time instants between \\(t=20\\) and \\(t=500\\) as the training data.\n",
      "\n",
      "Consider first the case with noiseless measurement (\\(\\sigma=0\\)). The sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{2000}\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\(z_{i}\\) indeed captures the structure of such a Lorenz attractor in a \\(4\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\(80\\%\\) of the sample under the mean-squares loss metric, and validate using the remaining \\(20\\%\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\(10^{-3}\\) is used for optimization. The number of epochs is empirically tuned to \\(300\\). The neural network has \\(2\\) hidden layers, each containing \\(8\\) neurons, resulting in \\(292\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\(1.5\\) seconds (for a randomly initialized network).\n",
      "\n",
      "Varying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.\n",
      "\n",
      "* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\(1000\\), the \\(L_{S}\\) after training does not exceed \\(300\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\n",
      "* When the Lipschitz bound is small, relaxing the restriction on \\(L_{S}\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\(L_{S}\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and\n",
      "\n",
      "Fig. 3: Sample collected from the Lorenz system.\n",
      "validation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\n",
      "* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\(\\sigma=1\\), a suitable choice can be \\(\\gamma=100\\), whereas at \\(\\sigma=5\\) and \\(\\sigma=10\\), \\(\\gamma\\) can be chosen as \\(30\\) and \\(10\\), respectively.\n",
      "\n",
      "Now suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\(\\sigma=0\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\(L_{S}\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\(\\sigma\\geq 3\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\n",
      "\n",
      "Finally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\(L_{S}=10\\), and applying it to environments with noise \\(\\sigma=0.1\\), \\(0.3\\), \\(1.0\\), \\(3.0\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\(10\\) time units. Naturally, when \\(\\sigma\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\(\\sigma\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\(3<t<4\\) or \\(8<t<9\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.\n",
      "\n",
      "## V Conclusions and Discussions\n",
      "\n",
      "This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.\n",
      "\n",
      "Fig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)\n",
      "\n",
      "Fig. 5: Errors of noiselessly trained observers in noisy environments.\n",
      "We implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.\n",
      "\n",
      "Also, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Sample\n",
    "'''\n",
    "Abstract is usually defined as\n",
    "'###### Abstract'\n",
    "'''\n",
    "idx = 0\n",
    "# idx = 15\n",
    "sample = df.iloc[idx]['markdown']\n",
    "# print(len(sample), sample[:200])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks'}, page_content='###### Abstract  \\nThis paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'I Introduction'}, page_content='For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\\\(Q\\\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.  \\nHence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.  \\nThis paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.  \\nIt is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\\nthe neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.  \\nHence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'II Preliminaries'}, page_content='We consider a nonlinear autonomous system:  \\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]  \\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.  \\n### _KKL Observer_  \\nFor nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as  \\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]  \\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:  \\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]  \\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.  \\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).  \\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._  \\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._  \\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.  \\n### _Lipschitz-Bounded Neural Networks_  \\nConsider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as  \\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]  \\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.  \\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz  \\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as  \\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]  \\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.  \\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].  \\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_  \\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]  \\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.  \\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).  \\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_  \\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]  \\n_Here the parameters include_  \\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]  \\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._  \\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'III Analysis on the Generalized Loss'}, page_content=\"Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.  \\n**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\\\(\\\\mathcal{F}\\\\)._  \\nSuppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. Then the observer states can be simulated from this linear dynamics.  \\n**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_  \\n\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall t \\\\in\\\\mathbb{R}\\\\\\\\ &\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in \\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]  \\nIn this way, the collected sample, denoted as \\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), in fact satisfies the following relation:  \\n\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- \\\\tau)d\\\\tau. \\\\tag{9}\\\\]  \\nHere \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); \\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise obtained if there were no white noises in the output measurements.  \\n**Assumption 3** (Sufficient decay).: _After a significantly long time \\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough \\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._  \\nFig. 2: A sandwich layer and its parameters.\\nThen, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may write  \\n\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. \\\\tag{10}\\\\]  \\nNow we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the resulting empirical loss, if defined as the average squared observation error, is  \\n\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. \\\\tag{11}\\\\]  \\nThen we get  \\n\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i }^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]  \\n**Assumption 4**.: _Assume that the probability distribution \\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if \\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._  \\nIt follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have  \\n\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) |\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). \\\\tag{13}\\\\]  \\nDenote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let \\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely. Combining the above two equations, we further get  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L _{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} \\\\|+\\\\epsilon)^{2}.\\\\]  \\nThat is,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ \\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]  \\nThe left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) \\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nGiven that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a white noise of covariance \\\\(\\\\sigma^{2}\\\\), \\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the \\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. Therefore,  \\n\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. \\\\tag{17}\\\\]  \\nLet \\\\(\\\\alpha\\\\) be a small positive number. With confidence \\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be found according to Markov inequality:  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. \\\\tag{18}\\\\]  \\nTherefore,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nFinally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),  \\n\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} \\\\tag{20}\\\\] \\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp \\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]  \\nThus, with confidence \\\\(1-\\\\alpha/2\\\\), we have  \\n\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- \\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. \\\\tag{21}\\\\] \\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m }}.\\\\]  \\nCombining (19) and (21), we have the following theorem.  \\n**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_  \\n\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), \\\\tag{22}\\\\]  \\n_is related to the empirical loss as defined in (11) by_  \\n\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, \\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]  \\n_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_  \\n\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- \\\\alpha/2} \\\\tag{24}\\\\] \\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]  \\nThe theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\\\(\\\\sigma\\\\)\\nand \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of noisy measurements on the observer states.  \\n**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\\\((A,B)\\\\) and the neural network._\"),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'IV Case Study'}, page_content='Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:  \\n\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\\\]  \\nSuppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, \\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and \\\\(t=500\\\\) as the training data.  \\nConsider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\\\(z_{i}\\\\) indeed captures the structure of such a Lorenz attractor in a \\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\\\(80\\\\%\\\\) of the sample under the mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) seconds (for a randomly initialized network).  \\nVarying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.  \\n* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\\\(1000\\\\), the \\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\\n* When the Lipschitz bound is small, relaxing the restriction on \\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and  \\nFig. 3: Sample collected from the Lorenz system.\\nvalidation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\\n* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at \\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as \\\\(30\\\\) and \\\\(10\\\\), respectively.  \\nNow suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq 3\\\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.  \\nFinally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or \\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'V Conclusions and Discussions'}, page_content=\"This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.  \\nFig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)  \\nFig. 5: Errors of noiselessly trained observers in noisy environments.\\nWe implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.  \\nAlso, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_splits = splitter.split_text(sample)\n",
    "print(len(sample_splits))\n",
    "sample_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_markdown_hierarchy(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "    # Define a pattern to match headers (from # to ######)\n",
    "    header_pattern = re.compile(r'^(#{1,6})\\s*(.*)$')\n",
    "\n",
    "    # Initialize the root of the hierarchy\n",
    "    root = {'children': []}\n",
    "    # Stack to keep track of the current hierarchy levels\n",
    "    stack = [{'level': 0, 'node': root}]\n",
    "    # Accumulate text for the current node\n",
    "    current_text = []\n",
    "\n",
    "    for line in lines:\n",
    "        header_match = header_pattern.match(line)\n",
    "        if header_match:\n",
    "            # If we have accumulated text, add it to the current node\n",
    "            if current_text:\n",
    "                # Join accumulated text and add to the last node's 'text'\n",
    "                stack[-1]['node'].setdefault('text', '')\n",
    "                if stack[-1]['node']['text']:\n",
    "                    stack[-1]['node']['text'] += '\\n'\n",
    "                stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "                current_text = []\n",
    "            # Extract header level and text\n",
    "            header_marks, header_text = header_match.groups()\n",
    "            level = len(header_marks)\n",
    "            # Pop the stack to find the correct parent level\n",
    "            while stack and stack[-1]['level'] >= level:\n",
    "                stack.pop()\n",
    "            # Create a new node for the header\n",
    "            node = {\n",
    "                'header': f'h{level}',\n",
    "                'value': header_text.strip(),\n",
    "                'children': []\n",
    "            }\n",
    "            # Add the new node to its parent's 'children'\n",
    "            stack[-1]['node']['children'].append(node) ## parent\n",
    "            # Push the new node onto the stack\n",
    "            stack.append({'level': level, 'node': node}) ## for accumulating potential children\n",
    "        else:\n",
    "            # Accumulate non-header lines\n",
    "            current_text.append(line)\n",
    "    # After processing all lines, add any remaining text\n",
    "    if current_text:\n",
    "        stack[-1]['node'].setdefault('text', '')\n",
    "        if stack[-1]['node']['text']:\n",
    "            stack[-1]['node']['text'] += '\\n'\n",
    "        stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "    # Return the hierarchy starting from the root's children\n",
    "    return root['children']\n",
    "hierarchical_structure = parse_markdown_hierarchy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'children': [{'children': [],\n",
      "                'header': 'h6',\n",
      "                'text': 'This paper focuses on the _model-free_ synthesis of state observers for '\n",
      "                        'nonlinear autonomous systems without knowing the governing equations. '\n",
      "                        'Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure '\n",
      "                        'is leveraged, where the outputs are fed into a linear time-invariant '\n",
      "                        '(LTI) system to obtain the observer states, which can be viewed as the '\n",
      "                        'states nonlinearly transformed by an immersion mapping, and a neural '\n",
      "                        'network is used to approximate the inverse of the nonlinear immersion and '\n",
      "                        'estimate the states. In view of the possible existence of noises in '\n",
      "                        'output measurements, this work proposes to impose an upper bound on the '\n",
      "                        'Lipschitz constant of the neural network for robust and safe observation. '\n",
      "                        'A relation that bounds the generalization loss of state observation '\n",
      "                        'according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI part in the KKL observer, is established, thus reducing the '\n",
      "                        'model-free observer synthesis problem to that of Lipschitz-bounded neural '\n",
      "                        'network training, for which a direct parameterization technique is used. '\n",
      "                        'The proposed approach is demonstrated on a chaotic Lorenz system.',\n",
      "                'value': 'Abstract'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'For nonlinear systems that arise from realistic engineering applications '\n",
      "                        'such as transport-reaction processes, modern control theory relies on '\n",
      "                        '_state-space representations_ for their modeling, analysis, and control '\n",
      "                        '[1, 2, 3]. Recent advances in nonlinear control have highlighted the role '\n",
      "                        'of data-driven (machine learning) techniques in identifying governing '\n",
      "                        'equations or underlying dynamical structures [4, 5, 6], analyzing system '\n",
      "                        'and control-theoretic properties [7, 8], and synthesizing model-free '\n",
      "                        'controllers [9, 10, 11]. In these efforts, it is often assumed that the '\n",
      "                        '_state_ information is available for analysis or control; for example, in '\n",
      "                        'reinforcement learning (RL) literature, it is common to apply stochastic '\n",
      "                        'first-order optimization to learn a value (cost) function or \\\\(Q\\\\) '\n",
      "                        'function based on temporal actions and state measurements. In many (if '\n",
      "                        'not most) control engineering applications, such as in chemical '\n",
      "                        'processes, however, it is more likely that the states are not '\n",
      "                        'measurable.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, for nonlinear control in a state-space framework, a _state '\n",
      "                        'observer_ is necessary, whereby the states are estimated based on input '\n",
      "                        'and output history [12]. A recent review on model-based approaches to '\n",
      "                        'synthesize state observers is found in Bernard, Andrieu, and Astolfi '\n",
      "                        '[13]. A classical form of state observer for linear systems is known as '\n",
      "                        'Luenberger observer [14], which an auxiliary linear time-invariant (LTI) '\n",
      "                        'system that uses the plant outputs as inputs and returns state estimates. '\n",
      "                        'The observer states are in fact a linear transform of the plant states '\n",
      "                        '[15]. The idea was extended to nonlinear systems in the seminal work of '\n",
      "                        'Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) '\n",
      "                        'observer (as named in Andrieu and Praly [17]) still uses an LTI system to '\n",
      "                        'convert plant outputs to observer states, which turn out to be the plant '\n",
      "                        'states transformed via a nonlinear immersion. Thus, the observer '\n",
      "                        'synthesis problem reduces to the determination of this nonlinear '\n",
      "                        'immersion and its inverse, via solving (model-based) partial differential '\n",
      "                        'equations (PDEs). Such a KKL observer was extended from autonomous to '\n",
      "                        'actuated systems in [18], where the LTI part is replaced by an '\n",
      "                        'input-affine one with an additional nonlinear drift term associated with '\n",
      "                        'the actuated inputs.\\n'\n",
      "                        '\\n'\n",
      "                        'This paper focuses on the _synthesis of KKL observer_ in a _model-free_ '\n",
      "                        'manner, without assuming prior knowledge on the plant dynamics. This is '\n",
      "                        'motivated by two reasons: (i) many nonlinear systems that involve complex '\n",
      "                        'kinetic or kinematic mechanisms are often hard to model accurately, and '\n",
      "                        '(ii) it can be challenging to solve the associated PDEs, especially in '\n",
      "                        'high-dimensional state space (in fact, there may not be well-posed '\n",
      "                        'boundary conditions). In the recent years, there have been several works '\n",
      "                        'that pioneered the use of neural networks in the observer problem. For '\n",
      "                        'example, Ramos et al. [19] first trained neural networks to approximate '\n",
      "                        'the inverse immersion map to reconstruct the actual states from observer '\n",
      "                        'states. Then, the optimization of pole placement was considered along '\n",
      "                        'with the training of inverse immersion in [20]. Niazi et al. [21] used '\n",
      "                        'physics-informed neural networks (PINNs) to approach a surrogate solution '\n",
      "                        'to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization '\n",
      "                        'problem to minimize the accumulated squared state observation error, '\n",
      "                        'whereby the optimality condition, through calculus of variations results '\n",
      "                        'in neural ODEs.\\n'\n",
      "                        '\\n'\n",
      "                        'It is commonly known that neural networks, when over-parameterized with '\n",
      "                        'large widths and depths, may cause a deteriorated capability of '\n",
      "                        'generalization. It has also been argued that neural networks can be '\n",
      "                        'fragile to adversarial attacks to the training data and thus must be '\n",
      "                        'equipped with a self-defense mechanisms that warranty robustness [23, '\n",
      "                        '24]. In particular, controlling the Lipschitz constant of the mapping '\n",
      "                        'specified by the neural network has been studied as a promising approach '\n",
      "                        '[25, 26, 27]. However, in these works, estimating and minimizing the '\n",
      "                        'Lipschitz constant requires the use of semidefinite programming routines, '\n",
      "                        'which has a high complexity when the number of neurons is large. An '\n",
      "                        'alternative way, called _direct paramterizaton_, as recently proposed in '\n",
      "                        'Wang and Manchester [28], is to translate the Lipschitz bound constraint '\n",
      "                        'into a special architecture of\\n'\n",
      "                        'the neural layers, thus allowing the use of typical back-propagation (BP) '\n",
      "                        'to train the network in an unconstrained way.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, in this work, the Wang-Manchester direct parameterization is '\n",
      "                        'adopted to train Lipschitz-bounded neural networks in a KKL state '\n",
      "                        'observer for any unknown nonlinear autonomous system. The paper '\n",
      "                        'establishes a relation between the generalized observation error and the '\n",
      "                        'Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI observer dynamics, under a typical white noise assumption on the '\n",
      "                        'plant outputs. Hence, by varying the Lipschitz bound, the optimal '\n",
      "                        'observer can be synthesized.',\n",
      "                'value': 'I Introduction'},\n",
      "               {'children': [{'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'For nonlinear systems, KKL observer generalizes the notion '\n",
      "                                      'of Luenberger observers that were restricted to linear '\n",
      "                                      'systems [14], providing a generic method for state '\n",
      "                                      'observation with mild assumptions to guarantee existence. '\n",
      "                                      'Specifically, the KKL observer for (1) is expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). '\n",
      "                                      '\\\\tag{2}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'Here the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has '\n",
      "                                      'an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are '\n",
      "                                      'chosen under the requirements of (i) controllability of '\n",
      "                                      '\\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property '\n",
      "                                      'of \\\\(A\\\\), and (iii) sufficiently high dimension of '\n",
      "                                      '\\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) '\n",
      "                                      'if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if '\n",
      "                                      '\\\\((A,B)\\\\) is real [29]. The mapping from the observer '\n",
      "                                      'states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a '\n",
      "                                      'static one, \\\\(T^{\\\\dagger}\\\\), which is the '\n",
      "                                      'left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., '\n",
      "                                      'a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ '\n",
      "                                      'T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy '\n",
      "                                      'the following PDE:\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\frac{\\\\partial T}{\\\\partial '\n",
      "                                      'x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, '\n",
      "                                      '\\\\tag{3}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian '\n",
      "                                      'matrix of \\\\(T\\\\). It can be easily verified that under the '\n",
      "                                      'above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) '\n",
      "                                      'has an exponentially decaying dynamics, as \\\\(A\\\\) is '\n",
      "                                      'Hurwitz.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The conditions for the existence of a KKL observer, namely '\n",
      "                                      'the solution to its defining PDE (3), have been established '\n",
      "                                      'based on the condition of backward distinguishability. In '\n",
      "                                      'below, we denote the solution to the ODEs '\n",
      "                                      '\\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition '\n",
      "                                      '\\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the '\n",
      "                                      'backward time instant after which the solution does not '\n",
      "                                      'escape this region by '\n",
      "                                      '\\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). '\n",
      "                                      'Also denote '\n",
      "                                      '\\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 1** (Backward distinguishability).: _The '\n",
      "                                      'system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward '\n",
      "                                      'distinguishable if for any distinct '\n",
      "                                      '\\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a '\n",
      "                                      'negative '\n",
      "                                      '\\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} '\n",
      "                                      '(\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq '\n",
      "                                      'h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Fact 1** (Existence of KKL observer, cf. Brivadis et al. '\n",
      "                                      '[29]).: _Assume that there is an open '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a '\n",
      "                                      'positive constant \\\\(\\\\epsilon\\\\) such that the system (1) '\n",
      "                                      'is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. '\n",
      "                                      'Then there exists a constant \\\\(\\\\rho>0\\\\) such that for '\n",
      "                                      'all but a Lebesgue-zero-measure set of '\n",
      "                                      '\\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), '\n",
      "                                      'if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion '\n",
      "                                      '\\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) '\n",
      "                                      'solving the PDEs (3)._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above theorem clarifies that as long as the spectrum of '\n",
      "                                      '\\\\(A\\\\) is restricted to the left of '\n",
      "                                      '\\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL '\n",
      "                                      'observer can be almost arbitrarily assigned. Once '\n",
      "                                      '\\\\((A,B)\\\\) are chosen, the remaining question for '\n",
      "                                      'synthesis a KKL observer (2) is to numerically determine '\n",
      "                                      'the solution. In view of the computational challenge in '\n",
      "                                      'directly solving the PDEs (3) and the recent trend of '\n",
      "                                      'handling the problem by neural approaches [19, 20, 21], '\n",
      "                                      'this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a '\n",
      "                                      'neural network. Yet, instead of using a vanilla multi-layer '\n",
      "                                      'perceptron architecture, a Lipschitz-bounded neural network '\n",
      "                                      'will be adopted, which safeguards the generalization '\n",
      "                                      'performance of state observation, which will be discussed '\n",
      "                                      'in SSIII. This overall idea is illustrated in Fig. 1.',\n",
      "                              'value': '_KKL Observer_'},\n",
      "                             {'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network '\n",
      "                                      '\\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as '\n",
      "                                      'a single vector \\\\(\\\\theta\\\\). Without loss of generality, '\n",
      "                                      'assume that the activation function (element-wise applied '\n",
      "                                      'to vectors) is '\n",
      "                                      '\\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with '\n",
      "                                      'slope bounded in \\\\([0,1]\\\\) (in this work, rectified '\n",
      "                                      'linear units (ReLU) are used to prevent gradient decay in '\n",
      "                                      'BP training). The neural network then can be expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\begin{split}& '\n",
      "                                      'z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ '\n",
      "                                      '\\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & '\n",
      "                                      'z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} '\n",
      "                                      '\\\\tag{4}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices '\n",
      "                                      'and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total '\n",
      "                                      'there are \\\\(\\\\nu\\\\) activation layers inserted between '\n",
      "                                      '\\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the '\n",
      "                                      'inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the '\n",
      "                                      'output vector, as we will use such a neural network to '\n",
      "                                      'approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL '\n",
      "                                      'observer.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Given a neural network with fixed parameters '\n",
      "                                      '\\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a '\n",
      "                                      'rough estimate of the Lipschitz\\n'\n",
      "                                      '\\n'\n",
      "                                      'Fig. 1: KKL observer with a Lipschitz-bounded neural '\n",
      "                                      'network to be trained.\\n'\n",
      "                                      'constant of \\\\(S\\\\) can be obviously obtained as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, '\n",
      "                                      '\\\\tag{5}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its '\n",
      "                                      'operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of '\n",
      "                                      'vectors, i.e., its largest singular value. To reduce the '\n",
      "                                      'conservativeness, Fazlyab et al. [25] leverages the '\n",
      "                                      'control-theoretic tool of integral quadratic constraints to '\n",
      "                                      'formulate the Lipschitz bound condition as a linear matrix '\n",
      "                                      'inequality, thus estimating the Lipschitz constants and '\n",
      "                                      'training Lipschitz-bounded neural networks through solving '\n",
      "                                      'semidefinite programming problems [27]. The pertinent '\n",
      "                                      'matrix size, however, proportionally scales with the total '\n",
      "                                      'number of neurons, which results in high computational '\n",
      "                                      'complexity unless the neural network is very small.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The recent work of Wang and Manchester [28] proposed a '\n",
      "                                      '_direct parameterization_ approach to accommodate Lipschitz '\n",
      "                                      'bound by a special design of the neural network '\n",
      "                                      'architecture instead of imposing extra parameter '\n",
      "                                      'constraints. By this approach, the training of neural '\n",
      "                                      'networks is an unconstrained optimization problem and is '\n",
      "                                      'thus amenable to the typical, computationally lightweight '\n",
      "                                      'back-propagation (BP) routine. Wang-Manchester direct '\n",
      "                                      'parameterization is conceptually related to, and arguably '\n",
      "                                      'motivated by, the theory of controller parameterization '\n",
      "                                      '[30, 31].\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. '\n",
      "                                      '[28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times '\n",
      "                                      'd}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), '\n",
      "                                      '\\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), '\n",
      "                                      'a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a '\n",
      "                                      'mapping '\n",
      "                                      '\\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that '\n",
      "                                      'maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a '\n",
      "                                      '\\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the '\n",
      "                                      'following formulas:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ '\n",
      "                                      '\\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} '\n",
      "                                      '=\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} '\n",
      "                                      '=\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) '\n",
      "                                      '=\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, '\n",
      "                                      'Y}h+b).\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'It turns out that the Lipschitz constant of the '\n",
      "                                      'above-defined sandwich layer is guaranteed to be upper '\n",
      "                                      'bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the '\n",
      "                                      'input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded '\n",
      "                                      'as comprising of an activation layer in the midst of two '\n",
      "                                      'fully connected layers with related parameters. The '\n",
      "                                      'operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the '\n",
      "                                      '_Cayley transform_. The structure and the parameters of a '\n",
      "                                      'sandwich layer is shown in Fig. 2.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Thus, by stacking a number of such sandwich layers after a '\n",
      "                                      'scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated '\n",
      "                                      'half-sandwich layer (meaning a layer containing only the '\n",
      "                                      'terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), '\n",
      "                                      'a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be '\n",
      "                                      'obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 3** (Wang-Manchester network).: _In this work, '\n",
      "                                      'we refer to Wang-Manchester network, '\n",
      "                                      '\\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the '\n",
      "                                      'following architecture:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} '\n",
      "                                      '=\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ '\n",
      "                                      '\\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} '\n",
      "                                      '=\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_Here the parameters include_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, '\n",
      "                                      'Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_which can be trained in an unconstrained way using '\n",
      "                                      'back-propagation. The inputs and outputs of the network are '\n",
      "                                      '\\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above-defined Wang-Manchester network satisfies '\n",
      "                                      '\\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). '\n",
      "                                      'In this work, the network is defined and trained with data '\n",
      "                                      'using PyTorch (version 2.0.1) on Google Colaboratory, which '\n",
      "                                      'allows the auto-differentiation of a user-defined loss '\n",
      "                                      'function with respect to the neural network parameters for '\n",
      "                                      'the parameters to be iteratively updated.',\n",
      "                              'value': '_Lipschitz-Bounded Neural Networks_'}],\n",
      "                'header': 'h2',\n",
      "                'text': 'We consider a nonlinear autonomous system:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'where \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector '\n",
      "                        'of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For '\n",
      "                        'simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and '\n",
      "                        '\\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and '\n",
      "                        'uniqueness of solution but unknown for model-based synthesis.',\n",
      "                'value': 'II Preliminaries'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Here we shall provide a justification for requiring a Lipschitz bound on '\n",
      "                        'the neural network. We will make the following standing assumptions on '\n",
      "                        'the training data collection procedure for subsequent analysis.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is '\n",
      "                        'collected from the system, whose initial state is sampled from a '\n",
      "                        'probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure '\n",
      "                        'of the Perron-Frobenius operator), so that any point of the trajectory '\n",
      "                        'comes from \\\\(\\\\mathcal{F}\\\\)._\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. '\n",
      "                        'Then the observer states can be simulated from this linear dynamics.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 2** (Noisy measurements).: _Assume that the input signal for '\n",
      "                        'this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead '\n",
      "                        'containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In '\n",
      "                        'other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall '\n",
      "                        't \\\\in\\\\mathbb{R}\\\\\\\\ '\n",
      "                        '&\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in '\n",
      "                        '\\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'In this way, the collected sample, denoted as '\n",
      "                        '\\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), '\n",
      "                        'in fact satisfies the following relation:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- '\n",
      "                        '\\\\tau)d\\\\tau. \\\\tag{9}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Here \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); '\n",
      "                        '\\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise '\n",
      "                        'obtained if there were no white noises in the output measurements.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 3** (Sufficient decay).: _After a significantly long time '\n",
      "                        '\\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough '\n",
      "                        '\\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 2: A sandwich layer and its parameters.\\n'\n",
      "                        'Then, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may '\n",
      "                        'write\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. '\n",
      "                        '\\\\tag{10}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Now we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is '\n",
      "                        'used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the '\n",
      "                        'state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the '\n",
      "                        'resulting empirical loss, if defined as the average squared observation '\n",
      "                        'error, is\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. '\n",
      "                        '\\\\tag{11}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Then we get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i '\n",
      "                        '}^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 4**.: _Assume that the probability distribution '\n",
      "                        '\\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if '\n",
      "                        '\\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._\\n'\n",
      "                        '\\n'\n",
      "                        'It follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be '\n",
      "                        'Lipschitz continuous. Denote their Lipschitz constants as '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) '\n",
      "                        '|\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). '\n",
      "                        '\\\\tag{13}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Denote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let '\n",
      "                        '\\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) '\n",
      "                        'almost surely. Combining the above two equations, we further get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L '\n",
      "                        '_{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} '\n",
      "                        '\\\\|+\\\\epsilon)^{2}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'That is,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ '\n",
      "                        '\\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The left-hand side gives an estimation of the empirical loss when '\n",
      "                        'observing the states from perfect output measurements (namely when '\n",
      "                        '\\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last '\n",
      "                        'term and applying Cauchy-Schwarz inequality, we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) '\n",
      "                        '\\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Given that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a '\n",
      "                        'white noise of covariance \\\\(\\\\sigma^{2}\\\\), '\n",
      "                        '\\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the '\n",
      "                        '\\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. '\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{17}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Let \\\\(\\\\alpha\\\\) be a small positive number. With confidence '\n",
      "                        '\\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be '\n",
      "                        'found according to Markov inequality:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{18}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ '\n",
      "                        'h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, '\n",
      "                        \"by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),\\n\"\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ '\n",
      "                        'i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} '\n",
      "                        '\\\\tag{20}\\\\] '\n",
      "                        '\\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp '\n",
      "                        '\\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Thus, with confidence \\\\(1-\\\\alpha/2\\\\), we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- '\n",
      "                        '\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. '\n",
      "                        '\\\\tag{21}\\\\] '\n",
      "                        '\\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m '\n",
      "                        '}}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Combining (19) and (21), we have the following theorem.\\n'\n",
      "                        '\\n'\n",
      "                        '**Theorem 1**.: _Under the afore-mentioned assumptions, the '\n",
      "                        'generalization loss, defined as_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), '\n",
      "                        '\\\\tag{22}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_is related to the empirical loss as defined in (11) by_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, '\n",
      "                        '\\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= '\n",
      "                        'D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- '\n",
      "                        '\\\\alpha/2} \\\\tag{24}\\\\] '\n",
      "                        '\\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The theorem shows that the Lipschitz constant of the neural network '\n",
      "                        'trained plays an important role in the generalized performance of the '\n",
      "                        'resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly '\n",
      "                        'that of amplifying the first and third terms defined on the right-hand '\n",
      "                        'side of (24), supposing that \\\\(\\\\sigma\\\\)\\n'\n",
      "                        'and \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise '\n",
      "                        'from (i) the overall upper bound of the observation error '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the '\n",
      "                        'Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of '\n",
      "                        'noisy measurements on the observer states.\\n'\n",
      "                        '\\n'\n",
      "                        '**Remark 1**.: _It is noted that the performance bound stated in the '\n",
      "                        'above theorem can be conservative. The conclusion that '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement '\n",
      "                        'noise should be considered as qualitative. The theorem also does not '\n",
      "                        'suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) '\n",
      "                        'along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence '\n",
      "                        'of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does '\n",
      "                        'not consider the problem of simultaneously training \\\\((A,B)\\\\) and the '\n",
      "                        'neural network._',\n",
      "                'value': 'III Analysis on the Generalized Loss'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Let us consider a Lorenz system in a 3-dimensional state space with '\n",
      "                        'chaotic behavior. The equation is written as:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} '\n",
      "                        '=x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} '\n",
      "                        '=10x_{1}x_{2}-(8/3)x_{3}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), '\n",
      "                        'where a white noise exists. We assign different values to the variance of '\n",
      "                        'the measurement noise and investigate how the resulting neural network '\n",
      "                        'should be chosen differently. To simulate the process we will use a '\n",
      "                        'sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, '\n",
      "                        '\\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are '\n",
      "                        'chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set '\n",
      "                        'as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and '\n",
      "                        'randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and '\n",
      "                        '\\\\(t=500\\\\) as the training data.\\n'\n",
      "                        '\\n'\n",
      "                        'Consider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The '\n",
      "                        'sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which '\n",
      "                        'shows that the data points are representative on the forward invariant '\n",
      "                        'set of the system, and that the observer states \\\\(z_{i}\\\\) indeed '\n",
      "                        'captures the structure of such a Lorenz attractor in a '\n",
      "                        '\\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network '\n",
      "                        'using a randomly selected \\\\(80\\\\%\\\\) of the sample under the '\n",
      "                        'mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) '\n",
      "                        'sample points. Stochastic gradient descent (SGD) algorithm with a '\n",
      "                        'learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of '\n",
      "                        'epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) '\n",
      "                        'hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) '\n",
      "                        'parameters to train in total. After training, the Lipschitz constant is '\n",
      "                        'evaluated a posteriori via the semidefinite programming approach of '\n",
      "                        'Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) '\n",
      "                        'seconds (for a randomly initialized network).\\n'\n",
      "                        '\\n'\n",
      "                        'Varying the prior bound on the Lipschitz constant, the resulting training '\n",
      "                        'loss, validation loss, and the posterior Lipschitz bound obtained from '\n",
      "                        'the same training conditions are illustrated in Fig. 4. The following '\n",
      "                        'observations can be made from these results.\\n'\n",
      "                        '\\n'\n",
      "                        '* As anticipated, as the set bound on the Lipschitz bound increases, the '\n",
      "                        'Lipschitz constant of the trained neural network becomes higher. The '\n",
      "                        'Lipschitz constants estimated a posteriori are lower than the prior bound '\n",
      "                        'on the Wang-Manchester network, validating the direct parameterization '\n",
      "                        'approach on constraining the slope. On the other hand, the actually '\n",
      "                        'posterior Lipschitz constant has an increasingly large lag behind the '\n",
      "                        'prior bound; for example, when the prior bound is \\\\(1000\\\\), the '\n",
      "                        '\\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that '\n",
      "                        'even for the training objective alone, there is a \"resistance\" to pursue '\n",
      "                        'the maximally possible Lipschitz constant.\\n'\n",
      "                        '* When the Lipschitz bound is small, relaxing the restriction on '\n",
      "                        '\\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the '\n",
      "                        'validation loss, showing that the Lipschitz bound is a bottleneck causing '\n",
      "                        'underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no '\n",
      "                        'longer exists; instead, overfitting will appear, with rising training '\n",
      "                        'and\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 3: Sample collected from the Lorenz system.\\n'\n",
      "                        'validation losses. The overfitting phenomenon is more significant when '\n",
      "                        'the noise is large. Thus, there should be optimal values to be set as the '\n",
      "                        'Lipschitz bound.\\n'\n",
      "                        '* Depending on the noise magnitude, the deviation of posterior Lipschitz '\n",
      "                        'constant from the prior bound and the emergence of overfitting phenomenon '\n",
      "                        'occur at different threshold values of the Lipschitz bound. Thus, the '\n",
      "                        'Lipschitz bound to be used for neural network training should be tuned '\n",
      "                        'differently as the noise intensity varies. For example, at '\n",
      "                        '\\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at '\n",
      "                        '\\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as '\n",
      "                        '\\\\(30\\\\) and \\\\(10\\\\), respectively.\\n'\n",
      "                        '\\n'\n",
      "                        'Now suppose that at the observer design stage, the Wang-Manchester '\n",
      "                        'network is trained by the simulated data from a perfect digital twin of '\n",
      "                        'the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network '\n",
      "                        'trained to observe the states of the physical system, the environment is '\n",
      "                        'noisy. In Fig. 5, the resulting loss (mean squared state observation '\n",
      "                        'error) is plotted against varying prior Lipschitz bounds under multiple '\n",
      "                        'values of the environment noise magnitude. It is seen that when the noise '\n",
      "                        'is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic '\n",
      "                        'decrease in the observation error within a large range. On the other '\n",
      "                        'hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq '\n",
      "                        '3\\\\)), the Lipschitz bound has a severe effect on the generalization '\n",
      "                        'loss, and since the achievable performance is restrictive, the '\n",
      "                        'fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, the performance of the state observer is examined. Consider '\n",
      "                        'using the network trained with noiseless simulation data under the prior '\n",
      "                        'Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with '\n",
      "                        'noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The '\n",
      "                        'trajectories of the three components of estimated states by the observer '\n",
      "                        'are plotted against the true states in Fig. 6, within a time horizon of '\n",
      "                        '\\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state '\n",
      "                        'estimates can well track the true states and capture the trends in the '\n",
      "                        'correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered '\n",
      "                        'and the signals constructed by the observer are more noisy, occasionally '\n",
      "                        'yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or '\n",
      "                        '\\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz '\n",
      "                        'attractor). Overall, the state estimates mollifies the true state '\n",
      "                        'trajectories, which is due to the structure of our KKL observer - a '\n",
      "                        'linear filter (LTI system) as the state dynamics and a Lipschitz-bounded '\n",
      "                        'neural network as the static output map.',\n",
      "                'value': 'IV Case Study'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'This work leverages the recent tools of Lipschitz-bounded neural networks '\n",
      "                        'for the synthesis of nonlinear state observers in a model-free setting. '\n",
      "                        'The observer, which has a Kazantzis-Kravaris structure, turns out to have '\n",
      "                        'a provable generalization performance that is related to the Lipschitz '\n",
      "                        'constant of the trained neural network (which represents the mapping from '\n",
      "                        'the observer states to the plant states). As such, by varying the '\n",
      "                        'Lipschitz bound and re-training the neural network, the optimal training '\n",
      "                        'result can yield the minimum generalized state observation error. The '\n",
      "                        'importance of bounding the Lipschitz constant has been demonstrated by a '\n",
      "                        'numerical case study on the Lorenz system.\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 4: Loss and Lipschitz constants under different prior Lipschitz '\n",
      "                        'bounds. (Blue wedges: training loss, blue circles: validation loss, green '\n",
      "                        'circles: prior Lipschitz bound; green wedges: posterior Lipschitz '\n",
      "                        'bound.)\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 5: Errors of noiselessly trained observers in noisy environments.\\n'\n",
      "                        'We implicitly assumed here that a simulator of the dynamics is available, '\n",
      "                        \"so that the true states' trajectories can be used to train the neural \"\n",
      "                        'network. However, such ground truth for supervised learning may not '\n",
      "                        'actually exist in real applications, i.e., only inputs and outputs are '\n",
      "                        'recorded, yet a state observation mechanism is still needed or desired '\n",
      "                        \"for feedback control. To this end, the author's recent work [32] proposed \"\n",
      "                        'a data-driven KKL observer by appending a kernel dimensionality reduction '\n",
      "                        'scheme to the LTI dynamics, thus obtaining estimates that are '\n",
      "                        'diffeomorphic to the states.\\n'\n",
      "                        '\\n'\n",
      "                        'Also, the current approach is yet restricted to autonomous systems. For '\n",
      "                        'control purposes, it should be further extended to non-autonomous ones, '\n",
      "                        'where the Bernard-Andrieu observer structure [18] is anticipated. Also, '\n",
      "                        'the application of such data-driven state observers to learning '\n",
      "                        'control-relevant properties of nonlinear dynamical systems and controller '\n",
      "                        'synthesis [33, 34] is undergoing active research.',\n",
      "                'value': 'V Conclusions and Discussions'}],\n",
      "  'header': 'h1',\n",
      "  'text': '',\n",
      "  'value': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural '\n",
      "           'Networks'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(hierarchical_structure, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_texts(node):\n",
    "    texts = [node[\"text\"]]\n",
    "    for child in node[\"children\"]:\n",
    "        texts.extend(get_node_texts(child))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 II Preliminaries 2\n",
      "h2 III Analysis on the Generalized Loss 0\n",
      "h2 IV Case Study 0\n",
      "h2 V Conclusions and Discussions 0\n"
     ]
    }
   ],
   "source": [
    "## Top Section\n",
    "top_section = hierarchical_structure[0]\n",
    "header_type = top_section[\"header\"]\n",
    "section_name = top_section[\"value\"]\n",
    "print(header_type, section_name)\n",
    "\n",
    "\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = []\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    if section_name.lower()==\"abstract\":\n",
    "        continue\n",
    "    \n",
    "    section_text = get_node_texts(section)\n",
    "    section_texts.append(section_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4958, 9149, 7740, 5915, 1977]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(\"\\n\".join(x)) for x in section_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': 'h2',\n",
       " 'value': 'II Preliminaries',\n",
       " 'children': [{'header': 'h3',\n",
       "   'value': '_KKL Observer_',\n",
       "   'children': [],\n",
       "   'text': 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.'},\n",
       "  {'header': 'h3',\n",
       "   'value': '_Lipschitz-Bounded Neural Networks_',\n",
       "   'children': [],\n",
       "   'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'}],\n",
       " 'text': 'We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_section[\"children\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.',\n",
       " 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.',\n",
       " 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_texts = get_node_texts(top_section[\"children\"][2])\n",
    "print(len(section_texts))\n",
    "section_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section count test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 7220/10000 [00:00<00:00, 8795.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR 5786 - [{'header': 'h2', 'value': 'Abstract', 'children': [{'header': 'h6', 'value': 'Contents', 'children': [], 'text': '* 1 Introduction\\n* 2 Model and Method\\n\\t* 2.1 Model\\n\\t* 2.2 Method\\n\\t* 2.3 Dynamical Correlation Functions\\n\\t* 2.4 Current-current correlation function\\n* 3 Correlation functions\\n\\t* 3.1 \\\\(T=0\\\\)'}], 'text': \"**Using variational matrix product states, we analyze the finite temperature behavior of a half-filled periodic Anderson model in one dimension, a prototypical model of a Kondo insulator. We present an extensive analysis of single-particle Green's functions, two-particle Green's functions, and transport functions creating a broad picture of the low-temperature properties. We confirm the existence of energetically low-lying spin excitations in this model and study their energy-momentum dispersion and temperature dependence. We demonstrate that charge-charge correlations at the Fermi energy exhibit a different temperature dependence than spin-spin correlations. While energetically low-lying spin excitations emerge approximately at the Kondo temperature, which exponentially depends on the interaction strength, charge correlations vanish already at high temperatures. Furthermore, we analyze the charge and thermal conductivity at finite temperatures by calculating the time-dependent current-current correlation functions. While both charge and thermal conductivity can be fitted for all interaction strengths by gapped systems with a renormalized band gap, the gap in the system describing the thermal conductivity is generally smaller than the system describing the charge conductivity. Thus, two-particle correlations affect the charge and heat conductivities in a different way resulting in a temperature region where the charge conductivity of this one-dimensional Kondo insulator is already decreasing while the heat conductivity is still increasing.**\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:01<00:00, 8996.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has title 8468, no title 1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_sections = []\n",
    "has_title_count = 0\n",
    "no_title_count = 0\n",
    "\n",
    "for idx in tqdm(range(df.shape[0])):\n",
    "    text = df.iloc[idx]['markdown']\n",
    "    hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "    \n",
    "    # has H1 Title \n",
    "    if len(hierarchical_structure)==1 and hierarchical_structure[0]['header']=='h1':\n",
    "        has_title_count+=1\n",
    "        num_section = 0\n",
    "        top_section = hierarchical_structure[0]\n",
    "        for section in top_section[\"children\"]:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    elif len(hierarchical_structure)>1:\n",
    "        no_title_count+=1\n",
    "        num_section = 0\n",
    "        for section in hierarchical_structure:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    else:\n",
    "        print(\"ERR {} - {}\".format(idx, hierarchical_structure, len(hierarchical_structure)))\n",
    "        \n",
    "print(\"has title {}, no title {}\".format(has_title_count, no_title_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX 43 AVG 5.901490149014902 MIN 0\n"
     ]
    }
   ],
   "source": [
    "num_sections_np = np.array(num_sections)\n",
    "print(\"MAX {} AVG {} MIN {}\".format(num_sections_np.max(), num_sections_np.mean(), num_sections_np.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sections_np[num_sections_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  27,   54,   88,  160,  190,  218,  250,  259,  271,  304,  344,\n",
       "        384,  521,  523,  524,  563,  571,  624,  742,  760,  820,  868,\n",
       "       1006, 1095, 1147, 1208, 1232, 1237, 1263, 1297])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_sections_np==2).nonzero()[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 Appendix A Complex representation of a real wave 0\n"
     ]
    }
   ],
   "source": [
    "# idx = 7843 ## 43 sections\n",
    "# https://arxiv.org/pdf/2308.03803\n",
    "\n",
    "idx = 27 ## 2 sections\n",
    "# https://arxiv.org/pdf/2301.09285\n",
    "text = df.iloc[idx]['markdown']\n",
    "# print(text)\n",
    "hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "print(len(hierarchical_structure[0]['children']))\n",
    "hierarchical_structure\n",
    "\n",
    "for section in hierarchical_structure[0][\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.hist(num_sections, bins = 50)\n",
    "plt.xlim(-1, 20)\n",
    "plt.title(\"Number of identitified sections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2. md2py based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from md2py import md2py, TreeOfContents\n",
    "from src.custom_md2py import md2py, TreeOfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs\n",
      "Depth: 3\n",
      "Heading: None\n",
      "Branches: 0\n",
      "Expanded Branches: 0\n",
      "------------------------------\n",
      "h6 Abstract\n",
      "Depth: 3\n",
      "Heading: 6\n",
      "Branches: 0\n",
      "Expanded Branches: 0\n",
      "------------------------------\n",
      "p Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over (8\\%) performance gains.\n",
      "Depth: 3\n",
      "Heading: None\n",
      "Branches: 0\n",
      "Expanded Branches: 0\n",
      "------------------------------\n",
      "h2 1 Introduction\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "SUBCHILD 1 - tag p\n",
      "SUBCHILD 2 - tag p\n",
      "SUBCHILD 3 - tag p\n",
      "Branches: 4\n",
      "Expanded Branches: 4\n",
      "------------------------------\n",
      "h2 2 Related Work\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag h3\n",
      "SUBCHILD 1 - tag h3\n",
      "Branches: 2\n",
      "Expanded Branches: 7\n",
      "------------------------------\n",
      "h2 3 Method\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "SUBCHILD 1 - tag h3\n",
      "SUBCHILD 2 - tag h3\n",
      "SUBCHILD 3 - tag h3\n",
      "Branches: 4\n",
      "Expanded Branches: 15\n",
      "------------------------------\n",
      "h2 4 Experiment\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "SUBCHILD 1 - tag p\n",
      "SUBCHILD 2 - tag h3\n",
      "SUBCHILD 3 - tag h3\n",
      "SUBCHILD 4 - tag h3\n",
      "Branches: 5\n",
      "Expanded Branches: 19\n",
      "------------------------------\n",
      "h2 5 Conclusion\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "SUBCHILD 1 - tag p\n",
      "SUBCHILD 2 - tag p\n",
      "Branches: 3\n",
      "Expanded Branches: 3\n",
      "------------------------------\n",
      "h2 6 Limitations\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "Branches: 1\n",
      "Expanded Branches: 1\n",
      "------------------------------\n",
      "h2 7 Ethics Statement\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "Branches: 1\n",
      "Expanded Branches: 1\n",
      "------------------------------\n",
      "h2 Acknowledgement\n",
      "Depth: 3\n",
      "Heading: 2\n",
      "SUBCHILD 0 - tag p\n",
      "Branches: 1\n",
      "Expanded Branches: 1\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "src.custom_md2py.TreeOfContents"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test md2py\n",
    "idx = 0 # has title\n",
    "# [Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks]\n",
    "idx = 14 # has sections\n",
    "# [Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs,\n",
    "#  Abstract,\n",
    "#  Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over (8\\%) performance gains.,\n",
    "#  1 Introduction,\n",
    "#  2 Related Work,\n",
    "#  3 Method,\n",
    "#  4 Experiment,\n",
    "#  5 Conclusion,\n",
    "#  6 Limitations,\n",
    "#  7 Ethics Statement,\n",
    "#  Acknowledgement]\n",
    "\n",
    "sample = df.iloc[idx][\"markdown\"]\n",
    "toc = md2py(sample)\n",
    "toc.branches\n",
    "for child in toc.branches:\n",
    "    print(child.name, child.string)\n",
    "    print(\"Depth:\",child.depth)\n",
    "    print(\"Heading:\",TreeOfContents.getHeadingLevel(child))\n",
    "    for subchild_i, subchild in enumerate(child.branches):\n",
    "        print(\"SUBCHILD {} - tag {}\".format(subchild_i, subchild.name))\n",
    "        # print(subchild.string)\n",
    "    expanded_children = child.expandDescendants(child)\n",
    "    print(\"Branches:\", len(child.branches))\n",
    "    print(\"Expanded Branches:\", len(expanded_children))\n",
    "    \n",
    "    print('-'*30)\n",
    "type(toc.branches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
