{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7) Index(['id', 'title', 'abstract', 'authors', 'published_date', 'link',\n",
      "       'markdown'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(settings.data_dir, \"arxiver/data/train.parquet\"))\n",
    "## Sample 10k\n",
    "df = df.sample(10000)\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"sample.parquet\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Splitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "This paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\(H_{2}\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.\n",
      "\n",
      "## I Introduction\n",
      "\n",
      "For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\(Q\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.\n",
      "\n",
      "Hence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.\n",
      "\n",
      "This paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.\n",
      "\n",
      "It is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\n",
      "the neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.\n",
      "\n",
      "Hence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\(H_{2}\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.\n",
      "\n",
      "## II Preliminaries\n",
      "\n",
      "We consider a nonlinear autonomous system:\n",
      "\n",
      "\\[\\dot{x}(t)=f(x(t)),\\quad y(t)=h(x(t)) \\tag{1}\\]\n",
      "\n",
      "where \\(x(t)\\in\\mathcal{X}\\subseteq\\mathbb{R}^{n}\\) is the vector of states and \\(y(t)\\in\\mathbb{R}^{m}\\) represents the outputs. For simplicity, we will consider \\(m=1\\). It is assumed that \\(f\\) and \\(h\\) are smooth on \\(\\mathcal{X}\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.\n",
      "\n",
      "### _KKL Observer_\n",
      "\n",
      "For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\n",
      "\n",
      "\\[\\dot{z}(t)=Az(t)+By(t),\\quad\\hat{x}(t)=T^{\\dagger}(z(t)). \\tag{2}\\]\n",
      "\n",
      "Here the observer states \\(z\\in\\mathbb{R}^{n_{z}}\\) has an LTI dynamics. The matrices \\(A\\) and \\(B\\) are chosen under the requirements of (i) controllability of \\((A,B)\\) should be controllable, (ii) Hurwitz property of \\(A\\), and (iii) sufficiently high dimension of \\(z\\) (\\(n_{z}\\)), which should be at least \\(n+1\\) if \\((A,B)\\) is complex [17] and at least \\(2n+1\\) if \\((A,B)\\) is real [29]. The mapping from the observer states \\(z\\) to the state estimates \\(\\hat{x}\\) is a static one, \\(T^{\\dagger}\\), which is the left-pseudoinverse of a nonlinear immersion \\(T\\) (i.e., a differentiable injection satisfying \\(T^{\\dagger}\\circ T=\\mathsf{id}\\)). This immersion \\(T\\) should satisfy the following PDE:\n",
      "\n",
      "\\[\\frac{\\partial T}{\\partial x}(x)f(x)=AT(x)+Bh(x),\\quad\\forall x\\in\\mathcal{X}, \\tag{3}\\]\n",
      "\n",
      "where \\(\\partial T/\\partial x\\) denotes the Jacobian matrix of \\(T\\). It can be easily verified that under the above PDE, \\(dT(x)/dt=AT(x)+By\\), and thus \\(z-T(x)\\) has an exponentially decaying dynamics, as \\(A\\) is Hurwitz.\n",
      "\n",
      "The conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\(\\dot{x}=f(x)\\) at time \\(t\\) with initial condition \\(x(0)=\\xi\\) as \\(\\Phi_{t}(\\xi)\\). For any open set \\(\\mathcal{O}\\) in \\(\\mathcal{X}\\), denote the backward time instant after which the solution does not escape this region by \\(\\varsigma_{\\mathcal{O}}(\\xi)=\\inf\\{t|\\Phi_{t}(\\xi)\\in\\mathcal{O}\\}\\). Also denote \\(\\mathcal{O}+\\epsilon:=\\{\\xi+\\eta|\\xi\\in\\mathcal{O},\\|\\eta\\|<\\epsilon\\}\\).\n",
      "\n",
      "**Definition 1** (Backward distinguishability).: _The system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable if for any distinct \\(\\xi,\\xi^{\\prime}\\in\\mathcal{X}\\) there exists a negative \\(t>\\varsigma_{\\mathcal{O}+\\epsilon}(\\xi)\\wedge\\varsigma_{\\mathcal{O}+\\epsilon} (\\xi^{\\prime})\\) such that \\(h(\\Phi_{t}(\\xi))\\neq h(\\Phi_{t}(\\xi^{\\prime}))\\)._\n",
      "\n",
      "**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\(\\mathcal{O}\\subseteq\\bar{\\mathcal{X}}\\) and a positive constant \\(\\epsilon\\) such that the system (1) is \\((\\mathcal{O},\\epsilon)\\)-backward distinguishable. Then there exists a constant \\(\\rho>0\\) such that for all but a Lebesgue-zero-measure set of \\((A,B)\\in\\mathbb{R}^{(2n+1)\\times(2n+1)}\\times\\mathbb{R}^{(2n+1)}\\), if \\(A+\\rho I\\) Hurwitz, then there exists an immersion \\(T:\\mathcal{O}\\rightarrow\\mathbb{R}^{(2n+1)}\\) solving the PDEs (3)._\n",
      "\n",
      "The above theorem clarifies that as long as the spectrum of \\(A\\) is restricted to the left of \\(-\\rho+i\\mathbb{R}\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\((A,B)\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\(T^{\\dagger}\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.\n",
      "\n",
      "### _Lipschitz-Bounded Neural Networks_\n",
      "\n",
      "Consider a \\(\\nu\\)-layer neural network \\(\\hat{x}=S(z,\\theta)\\) with all parameters denoted as a single vector \\(\\theta\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\(\\sigma:\\mathbb{R}\\rightarrow\\mathbb{R}\\), with slope bounded in \\([0,1]\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\n",
      "\n",
      "\\[\\begin{split}& z^{\\ell+1}=\\sigma(W^{\\ell}z^{\\ell}+b^{\\ell}),\\ \\ \\ell=0,\\ldots,\\nu-1\\\\ & z^{0}=z,\\quad\\hat{x}=W^{\\nu}z^{\\nu}+b^{\\nu}.\\end{split} \\tag{4}\\]\n",
      "\n",
      "where \\(W^{0},\\ldots,W^{\\nu}\\) are the weight matrices and \\(b^{0},\\ldots,b^{\\nu}\\) are the biases. In total there are \\(\\nu\\) activation layers inserted between \\(\\nu+1\\) fully connected layers. \\(z\\) represents the inputs to the neural network and \\(\\hat{x}\\) is the output vector, as we will use such a neural network to approximate the \\(T^{\\dagger}\\) mapping in the KKL observer.\n",
      "\n",
      "Given a neural network with fixed parameters \\(\\theta=(W^{0},b^{0},\\ldots,W^{\\nu},b^{\\nu})\\), a rough estimate of the Lipschitz\n",
      "\n",
      "Fig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\n",
      "constant of \\(S\\) can be obviously obtained as\n",
      "\n",
      "\\[L_{S}(\\theta)=\\prod_{\\ell=0}^{\\nu}\\|W^{\\ell}\\|_{2}, \\tag{5}\\]\n",
      "\n",
      "where \\(\\|\\cdot\\|_{2}\\) for a matrix refers to its operator norm induced by the \\(\\ell_{2}\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\n",
      "\n",
      "The recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\n",
      "\n",
      "**Definition 2** (\\(1\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\(X\\in\\mathbb{R}^{d\\times d}\\), \\(Y\\in\\mathbb{R}^{c\\times d}\\), \\(s\\in\\mathbb{R}^{d}\\), and \\(b\\in\\mathbb{R}^{d}\\), a \\(1\\)-Lipschitz sandwich layer is defined as such a mapping \\(\\Xi:\\mathbb{R}^{c}\\rightarrow\\mathbb{R}^{d}\\) that maps any \\(h\\in\\mathbb{R}^{c}\\) into a \\(\\Xi(h;X,Y,s,b)\\in\\mathbb{R}^{d}\\) according to the following formulas:_\n",
      "\n",
      "\\[Z =X-X^{\\top}+Y^{\\top}Y,\\ \\Psi_{s}=\\mathrm{diag}(e^{s}) \\tag{6}\\] \\[M_{X,Y} =\\left[(I+Z)^{-1}(I-Z)\\right]^{\\top},\\] \\[N_{X,Y} =\\left[-2Y(I+Z)^{-1}\\right]^{\\top},\\] \\[\\Xi(h) =\\sqrt{2}M_{X,Y}^{\\top}\\Psi_{s}\\sigma(\\sqrt{2}\\Psi_{s}^{-1}N_{X, Y}h+b).\\]\n",
      "\n",
      "It turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\(1\\)[28, Theorem 3.3]. The mapping from the input \\(h\\) to the output \\(\\Xi(h)\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\((X,Y)\\) to \\((M,N)\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\n",
      "\n",
      "Thus, by stacking a number of such sandwich layers after a scaling by \\(\\sqrt{\\gamma}\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\(\\Xi\\) as in Equation (6)), a neural network with Lipschitz bound \\(\\gamma\\) can be obtained, for any provided \\(\\gamma>0\\).\n",
      "\n",
      "**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\(S(\\cdot|\\theta)\\), by a neural network in the following architecture:_\n",
      "\n",
      "\\[h^{0} =\\sqrt{\\gamma}z; \\tag{7}\\] \\[h^{\\ell+1} =\\Xi(h^{\\ell};X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}),\\ \\ell=0,1,\\ldots,\\nu-1;\\] \\[\\hat{x} =\\sqrt{\\gamma}N_{X^{\\nu},Y^{\\nu}}h^{\\nu}+b^{\\nu}.\\]\n",
      "\n",
      "_Here the parameters include_\n",
      "\n",
      "\\[\\theta=\\{X^{\\ell},Y^{\\ell},s^{\\ell},b^{\\ell}\\}_{\\ell=0}^{\\nu-1}\\cup\\{X^{\\nu}, Y^{\\nu},b^{\\nu}\\}\\]\n",
      "\n",
      "_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\(z\\) and \\(\\hat{x}\\), respectively._\n",
      "\n",
      "The above-defined Wang-Manchester network satisfies \\(\\|S(\\cdot|\\theta)\\|_{\\mathrm{Lip}}\\leq\\gamma\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.\n",
      "\n",
      "## III Analysis on the Generalized Loss\n",
      "\n",
      "Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.\n",
      "\n",
      "**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\(\\mathcal{F}\\) on \\(\\mathcal{X}\\). The distribution \\(\\mathcal{F}\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\(\\mathcal{F}\\)._\n",
      "\n",
      "Suppose that The LTI dynamics of the KKL observer, \\((A,B)\\), is fixed. Then the observer states can be simulated from this linear dynamics.\n",
      "\n",
      "**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\(y=h(x)\\), but instead containing a white noise of unknown covariance \\(\\sigma^{2}\\). In other words, the simulation from \\(y\\) to \\(z\\) is_\n",
      "\n",
      "\\[\\begin{split}&\\dot{z}=Ax+By+w,\\quad\\mathbb{E}[w(t)]=0,\\,\\forall t \\in\\mathbb{R}\\\\ &\\mathbb{E}[w(t)w(s)]=\\delta(t-s)\\sigma^{2},\\,\\forall t,s\\in \\mathbb{R}.\\end{split} \\tag{8}\\]\n",
      "\n",
      "In this way, the collected sample, denoted as \\(\\{(x(t_{i}),z(t_{i}))\\}_{i=1}^{m}=\\{(x_{i},z_{i})\\}_{i=1}^{m}\\), in fact satisfies the following relation:\n",
      "\n",
      "\\[z_{i}=\\bar{z}_{i}+v_{i},\\quad\\delta_{i}=\\int_{-\\infty}^{t_{i}}g(\\tau)w(t_{i}- \\tau)d\\tau. \\tag{9}\\]\n",
      "\n",
      "Here \\(g(\\tau)\\) is the impulse response of LTI system \\((A,B)\\); \\(\\bar{z}\\) is the value of \\(z(t_{i})\\) that would be otherwise obtained if there were no white noises in the output measurements.\n",
      "\n",
      "**Assumption 3** (Sufficient decay).: _After a significantly long time \\(t_{\\epsilon}\\), \\(\\|z-T(x)\\|\\leq\\epsilon\\) for a small enough \\(z\\). Here \\(T\\) is the nonlinear immersion map specified by (3)._\n",
      "\n",
      "Fig. 2: A sandwich layer and its parameters.\n",
      "Then, \\(\\|\\bar{z}_{i}-T(x_{i})\\|\\leq\\epsilon\\). Thus, we may write\n",
      "\n",
      "\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\prime},\\quad\\|v_{i}^{\\prime}\\|\\leq\\epsilon. \\tag{10}\\]\n",
      "\n",
      "Now we suppose that the sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{m}\\) is used to train a neural network \\(S(\\cdot|\\theta)\\), which gives the state observations \\(\\hat{x}_{i}=S(z_{i}|\\theta)\\), and that the resulting empirical loss, if defined as the average squared observation error, is\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta):=\\frac{1}{m}\\sum_{i=1}^{m}\\|\\hat{x}_{i}-x_{i}\\|^{2}. \\tag{11}\\]\n",
      "\n",
      "Then we get\n",
      "\n",
      "\\[\\hat{R}_{S}(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\left\\|S\\left(T(x_{i})+v_{i}+v_{i }^{\\prime}|\\theta\\right)-x_{i}\\right\\|^{2}. \\tag{12}\\]\n",
      "\n",
      "**Assumption 4**.: _Assume that the probability distribution \\(\\mathcal{F}\\) is supported by a compact set, i.e., if \\(x\\sim\\mathcal{F}\\), then \\(x\\) should be almost surely bounded._\n",
      "\n",
      "It follows that both \\(S(\\cdot|\\theta)\\) and \\(T\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\(L_{S}(\\theta)\\) and \\(L_{T}\\), respectively. We have\n",
      "\n",
      "\\[\\|S\\left(T(x_{i})+\\delta_{i}+\\delta_{i}^{\\prime}|\\theta\\right)-S\\left(T(x_{i}) |\\theta\\right)\\|\\leq L_{S}(\\theta)L_{T}(\\|v_{i}\\|+\\epsilon). \\tag{13}\\]\n",
      "\n",
      "Denote \\(D\\) as the essential upper bound of \\(\\|x\\|\\) on the distribution \\(\\mathcal{F}\\). As such, without loss of generality, let \\(S(T(0))=0\\). Then \\(\\|x-S(T(x))\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely. Combining the above two equations, we further get\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{14}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}(\\theta)L_{T}(L_{S}(\\theta)L _{T}+1)D(\\|v_{i}\\|+\\epsilon)\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}L_{S}^{2}(\\theta)L_{T}^{2}(\\|v_{i} \\|+\\epsilon)^{2}.\\]\n",
      "\n",
      "That is,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq \\hat{R}_{S}(\\theta) \\tag{15}\\] \\[\\quad+\\frac{1}{m}\\sum_{i=1}^{m}(L_{S}(\\theta)L_{T}+1)^{2}\\left(D+ \\|v_{i}\\|+\\epsilon\\right)(\\|v_{i}\\|+\\epsilon).\\]\n",
      "\n",
      "The left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\(z_{i}=T(x_{i})\\), \\(i=1,\\ldots,m\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{16}\\] \\[\\quad\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}+(D+2\\epsilon) \\left(\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)^{1/2}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Given that \\(v_{i}\\) is the response of LTI system \\((A,B)\\) to a white noise of covariance \\(\\sigma^{2}\\), \\(\\mathbb{E}(\\|v_{i}\\|^{2})=h^{2}\\sigma^{2}\\) where \\(h\\) is the \\(H_{2}\\)-norm of the system \\((A,B)\\) where \\(A\\) is Hurwitz. Therefore,\n",
      "\n",
      "\\[\\mathbb{E}\\left(\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\right)=h^{2}\\sigma^{2}. \\tag{17}\\]\n",
      "\n",
      "Let \\(\\alpha\\) be a small positive number. With confidence \\(1-\\alpha/2\\), a conservative estimation for its upper bound can be found according to Markov inequality:\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|v_{i}\\|^{2}\\leq\\frac{1}{1-\\alpha/2}h^{2}\\sigma^{2}. \\tag{18}\\]\n",
      "\n",
      "Therefore,\n",
      "\n",
      "\\[\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}\\leq\\hat {R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\times \\tag{19}\\] \\[\\quad\\left[\\frac{h^{2}\\sigma^{2}}{1-\\alpha/2}+(D+2\\epsilon)\\frac{ h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon\\right].\\]\n",
      "\n",
      "Finally, we note that for \\(x\\sim\\mathcal{F}\\), now that \\(\\|x-S(T(x)|\\theta)\\|\\leq(L_{S}(\\theta)L_{T}+1)D\\) almost surely, by Hoeffding's inequality, for any \\(\\varepsilon>0\\),\n",
      "\n",
      "\\[\\mathbb{P}\\bigg{(}\\bigg{|}\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{ i})|\\theta)\\|^{2}-\\mathbb{E}\\left(\\|x-S(T(x))\\|^{2}\\right)\\bigg{|} \\tag{20}\\] \\[\\geq(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\varepsilon\\bigg{)}\\leq 2\\exp \\left(-2m\\varepsilon^{2}\\right).\\]\n",
      "\n",
      "Thus, with confidence \\(1-\\alpha/2\\), we have\n",
      "\n",
      "\\[\\left|\\frac{1}{m}\\sum_{i=1}^{m}\\|x_{i}-S(T(x_{i})|\\theta)\\|^{2}- \\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right)\\bigg{|}\\right. \\tag{21}\\] \\[\\quad<(L_{S}(\\theta)L_{T}+1)^{2}D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m }}.\\]\n",
      "\n",
      "Combining (19) and (21), we have the following theorem.\n",
      "\n",
      "**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_\n",
      "\n",
      "\\[R_{S}(\\theta)=\\mathbb{E}\\left(\\|x-S(T(x)|\\theta)\\|^{2}\\right), \\tag{22}\\]\n",
      "\n",
      "_is related to the empirical loss as defined in (11) by_\n",
      "\n",
      "\\[R_{S}(\\theta)<\\hat{R}_{S}(\\theta)+(L_{S}(\\theta)L_{T}+1)^{2}\\Delta(h,\\sigma, \\alpha,\\epsilon). \\tag{23}\\]\n",
      "\n",
      "_with confidence \\(1-\\alpha\\) (\\(\\alpha\\in(0,1)\\)). Here_\n",
      "\n",
      "\\[\\Delta(h,\\sigma,\\alpha,\\epsilon)= D^{2}\\sqrt{\\frac{\\ln(4/\\alpha)}{2m}}+\\frac{h^{2}\\sigma^{2}}{1- \\alpha/2} \\tag{24}\\] \\[+(D+2\\epsilon)\\frac{h\\sigma}{\\sqrt{1-\\alpha/2}}+(D+\\epsilon)\\epsilon.\\]\n",
      "\n",
      "The theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\(L_{S}(\\theta)\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\(\\sigma\\)\n",
      "and \\(\\epsilon\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\(\\|x-S(T(x)|\\theta)\\|\\), which acts as a coefficient before the Hoeffding term \\(\\sqrt{\\ln(4/\\alpha)/2m}\\), and (ii) the effect of noisy measurements on the observer states.\n",
      "\n",
      "**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\(L_{S}(\\theta)\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\((A,B)\\) along with the neural network \\(S(\\cdot|\\theta)\\), as the dependence of \\(L_{T}\\) on \\((A,B)\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\((A,B)\\) and the neural network._\n",
      "\n",
      "## IV Case Study\n",
      "\n",
      "Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:\n",
      "\n",
      "\\[\\dot{x}_{1} =10(x_{2}-x_{1}), \\tag{25}\\] \\[\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\] \\[\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\]\n",
      "\n",
      "Suppose that the measurement used for state observation is \\(y=x_{2}\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\(0.01\\). The LTI part of the KKL observer, \\(A=-\\mathrm{diag}(8,4,2,1)\\) and \\(B=[1,1,1,1]^{\\top}\\) are chosen. At the beginning of the observer simulation, \\(z(0)=0\\) is set as the initial condition; we simulate the dynamics until \\(t=500\\) and randomly collect \\(m=2000\\) time instants between \\(t=20\\) and \\(t=500\\) as the training data.\n",
      "\n",
      "Consider first the case with noiseless measurement (\\(\\sigma=0\\)). The sample \\(\\{(x_{i},z_{i})\\}_{i=1}^{2000}\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\(z_{i}\\) indeed captures the structure of such a Lorenz attractor in a \\(4\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\(80\\%\\) of the sample under the mean-squares loss metric, and validate using the remaining \\(20\\%\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\(10^{-3}\\) is used for optimization. The number of epochs is empirically tuned to \\(300\\). The neural network has \\(2\\) hidden layers, each containing \\(8\\) neurons, resulting in \\(292\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\(1.5\\) seconds (for a randomly initialized network).\n",
      "\n",
      "Varying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.\n",
      "\n",
      "* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\(1000\\), the \\(L_{S}\\) after training does not exceed \\(300\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\n",
      "* When the Lipschitz bound is small, relaxing the restriction on \\(L_{S}\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\(L_{S}\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and\n",
      "\n",
      "Fig. 3: Sample collected from the Lorenz system.\n",
      "validation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\n",
      "* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\(\\sigma=1\\), a suitable choice can be \\(\\gamma=100\\), whereas at \\(\\sigma=5\\) and \\(\\sigma=10\\), \\(\\gamma\\) can be chosen as \\(30\\) and \\(10\\), respectively.\n",
      "\n",
      "Now suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\(\\sigma=0\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\(L_{S}\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\(\\sigma\\geq 3\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\n",
      "\n",
      "Finally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\(L_{S}=10\\), and applying it to environments with noise \\(\\sigma=0.1\\), \\(0.3\\), \\(1.0\\), \\(3.0\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\(10\\) time units. Naturally, when \\(\\sigma\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\(\\sigma\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\(3<t<4\\) or \\(8<t<9\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.\n",
      "\n",
      "## V Conclusions and Discussions\n",
      "\n",
      "This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.\n",
      "\n",
      "Fig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)\n",
      "\n",
      "Fig. 5: Errors of noiselessly trained observers in noisy environments.\n",
      "We implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.\n",
      "\n",
      "Also, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Sample\n",
    "'''\n",
    "Abstract is usually defined as\n",
    "'###### Abstract'\n",
    "'''\n",
    "idx = 0\n",
    "# idx = 15\n",
    "sample = df.iloc[idx]['markdown']\n",
    "# print(len(sample), sample[:200])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks'}, page_content='###### Abstract  \\nThis paper focuses on the _model-free_ synthesis of state observers for nonlinear autonomous systems without knowing the governing equations. Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure is leveraged, where the outputs are fed into a linear time-invariant (LTI) system to obtain the observer states, which can be viewed as the states nonlinearly transformed by an immersion mapping, and a neural network is used to approximate the inverse of the nonlinear immersion and estimate the states. In view of the possible existence of noises in output measurements, this work proposes to impose an upper bound on the Lipschitz constant of the neural network for robust and safe observation. A relation that bounds the generalization loss of state observation according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of the LTI part in the KKL observer, is established, thus reducing the model-free observer synthesis problem to that of Lipschitz-bounded neural network training, for which a direct parameterization technique is used. The proposed approach is demonstrated on a chaotic Lorenz system.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'I Introduction'}, page_content='For nonlinear systems that arise from realistic engineering applications such as transport-reaction processes, modern control theory relies on _state-space representations_ for their modeling, analysis, and control [1, 2, 3]. Recent advances in nonlinear control have highlighted the role of data-driven (machine learning) techniques in identifying governing equations or underlying dynamical structures [4, 5, 6], analyzing system and control-theoretic properties [7, 8], and synthesizing model-free controllers [9, 10, 11]. In these efforts, it is often assumed that the _state_ information is available for analysis or control; for example, in reinforcement learning (RL) literature, it is common to apply stochastic first-order optimization to learn a value (cost) function or \\\\(Q\\\\) function based on temporal actions and state measurements. In many (if not most) control engineering applications, such as in chemical processes, however, it is more likely that the states are not measurable.  \\nHence, for nonlinear control in a state-space framework, a _state observer_ is necessary, whereby the states are estimated based on input and output history [12]. A recent review on model-based approaches to synthesize state observers is found in Bernard, Andrieu, and Astolfi [13]. A classical form of state observer for linear systems is known as Luenberger observer [14], which an auxiliary linear time-invariant (LTI) system that uses the plant outputs as inputs and returns state estimates. The observer states are in fact a linear transform of the plant states [15]. The idea was extended to nonlinear systems in the seminal work of Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) observer (as named in Andrieu and Praly [17]) still uses an LTI system to convert plant outputs to observer states, which turn out to be the plant states transformed via a nonlinear immersion. Thus, the observer synthesis problem reduces to the determination of this nonlinear immersion and its inverse, via solving (model-based) partial differential equations (PDEs). Such a KKL observer was extended from autonomous to actuated systems in [18], where the LTI part is replaced by an input-affine one with an additional nonlinear drift term associated with the actuated inputs.  \\nThis paper focuses on the _synthesis of KKL observer_ in a _model-free_ manner, without assuming prior knowledge on the plant dynamics. This is motivated by two reasons: (i) many nonlinear systems that involve complex kinetic or kinematic mechanisms are often hard to model accurately, and (ii) it can be challenging to solve the associated PDEs, especially in high-dimensional state space (in fact, there may not be well-posed boundary conditions). In the recent years, there have been several works that pioneered the use of neural networks in the observer problem. For example, Ramos et al. [19] first trained neural networks to approximate the inverse immersion map to reconstruct the actual states from observer states. Then, the optimization of pole placement was considered along with the training of inverse immersion in [20]. Niazi et al. [21] used physics-informed neural networks (PINNs) to approach a surrogate solution to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization problem to minimize the accumulated squared state observation error, whereby the optimality condition, through calculus of variations results in neural ODEs.  \\nIt is commonly known that neural networks, when over-parameterized with large widths and depths, may cause a deteriorated capability of generalization. It has also been argued that neural networks can be fragile to adversarial attacks to the training data and thus must be equipped with a self-defense mechanisms that warranty robustness [23, 24]. In particular, controlling the Lipschitz constant of the mapping specified by the neural network has been studied as a promising approach [25, 26, 27]. However, in these works, estimating and minimizing the Lipschitz constant requires the use of semidefinite programming routines, which has a high complexity when the number of neurons is large. An alternative way, called _direct paramterizaton_, as recently proposed in Wang and Manchester [28], is to translate the Lipschitz bound constraint into a special architecture of\\nthe neural layers, thus allowing the use of typical back-propagation (BP) to train the network in an unconstrained way.  \\nHence, in this work, the Wang-Manchester direct parameterization is adopted to train Lipschitz-bounded neural networks in a KKL state observer for any unknown nonlinear autonomous system. The paper establishes a relation between the generalized observation error and the Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of the LTI observer dynamics, under a typical white noise assumption on the plant outputs. Hence, by varying the Lipschitz bound, the optimal observer can be synthesized.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'II Preliminaries'}, page_content='We consider a nonlinear autonomous system:  \\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]  \\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.  \\n### _KKL Observer_  \\nFor nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as  \\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]  \\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:  \\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]  \\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.  \\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).  \\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._  \\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._  \\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.  \\n### _Lipschitz-Bounded Neural Networks_  \\nConsider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as  \\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]  \\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.  \\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz  \\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as  \\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]  \\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.  \\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].  \\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_  \\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]  \\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.  \\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).  \\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_  \\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]  \\n_Here the parameters include_  \\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]  \\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._  \\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'III Analysis on the Generalized Loss'}, page_content=\"Here we shall provide a justification for requiring a Lipschitz bound on the neural network. We will make the following standing assumptions on the training data collection procedure for subsequent analysis.  \\n**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is collected from the system, whose initial state is sampled from a probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure of the Perron-Frobenius operator), so that any point of the trajectory comes from \\\\(\\\\mathcal{F}\\\\)._  \\nSuppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. Then the observer states can be simulated from this linear dynamics.  \\n**Assumption 2** (Noisy measurements).: _Assume that the input signal for this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_  \\n\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall t \\\\in\\\\mathbb{R}\\\\\\\\ &\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in \\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]  \\nIn this way, the collected sample, denoted as \\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), in fact satisfies the following relation:  \\n\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- \\\\tau)d\\\\tau. \\\\tag{9}\\\\]  \\nHere \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); \\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise obtained if there were no white noises in the output measurements.  \\n**Assumption 3** (Sufficient decay).: _After a significantly long time \\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough \\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._  \\nFig. 2: A sandwich layer and its parameters.\\nThen, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may write  \\n\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. \\\\tag{10}\\\\]  \\nNow we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the resulting empirical loss, if defined as the average squared observation error, is  \\n\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. \\\\tag{11}\\\\]  \\nThen we get  \\n\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i }^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]  \\n**Assumption 4**.: _Assume that the probability distribution \\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if \\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._  \\nIt follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be Lipschitz continuous. Denote their Lipschitz constants as \\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have  \\n\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) |\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). \\\\tag{13}\\\\]  \\nDenote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let \\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely. Combining the above two equations, we further get  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L _{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} \\\\|+\\\\epsilon)^{2}.\\\\]  \\nThat is,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq \\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] \\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ \\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]  \\nThe left-hand side gives an estimation of the empirical loss when observing the states from perfect output measurements (namely when \\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last term and applying Cauchy-Schwarz inequality, we have  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) \\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nGiven that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a white noise of covariance \\\\(\\\\sigma^{2}\\\\), \\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the \\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. Therefore,  \\n\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. \\\\tag{17}\\\\]  \\nLet \\\\(\\\\alpha\\\\) be a small positive number. With confidence \\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be found according to Markov inequality:  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. \\\\tag{18}\\\\]  \\nTherefore,  \\n\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat {R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] \\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]  \\nFinally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),  \\n\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} \\\\tag{20}\\\\] \\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp \\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]  \\nThus, with confidence \\\\(1-\\\\alpha/2\\\\), we have  \\n\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- \\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. \\\\tag{21}\\\\] \\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m }}.\\\\]  \\nCombining (19) and (21), we have the following theorem.  \\n**Theorem 1**.: _Under the afore-mentioned assumptions, the generalization loss, defined as_  \\n\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), \\\\tag{22}\\\\]  \\n_is related to the empirical loss as defined in (11) by_  \\n\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, \\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]  \\n_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_  \\n\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- \\\\alpha/2} \\\\tag{24}\\\\] \\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]  \\nThe theorem shows that the Lipschitz constant of the neural network trained plays an important role in the generalized performance of the resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly that of amplifying the first and third terms defined on the right-hand side of (24), supposing that \\\\(\\\\sigma\\\\)\\nand \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise from (i) the overall upper bound of the observation error \\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of noisy measurements on the observer states.  \\n**Remark 1**.: _It is noted that the performance bound stated in the above theorem can be conservative. The conclusion that \\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement noise should be considered as qualitative. The theorem also does not suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does not consider the problem of simultaneously training \\\\((A,B)\\\\) and the neural network._\"),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'IV Case Study'}, page_content='Let us consider a Lorenz system in a 3-dimensional state space with chaotic behavior. The equation is written as:  \\n\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} =x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} =10x_{1}x_{2}-(8/3)x_{3}.\\\\]  \\nSuppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), where a white noise exists. We assign different values to the variance of the measurement noise and investigate how the resulting neural network should be chosen differently. To simulate the process we will use a sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, \\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and \\\\(t=500\\\\) as the training data.  \\nConsider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which shows that the data points are representative on the forward invariant set of the system, and that the observer states \\\\(z_{i}\\\\) indeed captures the structure of such a Lorenz attractor in a \\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network using a randomly selected \\\\(80\\\\%\\\\) of the sample under the mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) sample points. Stochastic gradient descent (SGD) algorithm with a learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) parameters to train in total. After training, the Lipschitz constant is evaluated a posteriori via the semidefinite programming approach of Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) seconds (for a randomly initialized network).  \\nVarying the prior bound on the Lipschitz constant, the resulting training loss, validation loss, and the posterior Lipschitz bound obtained from the same training conditions are illustrated in Fig. 4. The following observations can be made from these results.  \\n* As anticipated, as the set bound on the Lipschitz bound increases, the Lipschitz constant of the trained neural network becomes higher. The Lipschitz constants estimated a posteriori are lower than the prior bound on the Wang-Manchester network, validating the direct parameterization approach on constraining the slope. On the other hand, the actually posterior Lipschitz constant has an increasingly large lag behind the prior bound; for example, when the prior bound is \\\\(1000\\\\), the \\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that even for the training objective alone, there is a \"resistance\" to pursue the maximally possible Lipschitz constant.\\n* When the Lipschitz bound is small, relaxing the restriction on \\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the validation loss, showing that the Lipschitz bound is a bottleneck causing underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no longer exists; instead, overfitting will appear, with rising training and  \\nFig. 3: Sample collected from the Lorenz system.\\nvalidation losses. The overfitting phenomenon is more significant when the noise is large. Thus, there should be optimal values to be set as the Lipschitz bound.\\n* Depending on the noise magnitude, the deviation of posterior Lipschitz constant from the prior bound and the emergence of overfitting phenomenon occur at different threshold values of the Lipschitz bound. Thus, the Lipschitz bound to be used for neural network training should be tuned differently as the noise intensity varies. For example, at \\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at \\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as \\\\(30\\\\) and \\\\(10\\\\), respectively.  \\nNow suppose that at the observer design stage, the Wang-Manchester network is trained by the simulated data from a perfect digital twin of the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network trained to observe the states of the physical system, the environment is noisy. In Fig. 5, the resulting loss (mean squared state observation error) is plotted against varying prior Lipschitz bounds under multiple values of the environment noise magnitude. It is seen that when the noise is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic decrease in the observation error within a large range. On the other hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq 3\\\\)), the Lipschitz bound has a severe effect on the generalization loss, and since the achievable performance is restrictive, the fine-tuning of Lipschitz bound as a hyperparameter becomes critical.  \\nFinally, the performance of the state observer is examined. Consider using the network trained with noiseless simulation data under the prior Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The trajectories of the three components of estimated states by the observer are plotted against the true states in Fig. 6, within a time horizon of \\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state estimates can well track the true states and capture the trends in the correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered and the signals constructed by the observer are more noisy, occasionally yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or \\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz attractor). Overall, the state estimates mollifies the true state trajectories, which is due to the structure of our KKL observer - a linear filter (LTI system) as the state dynamics and a Lipschitz-bounded neural network as the static output map.'),\n",
       " Document(metadata={'Header 1': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks', 'Header 2': 'V Conclusions and Discussions'}, page_content=\"This work leverages the recent tools of Lipschitz-bounded neural networks for the synthesis of nonlinear state observers in a model-free setting. The observer, which has a Kazantzis-Kravaris structure, turns out to have a provable generalization performance that is related to the Lipschitz constant of the trained neural network (which represents the mapping from the observer states to the plant states). As such, by varying the Lipschitz bound and re-training the neural network, the optimal training result can yield the minimum generalized state observation error. The importance of bounding the Lipschitz constant has been demonstrated by a numerical case study on the Lorenz system.  \\nFig. 4: Loss and Lipschitz constants under different prior Lipschitz bounds. (Blue wedges: training loss, blue circles: validation loss, green circles: prior Lipschitz bound; green wedges: posterior Lipschitz bound.)  \\nFig. 5: Errors of noiselessly trained observers in noisy environments.\\nWe implicitly assumed here that a simulator of the dynamics is available, so that the true states' trajectories can be used to train the neural network. However, such ground truth for supervised learning may not actually exist in real applications, i.e., only inputs and outputs are recorded, yet a state observation mechanism is still needed or desired for feedback control. To this end, the author's recent work [32] proposed a data-driven KKL observer by appending a kernel dimensionality reduction scheme to the LTI dynamics, thus obtaining estimates that are diffeomorphic to the states.  \\nAlso, the current approach is yet restricted to autonomous systems. For control purposes, it should be further extended to non-autonomous ones, where the Bernard-Andrieu observer structure [18] is anticipated. Also, the application of such data-driven state observers to learning control-relevant properties of nonlinear dynamical systems and controller synthesis [33, 34] is undergoing active research.\")]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_splits = splitter.split_text(sample)\n",
    "print(len(sample_splits))\n",
    "sample_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_markdown_hierarchy(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "    # Define a pattern to match headers (from # to ######)\n",
    "    header_pattern = re.compile(r'^(#{1,6})\\s*(.*)$')\n",
    "\n",
    "    # Initialize the root of the hierarchy\n",
    "    root = {'children': []}\n",
    "    # Stack to keep track of the current hierarchy levels\n",
    "    stack = [{'level': 0, 'node': root}]\n",
    "    # Accumulate text for the current node\n",
    "    current_text = []\n",
    "\n",
    "    for line in lines:\n",
    "        header_match = header_pattern.match(line)\n",
    "        if header_match:\n",
    "            # If we have accumulated text, add it to the current node\n",
    "            if current_text:\n",
    "                # Join accumulated text and add to the last node's 'text'\n",
    "                stack[-1]['node'].setdefault('text', '')\n",
    "                if stack[-1]['node']['text']:\n",
    "                    stack[-1]['node']['text'] += '\\n'\n",
    "                stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "                current_text = []\n",
    "            # Extract header level and text\n",
    "            header_marks, header_text = header_match.groups()\n",
    "            level = len(header_marks)\n",
    "            # Pop the stack to find the correct parent level\n",
    "            while stack and stack[-1]['level'] >= level:\n",
    "                stack.pop()\n",
    "            # Create a new node for the header\n",
    "            node = {\n",
    "                'header': f'h{level}',\n",
    "                'value': header_text.strip(),\n",
    "                'children': []\n",
    "            }\n",
    "            # Add the new node to its parent's 'children'\n",
    "            stack[-1]['node']['children'].append(node) ## parent\n",
    "            # Push the new node onto the stack\n",
    "            stack.append({'level': level, 'node': node}) ## for accumulating potential children\n",
    "        else:\n",
    "            # Accumulate non-header lines\n",
    "            current_text.append(line)\n",
    "    # After processing all lines, add any remaining text\n",
    "    if current_text:\n",
    "        stack[-1]['node'].setdefault('text', '')\n",
    "        if stack[-1]['node']['text']:\n",
    "            stack[-1]['node']['text'] += '\\n'\n",
    "        stack[-1]['node']['text'] += '\\n'.join(current_text).strip()\n",
    "    # Return the hierarchy starting from the root's children\n",
    "    return root['children']\n",
    "hierarchical_structure = parse_markdown_hierarchy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'children': [{'children': [],\n",
      "                'header': 'h6',\n",
      "                'text': 'This paper focuses on the _model-free_ synthesis of state observers for '\n",
      "                        'nonlinear autonomous systems without knowing the governing equations. '\n",
      "                        'Specifically, the Kazantzis-Kravaris/Luenberger (KKL) observer structure '\n",
      "                        'is leveraged, where the outputs are fed into a linear time-invariant '\n",
      "                        '(LTI) system to obtain the observer states, which can be viewed as the '\n",
      "                        'states nonlinearly transformed by an immersion mapping, and a neural '\n",
      "                        'network is used to approximate the inverse of the nonlinear immersion and '\n",
      "                        'estimate the states. In view of the possible existence of noises in '\n",
      "                        'output measurements, this work proposes to impose an upper bound on the '\n",
      "                        'Lipschitz constant of the neural network for robust and safe observation. '\n",
      "                        'A relation that bounds the generalization loss of state observation '\n",
      "                        'according to the Lipschitz constant, as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI part in the KKL observer, is established, thus reducing the '\n",
      "                        'model-free observer synthesis problem to that of Lipschitz-bounded neural '\n",
      "                        'network training, for which a direct parameterization technique is used. '\n",
      "                        'The proposed approach is demonstrated on a chaotic Lorenz system.',\n",
      "                'value': 'Abstract'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'For nonlinear systems that arise from realistic engineering applications '\n",
      "                        'such as transport-reaction processes, modern control theory relies on '\n",
      "                        '_state-space representations_ for their modeling, analysis, and control '\n",
      "                        '[1, 2, 3]. Recent advances in nonlinear control have highlighted the role '\n",
      "                        'of data-driven (machine learning) techniques in identifying governing '\n",
      "                        'equations or underlying dynamical structures [4, 5, 6], analyzing system '\n",
      "                        'and control-theoretic properties [7, 8], and synthesizing model-free '\n",
      "                        'controllers [9, 10, 11]. In these efforts, it is often assumed that the '\n",
      "                        '_state_ information is available for analysis or control; for example, in '\n",
      "                        'reinforcement learning (RL) literature, it is common to apply stochastic '\n",
      "                        'first-order optimization to learn a value (cost) function or \\\\(Q\\\\) '\n",
      "                        'function based on temporal actions and state measurements. In many (if '\n",
      "                        'not most) control engineering applications, such as in chemical '\n",
      "                        'processes, however, it is more likely that the states are not '\n",
      "                        'measurable.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, for nonlinear control in a state-space framework, a _state '\n",
      "                        'observer_ is necessary, whereby the states are estimated based on input '\n",
      "                        'and output history [12]. A recent review on model-based approaches to '\n",
      "                        'synthesize state observers is found in Bernard, Andrieu, and Astolfi '\n",
      "                        '[13]. A classical form of state observer for linear systems is known as '\n",
      "                        'Luenberger observer [14], which an auxiliary linear time-invariant (LTI) '\n",
      "                        'system that uses the plant outputs as inputs and returns state estimates. '\n",
      "                        'The observer states are in fact a linear transform of the plant states '\n",
      "                        '[15]. The idea was extended to nonlinear systems in the seminal work of '\n",
      "                        'Kazantzis and Kravaris [16]. In their Kazantzis-Kravaris/Luenberger (KKL) '\n",
      "                        'observer (as named in Andrieu and Praly [17]) still uses an LTI system to '\n",
      "                        'convert plant outputs to observer states, which turn out to be the plant '\n",
      "                        'states transformed via a nonlinear immersion. Thus, the observer '\n",
      "                        'synthesis problem reduces to the determination of this nonlinear '\n",
      "                        'immersion and its inverse, via solving (model-based) partial differential '\n",
      "                        'equations (PDEs). Such a KKL observer was extended from autonomous to '\n",
      "                        'actuated systems in [18], where the LTI part is replaced by an '\n",
      "                        'input-affine one with an additional nonlinear drift term associated with '\n",
      "                        'the actuated inputs.\\n'\n",
      "                        '\\n'\n",
      "                        'This paper focuses on the _synthesis of KKL observer_ in a _model-free_ '\n",
      "                        'manner, without assuming prior knowledge on the plant dynamics. This is '\n",
      "                        'motivated by two reasons: (i) many nonlinear systems that involve complex '\n",
      "                        'kinetic or kinematic mechanisms are often hard to model accurately, and '\n",
      "                        '(ii) it can be challenging to solve the associated PDEs, especially in '\n",
      "                        'high-dimensional state space (in fact, there may not be well-posed '\n",
      "                        'boundary conditions). In the recent years, there have been several works '\n",
      "                        'that pioneered the use of neural networks in the observer problem. For '\n",
      "                        'example, Ramos et al. [19] first trained neural networks to approximate '\n",
      "                        'the inverse immersion map to reconstruct the actual states from observer '\n",
      "                        'states. Then, the optimization of pole placement was considered along '\n",
      "                        'with the training of inverse immersion in [20]. Niazi et al. [21] used '\n",
      "                        'physics-informed neural networks (PINNs) to approach a surrogate solution '\n",
      "                        'to solve the PDEs. Miao and Gatsis [22] formulated a dynamic optimization '\n",
      "                        'problem to minimize the accumulated squared state observation error, '\n",
      "                        'whereby the optimality condition, through calculus of variations results '\n",
      "                        'in neural ODEs.\\n'\n",
      "                        '\\n'\n",
      "                        'It is commonly known that neural networks, when over-parameterized with '\n",
      "                        'large widths and depths, may cause a deteriorated capability of '\n",
      "                        'generalization. It has also been argued that neural networks can be '\n",
      "                        'fragile to adversarial attacks to the training data and thus must be '\n",
      "                        'equipped with a self-defense mechanisms that warranty robustness [23, '\n",
      "                        '24]. In particular, controlling the Lipschitz constant of the mapping '\n",
      "                        'specified by the neural network has been studied as a promising approach '\n",
      "                        '[25, 26, 27]. However, in these works, estimating and minimizing the '\n",
      "                        'Lipschitz constant requires the use of semidefinite programming routines, '\n",
      "                        'which has a high complexity when the number of neurons is large. An '\n",
      "                        'alternative way, called _direct paramterizaton_, as recently proposed in '\n",
      "                        'Wang and Manchester [28], is to translate the Lipschitz bound constraint '\n",
      "                        'into a special architecture of\\n'\n",
      "                        'the neural layers, thus allowing the use of typical back-propagation (BP) '\n",
      "                        'to train the network in an unconstrained way.\\n'\n",
      "                        '\\n'\n",
      "                        'Hence, in this work, the Wang-Manchester direct parameterization is '\n",
      "                        'adopted to train Lipschitz-bounded neural networks in a KKL state '\n",
      "                        'observer for any unknown nonlinear autonomous system. The paper '\n",
      "                        'establishes a relation between the generalized observation error and the '\n",
      "                        'Lipschitz bound of the neural network as well as the \\\\(H_{2}\\\\)-norm of '\n",
      "                        'the LTI observer dynamics, under a typical white noise assumption on the '\n",
      "                        'plant outputs. Hence, by varying the Lipschitz bound, the optimal '\n",
      "                        'observer can be synthesized.',\n",
      "                'value': 'I Introduction'},\n",
      "               {'children': [{'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'For nonlinear systems, KKL observer generalizes the notion '\n",
      "                                      'of Luenberger observers that were restricted to linear '\n",
      "                                      'systems [14], providing a generic method for state '\n",
      "                                      'observation with mild assumptions to guarantee existence. '\n",
      "                                      'Specifically, the KKL observer for (1) is expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). '\n",
      "                                      '\\\\tag{2}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'Here the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has '\n",
      "                                      'an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are '\n",
      "                                      'chosen under the requirements of (i) controllability of '\n",
      "                                      '\\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property '\n",
      "                                      'of \\\\(A\\\\), and (iii) sufficiently high dimension of '\n",
      "                                      '\\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) '\n",
      "                                      'if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if '\n",
      "                                      '\\\\((A,B)\\\\) is real [29]. The mapping from the observer '\n",
      "                                      'states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a '\n",
      "                                      'static one, \\\\(T^{\\\\dagger}\\\\), which is the '\n",
      "                                      'left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., '\n",
      "                                      'a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ '\n",
      "                                      'T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy '\n",
      "                                      'the following PDE:\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\frac{\\\\partial T}{\\\\partial '\n",
      "                                      'x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, '\n",
      "                                      '\\\\tag{3}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian '\n",
      "                                      'matrix of \\\\(T\\\\). It can be easily verified that under the '\n",
      "                                      'above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) '\n",
      "                                      'has an exponentially decaying dynamics, as \\\\(A\\\\) is '\n",
      "                                      'Hurwitz.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The conditions for the existence of a KKL observer, namely '\n",
      "                                      'the solution to its defining PDE (3), have been established '\n",
      "                                      'based on the condition of backward distinguishability. In '\n",
      "                                      'below, we denote the solution to the ODEs '\n",
      "                                      '\\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition '\n",
      "                                      '\\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the '\n",
      "                                      'backward time instant after which the solution does not '\n",
      "                                      'escape this region by '\n",
      "                                      '\\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). '\n",
      "                                      'Also denote '\n",
      "                                      '\\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 1** (Backward distinguishability).: _The '\n",
      "                                      'system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward '\n",
      "                                      'distinguishable if for any distinct '\n",
      "                                      '\\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a '\n",
      "                                      'negative '\n",
      "                                      '\\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} '\n",
      "                                      '(\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq '\n",
      "                                      'h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Fact 1** (Existence of KKL observer, cf. Brivadis et al. '\n",
      "                                      '[29]).: _Assume that there is an open '\n",
      "                                      '\\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a '\n",
      "                                      'positive constant \\\\(\\\\epsilon\\\\) such that the system (1) '\n",
      "                                      'is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. '\n",
      "                                      'Then there exists a constant \\\\(\\\\rho>0\\\\) such that for '\n",
      "                                      'all but a Lebesgue-zero-measure set of '\n",
      "                                      '\\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), '\n",
      "                                      'if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion '\n",
      "                                      '\\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) '\n",
      "                                      'solving the PDEs (3)._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above theorem clarifies that as long as the spectrum of '\n",
      "                                      '\\\\(A\\\\) is restricted to the left of '\n",
      "                                      '\\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL '\n",
      "                                      'observer can be almost arbitrarily assigned. Once '\n",
      "                                      '\\\\((A,B)\\\\) are chosen, the remaining question for '\n",
      "                                      'synthesis a KKL observer (2) is to numerically determine '\n",
      "                                      'the solution. In view of the computational challenge in '\n",
      "                                      'directly solving the PDEs (3) and the recent trend of '\n",
      "                                      'handling the problem by neural approaches [19, 20, 21], '\n",
      "                                      'this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a '\n",
      "                                      'neural network. Yet, instead of using a vanilla multi-layer '\n",
      "                                      'perceptron architecture, a Lipschitz-bounded neural network '\n",
      "                                      'will be adopted, which safeguards the generalization '\n",
      "                                      'performance of state observation, which will be discussed '\n",
      "                                      'in SSIII. This overall idea is illustrated in Fig. 1.',\n",
      "                              'value': '_KKL Observer_'},\n",
      "                             {'children': [],\n",
      "                              'header': 'h3',\n",
      "                              'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network '\n",
      "                                      '\\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as '\n",
      "                                      'a single vector \\\\(\\\\theta\\\\). Without loss of generality, '\n",
      "                                      'assume that the activation function (element-wise applied '\n",
      "                                      'to vectors) is '\n",
      "                                      '\\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with '\n",
      "                                      'slope bounded in \\\\([0,1]\\\\) (in this work, rectified '\n",
      "                                      'linear units (ReLU) are used to prevent gradient decay in '\n",
      "                                      'BP training). The neural network then can be expressed as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\begin{split}& '\n",
      "                                      'z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ '\n",
      "                                      '\\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & '\n",
      "                                      'z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} '\n",
      "                                      '\\\\tag{4}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices '\n",
      "                                      'and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total '\n",
      "                                      'there are \\\\(\\\\nu\\\\) activation layers inserted between '\n",
      "                                      '\\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the '\n",
      "                                      'inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the '\n",
      "                                      'output vector, as we will use such a neural network to '\n",
      "                                      'approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL '\n",
      "                                      'observer.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Given a neural network with fixed parameters '\n",
      "                                      '\\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a '\n",
      "                                      'rough estimate of the Lipschitz\\n'\n",
      "                                      '\\n'\n",
      "                                      'Fig. 1: KKL observer with a Lipschitz-bounded neural '\n",
      "                                      'network to be trained.\\n'\n",
      "                                      'constant of \\\\(S\\\\) can be obviously obtained as\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, '\n",
      "                                      '\\\\tag{5}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'where \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its '\n",
      "                                      'operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of '\n",
      "                                      'vectors, i.e., its largest singular value. To reduce the '\n",
      "                                      'conservativeness, Fazlyab et al. [25] leverages the '\n",
      "                                      'control-theoretic tool of integral quadratic constraints to '\n",
      "                                      'formulate the Lipschitz bound condition as a linear matrix '\n",
      "                                      'inequality, thus estimating the Lipschitz constants and '\n",
      "                                      'training Lipschitz-bounded neural networks through solving '\n",
      "                                      'semidefinite programming problems [27]. The pertinent '\n",
      "                                      'matrix size, however, proportionally scales with the total '\n",
      "                                      'number of neurons, which results in high computational '\n",
      "                                      'complexity unless the neural network is very small.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The recent work of Wang and Manchester [28] proposed a '\n",
      "                                      '_direct parameterization_ approach to accommodate Lipschitz '\n",
      "                                      'bound by a special design of the neural network '\n",
      "                                      'architecture instead of imposing extra parameter '\n",
      "                                      'constraints. By this approach, the training of neural '\n",
      "                                      'networks is an unconstrained optimization problem and is '\n",
      "                                      'thus amenable to the typical, computationally lightweight '\n",
      "                                      'back-propagation (BP) routine. Wang-Manchester direct '\n",
      "                                      'parameterization is conceptually related to, and arguably '\n",
      "                                      'motivated by, the theory of controller parameterization '\n",
      "                                      '[30, 31].\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. '\n",
      "                                      '[28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times '\n",
      "                                      'd}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), '\n",
      "                                      '\\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), '\n",
      "                                      'a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a '\n",
      "                                      'mapping '\n",
      "                                      '\\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that '\n",
      "                                      'maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a '\n",
      "                                      '\\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the '\n",
      "                                      'following formulas:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ '\n",
      "                                      '\\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} '\n",
      "                                      '=\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} '\n",
      "                                      '=\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) '\n",
      "                                      '=\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, '\n",
      "                                      'Y}h+b).\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      'It turns out that the Lipschitz constant of the '\n",
      "                                      'above-defined sandwich layer is guaranteed to be upper '\n",
      "                                      'bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the '\n",
      "                                      'input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded '\n",
      "                                      'as comprising of an activation layer in the midst of two '\n",
      "                                      'fully connected layers with related parameters. The '\n",
      "                                      'operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the '\n",
      "                                      '_Cayley transform_. The structure and the parameters of a '\n",
      "                                      'sandwich layer is shown in Fig. 2.\\n'\n",
      "                                      '\\n'\n",
      "                                      'Thus, by stacking a number of such sandwich layers after a '\n",
      "                                      'scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated '\n",
      "                                      'half-sandwich layer (meaning a layer containing only the '\n",
      "                                      'terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), '\n",
      "                                      'a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be '\n",
      "                                      'obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n'\n",
      "                                      '\\n'\n",
      "                                      '**Definition 3** (Wang-Manchester network).: _In this work, '\n",
      "                                      'we refer to Wang-Manchester network, '\n",
      "                                      '\\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the '\n",
      "                                      'following architecture:_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} '\n",
      "                                      '=\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ '\n",
      "                                      '\\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} '\n",
      "                                      '=\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_Here the parameters include_\\n'\n",
      "                                      '\\n'\n",
      "                                      '\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, '\n",
      "                                      'Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n'\n",
      "                                      '\\n'\n",
      "                                      '_which can be trained in an unconstrained way using '\n",
      "                                      'back-propagation. The inputs and outputs of the network are '\n",
      "                                      '\\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n'\n",
      "                                      '\\n'\n",
      "                                      'The above-defined Wang-Manchester network satisfies '\n",
      "                                      '\\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). '\n",
      "                                      'In this work, the network is defined and trained with data '\n",
      "                                      'using PyTorch (version 2.0.1) on Google Colaboratory, which '\n",
      "                                      'allows the auto-differentiation of a user-defined loss '\n",
      "                                      'function with respect to the neural network parameters for '\n",
      "                                      'the parameters to be iteratively updated.',\n",
      "                              'value': '_Lipschitz-Bounded Neural Networks_'}],\n",
      "                'header': 'h2',\n",
      "                'text': 'We consider a nonlinear autonomous system:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'where \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector '\n",
      "                        'of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For '\n",
      "                        'simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and '\n",
      "                        '\\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and '\n",
      "                        'uniqueness of solution but unknown for model-based synthesis.',\n",
      "                'value': 'II Preliminaries'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Here we shall provide a justification for requiring a Lipschitz bound on '\n",
      "                        'the neural network. We will make the following standing assumptions on '\n",
      "                        'the training data collection procedure for subsequent analysis.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 1** (Ergodicity).: _Assume that a sample trajectory is '\n",
      "                        'collected from the system, whose initial state is sampled from a '\n",
      "                        'probability distribution \\\\(\\\\mathcal{F}\\\\) on \\\\(\\\\mathcal{X}\\\\). The '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\) is time-invariant (i.e., an eigenmeasure '\n",
      "                        'of the Perron-Frobenius operator), so that any point of the trajectory '\n",
      "                        'comes from \\\\(\\\\mathcal{F}\\\\)._\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that The LTI dynamics of the KKL observer, \\\\((A,B)\\\\), is fixed. '\n",
      "                        'Then the observer states can be simulated from this linear dynamics.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 2** (Noisy measurements).: _Assume that the input signal for '\n",
      "                        'this LTI system is not noise-free measurements \\\\(y=h(x)\\\\), but instead '\n",
      "                        'containing a white noise of unknown covariance \\\\(\\\\sigma^{2}\\\\). In '\n",
      "                        'other words, the simulation from \\\\(y\\\\) to \\\\(z\\\\) is_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\begin{split}&\\\\dot{z}=Ax+By+w,\\\\quad\\\\mathbb{E}[w(t)]=0,\\\\,\\\\forall '\n",
      "                        't \\\\in\\\\mathbb{R}\\\\\\\\ '\n",
      "                        '&\\\\mathbb{E}[w(t)w(s)]=\\\\delta(t-s)\\\\sigma^{2},\\\\,\\\\forall t,s\\\\in '\n",
      "                        '\\\\mathbb{R}.\\\\end{split} \\\\tag{8}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'In this way, the collected sample, denoted as '\n",
      "                        '\\\\(\\\\{(x(t_{i}),z(t_{i}))\\\\}_{i=1}^{m}=\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\), '\n",
      "                        'in fact satisfies the following relation:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=\\\\bar{z}_{i}+v_{i},\\\\quad\\\\delta_{i}=\\\\int_{-\\\\infty}^{t_{i}}g(\\\\tau)w(t_{i}- '\n",
      "                        '\\\\tau)d\\\\tau. \\\\tag{9}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Here \\\\(g(\\\\tau)\\\\) is the impulse response of LTI system \\\\((A,B)\\\\); '\n",
      "                        '\\\\(\\\\bar{z}\\\\) is the value of \\\\(z(t_{i})\\\\) that would be otherwise '\n",
      "                        'obtained if there were no white noises in the output measurements.\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 3** (Sufficient decay).: _After a significantly long time '\n",
      "                        '\\\\(t_{\\\\epsilon}\\\\), \\\\(\\\\|z-T(x)\\\\|\\\\leq\\\\epsilon\\\\) for a small enough '\n",
      "                        '\\\\(z\\\\). Here \\\\(T\\\\) is the nonlinear immersion map specified by (3)._\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 2: A sandwich layer and its parameters.\\n'\n",
      "                        'Then, \\\\(\\\\|\\\\bar{z}_{i}-T(x_{i})\\\\|\\\\leq\\\\epsilon\\\\). Thus, we may '\n",
      "                        'write\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[z_{i}=T(x_{i})+v_{i}+v_{i}^{\\\\prime},\\\\quad\\\\|v_{i}^{\\\\prime}\\\\|\\\\leq\\\\epsilon. '\n",
      "                        '\\\\tag{10}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Now we suppose that the sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{m}\\\\) is '\n",
      "                        'used to train a neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), which gives the '\n",
      "                        'state observations \\\\(\\\\hat{x}_{i}=S(z_{i}|\\\\theta)\\\\), and that the '\n",
      "                        'resulting empirical loss, if defined as the average squared observation '\n",
      "                        'error, is\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta):=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|\\\\hat{x}_{i}-x_{i}\\\\|^{2}. '\n",
      "                        '\\\\tag{11}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Then we get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\hat{R}_{S}(\\\\theta)=\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\left\\\\|S\\\\left(T(x_{i})+v_{i}+v_{i '\n",
      "                        '}^{\\\\prime}|\\\\theta\\\\right)-x_{i}\\\\right\\\\|^{2}. \\\\tag{12}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '**Assumption 4**.: _Assume that the probability distribution '\n",
      "                        '\\\\(\\\\mathcal{F}\\\\) is supported by a compact set, i.e., if '\n",
      "                        '\\\\(x\\\\sim\\\\mathcal{F}\\\\), then \\\\(x\\\\) should be almost surely bounded._\\n'\n",
      "                        '\\n'\n",
      "                        'It follows that both \\\\(S(\\\\cdot|\\\\theta)\\\\) and \\\\(T\\\\) should be '\n",
      "                        'Lipschitz continuous. Denote their Lipschitz constants as '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) and \\\\(L_{T}\\\\), respectively. We have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\|S\\\\left(T(x_{i})+\\\\delta_{i}+\\\\delta_{i}^{\\\\prime}|\\\\theta\\\\right)-S\\\\left(T(x_{i}) '\n",
      "                        '|\\\\theta\\\\right)\\\\|\\\\leq L_{S}(\\\\theta)L_{T}(\\\\|v_{i}\\\\|+\\\\epsilon). '\n",
      "                        '\\\\tag{13}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Denote \\\\(D\\\\) as the essential upper bound of \\\\(\\\\|x\\\\|\\\\) on the '\n",
      "                        'distribution \\\\(\\\\mathcal{F}\\\\). As such, without loss of generality, let '\n",
      "                        '\\\\(S(T(0))=0\\\\). Then \\\\(\\\\|x-S(T(x))\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) '\n",
      "                        'almost surely. Combining the above two equations, we further get\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{14}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}(\\\\theta)L_{T}(L_{S}(\\\\theta)L '\n",
      "                        '_{T}+1)D(\\\\|v_{i}\\\\|+\\\\epsilon)\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}L_{S}^{2}(\\\\theta)L_{T}^{2}(\\\\|v_{i} '\n",
      "                        '\\\\|+\\\\epsilon)^{2}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'That is,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq '\n",
      "                        '\\\\hat{R}_{S}(\\\\theta) \\\\tag{15}\\\\] '\n",
      "                        '\\\\[\\\\quad+\\\\frac{1}{m}\\\\sum_{i=1}^{m}(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\left(D+ '\n",
      "                        '\\\\|v_{i}\\\\|+\\\\epsilon\\\\right)(\\\\|v_{i}\\\\|+\\\\epsilon).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The left-hand side gives an estimation of the empirical loss when '\n",
      "                        'observing the states from perfect output measurements (namely when '\n",
      "                        '\\\\(z_{i}=T(x_{i})\\\\), \\\\(i=1,\\\\ldots,m\\\\)). Further expanding the last '\n",
      "                        'term and applying Cauchy-Schwarz inequality, we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{16}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}+(D+2\\\\epsilon) '\n",
      "                        '\\\\left(\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)^{1/2}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Given that \\\\(v_{i}\\\\) is the response of LTI system \\\\((A,B)\\\\) to a '\n",
      "                        'white noise of covariance \\\\(\\\\sigma^{2}\\\\), '\n",
      "                        '\\\\(\\\\mathbb{E}(\\\\|v_{i}\\\\|^{2})=h^{2}\\\\sigma^{2}\\\\) where \\\\(h\\\\) is the '\n",
      "                        '\\\\(H_{2}\\\\)-norm of the system \\\\((A,B)\\\\) where \\\\(A\\\\) is Hurwitz. '\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{E}\\\\left(\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\right)=h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{17}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Let \\\\(\\\\alpha\\\\) be a small positive number. With confidence '\n",
      "                        '\\\\(1-\\\\alpha/2\\\\), a conservative estimation for its upper bound can be '\n",
      "                        'found according to Markov inequality:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|v_{i}\\\\|^{2}\\\\leq\\\\frac{1}{1-\\\\alpha/2}h^{2}\\\\sigma^{2}. '\n",
      "                        '\\\\tag{18}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Therefore,\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}\\\\leq\\\\hat '\n",
      "                        '{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\times \\\\tag{19}\\\\] '\n",
      "                        '\\\\[\\\\quad\\\\left[\\\\frac{h^{2}\\\\sigma^{2}}{1-\\\\alpha/2}+(D+2\\\\epsilon)\\\\frac{ '\n",
      "                        'h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon\\\\right].\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, we note that for \\\\(x\\\\sim\\\\mathcal{F}\\\\), now that '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\leq(L_{S}(\\\\theta)L_{T}+1)D\\\\) almost surely, '\n",
      "                        \"by Hoeffding's inequality, for any \\\\(\\\\varepsilon>0\\\\),\\n\"\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\mathbb{P}\\\\bigg{(}\\\\bigg{|}\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{ '\n",
      "                        'i})|\\\\theta)\\\\|^{2}-\\\\mathbb{E}\\\\left(\\\\|x-S(T(x))\\\\|^{2}\\\\right)\\\\bigg{|} '\n",
      "                        '\\\\tag{20}\\\\] '\n",
      "                        '\\\\[\\\\geq(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\varepsilon\\\\bigg{)}\\\\leq 2\\\\exp '\n",
      "                        '\\\\left(-2m\\\\varepsilon^{2}\\\\right).\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Thus, with confidence \\\\(1-\\\\alpha/2\\\\), we have\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\left|\\\\frac{1}{m}\\\\sum_{i=1}^{m}\\\\|x_{i}-S(T(x_{i})|\\\\theta)\\\\|^{2}- '\n",
      "                        '\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right)\\\\bigg{|}\\\\right. '\n",
      "                        '\\\\tag{21}\\\\] '\n",
      "                        '\\\\[\\\\quad<(L_{S}(\\\\theta)L_{T}+1)^{2}D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m '\n",
      "                        '}}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Combining (19) and (21), we have the following theorem.\\n'\n",
      "                        '\\n'\n",
      "                        '**Theorem 1**.: _Under the afore-mentioned assumptions, the '\n",
      "                        'generalization loss, defined as_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)=\\\\mathbb{E}\\\\left(\\\\|x-S(T(x)|\\\\theta)\\\\|^{2}\\\\right), '\n",
      "                        '\\\\tag{22}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_is related to the empirical loss as defined in (11) by_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[R_{S}(\\\\theta)<\\\\hat{R}_{S}(\\\\theta)+(L_{S}(\\\\theta)L_{T}+1)^{2}\\\\Delta(h,\\\\sigma, '\n",
      "                        '\\\\alpha,\\\\epsilon). \\\\tag{23}\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        '_with confidence \\\\(1-\\\\alpha\\\\) (\\\\(\\\\alpha\\\\in(0,1)\\\\)). Here_\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\Delta(h,\\\\sigma,\\\\alpha,\\\\epsilon)= '\n",
      "                        'D^{2}\\\\sqrt{\\\\frac{\\\\ln(4/\\\\alpha)}{2m}}+\\\\frac{h^{2}\\\\sigma^{2}}{1- '\n",
      "                        '\\\\alpha/2} \\\\tag{24}\\\\] '\n",
      "                        '\\\\[+(D+2\\\\epsilon)\\\\frac{h\\\\sigma}{\\\\sqrt{1-\\\\alpha/2}}+(D+\\\\epsilon)\\\\epsilon.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'The theorem shows that the Lipschitz constant of the neural network '\n",
      "                        'trained plays an important role in the generalized performance of the '\n",
      "                        'resulting state observer. The effect of \\\\(L_{S}(\\\\theta)\\\\) is mainly '\n",
      "                        'that of amplifying the first and third terms defined on the right-hand '\n",
      "                        'side of (24), supposing that \\\\(\\\\sigma\\\\)\\n'\n",
      "                        'and \\\\(\\\\epsilon\\\\) are small enough. These two terms respectively arise '\n",
      "                        'from (i) the overall upper bound of the observation error '\n",
      "                        '\\\\(\\\\|x-S(T(x)|\\\\theta)\\\\|\\\\), which acts as a coefficient before the '\n",
      "                        'Hoeffding term \\\\(\\\\sqrt{\\\\ln(4/\\\\alpha)/2m}\\\\), and (ii) the effect of '\n",
      "                        'noisy measurements on the observer states.\\n'\n",
      "                        '\\n'\n",
      "                        '**Remark 1**.: _It is noted that the performance bound stated in the '\n",
      "                        'above theorem can be conservative. The conclusion that '\n",
      "                        '\\\\(L_{S}(\\\\theta)\\\\) amplifies the generalization error and measurement '\n",
      "                        'noise should be considered as qualitative. The theorem also does not '\n",
      "                        'suggest a tractable algorithm to optimize the selection of \\\\((A,B)\\\\) '\n",
      "                        'along with the neural network \\\\(S(\\\\cdot|\\\\theta)\\\\), as the dependence '\n",
      "                        'of \\\\(L_{T}\\\\) on \\\\((A,B)\\\\) is highly implicit. Hence, this paper does '\n",
      "                        'not consider the problem of simultaneously training \\\\((A,B)\\\\) and the '\n",
      "                        'neural network._',\n",
      "                'value': 'III Analysis on the Generalized Loss'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'Let us consider a Lorenz system in a 3-dimensional state space with '\n",
      "                        'chaotic behavior. The equation is written as:\\n'\n",
      "                        '\\n'\n",
      "                        '\\\\[\\\\dot{x}_{1} =10(x_{2}-x_{1}), \\\\tag{25}\\\\] \\\\[\\\\dot{x}_{2} '\n",
      "                        '=x_{1}(28-10x_{3})-x_{2},\\\\] \\\\[\\\\dot{x}_{3} '\n",
      "                        '=10x_{1}x_{2}-(8/3)x_{3}.\\\\]\\n'\n",
      "                        '\\n'\n",
      "                        'Suppose that the measurement used for state observation is \\\\(y=x_{2}\\\\), '\n",
      "                        'where a white noise exists. We assign different values to the variance of '\n",
      "                        'the measurement noise and investigate how the resulting neural network '\n",
      "                        'should be chosen differently. To simulate the process we will use a '\n",
      "                        'sampling time of \\\\(0.01\\\\). The LTI part of the KKL observer, '\n",
      "                        '\\\\(A=-\\\\mathrm{diag}(8,4,2,1)\\\\) and \\\\(B=[1,1,1,1]^{\\\\top}\\\\) are '\n",
      "                        'chosen. At the beginning of the observer simulation, \\\\(z(0)=0\\\\) is set '\n",
      "                        'as the initial condition; we simulate the dynamics until \\\\(t=500\\\\) and '\n",
      "                        'randomly collect \\\\(m=2000\\\\) time instants between \\\\(t=20\\\\) and '\n",
      "                        '\\\\(t=500\\\\) as the training data.\\n'\n",
      "                        '\\n'\n",
      "                        'Consider first the case with noiseless measurement (\\\\(\\\\sigma=0\\\\)). The '\n",
      "                        'sample \\\\(\\\\{(x_{i},z_{i})\\\\}_{i=1}^{2000}\\\\) is plotted in Fig. 3, which '\n",
      "                        'shows that the data points are representative on the forward invariant '\n",
      "                        'set of the system, and that the observer states \\\\(z_{i}\\\\) indeed '\n",
      "                        'captures the structure of such a Lorenz attractor in a '\n",
      "                        '\\\\(4\\\\)-dimensional space. Hence, we train the Wang-Manchester network '\n",
      "                        'using a randomly selected \\\\(80\\\\%\\\\) of the sample under the '\n",
      "                        'mean-squares loss metric, and validate using the remaining \\\\(20\\\\%\\\\) '\n",
      "                        'sample points. Stochastic gradient descent (SGD) algorithm with a '\n",
      "                        'learning rate of \\\\(10^{-3}\\\\) is used for optimization. The number of '\n",
      "                        'epochs is empirically tuned to \\\\(300\\\\). The neural network has \\\\(2\\\\) '\n",
      "                        'hidden layers, each containing \\\\(8\\\\) neurons, resulting in \\\\(292\\\\) '\n",
      "                        'parameters to train in total. After training, the Lipschitz constant is '\n",
      "                        'evaluated a posteriori via the semidefinite programming approach of '\n",
      "                        'Fazlyab et al. [25] using cvxpy, which costs approximately \\\\(1.5\\\\) '\n",
      "                        'seconds (for a randomly initialized network).\\n'\n",
      "                        '\\n'\n",
      "                        'Varying the prior bound on the Lipschitz constant, the resulting training '\n",
      "                        'loss, validation loss, and the posterior Lipschitz bound obtained from '\n",
      "                        'the same training conditions are illustrated in Fig. 4. The following '\n",
      "                        'observations can be made from these results.\\n'\n",
      "                        '\\n'\n",
      "                        '* As anticipated, as the set bound on the Lipschitz bound increases, the '\n",
      "                        'Lipschitz constant of the trained neural network becomes higher. The '\n",
      "                        'Lipschitz constants estimated a posteriori are lower than the prior bound '\n",
      "                        'on the Wang-Manchester network, validating the direct parameterization '\n",
      "                        'approach on constraining the slope. On the other hand, the actually '\n",
      "                        'posterior Lipschitz constant has an increasingly large lag behind the '\n",
      "                        'prior bound; for example, when the prior bound is \\\\(1000\\\\), the '\n",
      "                        '\\\\(L_{S}\\\\) after training does not exceed \\\\(300\\\\). This indicates that '\n",
      "                        'even for the training objective alone, there is a \"resistance\" to pursue '\n",
      "                        'the maximally possible Lipschitz constant.\\n'\n",
      "                        '* When the Lipschitz bound is small, relaxing the restriction on '\n",
      "                        '\\\\(L_{S}\\\\) is beneficial for decreasing the training loss as well as the '\n",
      "                        'validation loss, showing that the Lipschitz bound is a bottleneck causing '\n",
      "                        'underfitting. When \\\\(L_{S}\\\\) is high enough, such underfitting no '\n",
      "                        'longer exists; instead, overfitting will appear, with rising training '\n",
      "                        'and\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 3: Sample collected from the Lorenz system.\\n'\n",
      "                        'validation losses. The overfitting phenomenon is more significant when '\n",
      "                        'the noise is large. Thus, there should be optimal values to be set as the '\n",
      "                        'Lipschitz bound.\\n'\n",
      "                        '* Depending on the noise magnitude, the deviation of posterior Lipschitz '\n",
      "                        'constant from the prior bound and the emergence of overfitting phenomenon '\n",
      "                        'occur at different threshold values of the Lipschitz bound. Thus, the '\n",
      "                        'Lipschitz bound to be used for neural network training should be tuned '\n",
      "                        'differently as the noise intensity varies. For example, at '\n",
      "                        '\\\\(\\\\sigma=1\\\\), a suitable choice can be \\\\(\\\\gamma=100\\\\), whereas at '\n",
      "                        '\\\\(\\\\sigma=5\\\\) and \\\\(\\\\sigma=10\\\\), \\\\(\\\\gamma\\\\) can be chosen as '\n",
      "                        '\\\\(30\\\\) and \\\\(10\\\\), respectively.\\n'\n",
      "                        '\\n'\n",
      "                        'Now suppose that at the observer design stage, the Wang-Manchester '\n",
      "                        'network is trained by the simulated data from a perfect digital twin of '\n",
      "                        'the true dynamics, i.e., \\\\(\\\\sigma=0\\\\); yet, when applying the network '\n",
      "                        'trained to observe the states of the physical system, the environment is '\n",
      "                        'noisy. In Fig. 5, the resulting loss (mean squared state observation '\n",
      "                        'error) is plotted against varying prior Lipschitz bounds under multiple '\n",
      "                        'values of the environment noise magnitude. It is seen that when the noise '\n",
      "                        'is low, roughly speaking, increasing \\\\(L_{S}\\\\) leads to monotonic '\n",
      "                        'decrease in the observation error within a large range. On the other '\n",
      "                        'hand, when the environment is highly noisy (e.g., when \\\\(\\\\sigma\\\\geq '\n",
      "                        '3\\\\)), the Lipschitz bound has a severe effect on the generalization '\n",
      "                        'loss, and since the achievable performance is restrictive, the '\n",
      "                        'fine-tuning of Lipschitz bound as a hyperparameter becomes critical.\\n'\n",
      "                        '\\n'\n",
      "                        'Finally, the performance of the state observer is examined. Consider '\n",
      "                        'using the network trained with noiseless simulation data under the prior '\n",
      "                        'Lipschitz bound \\\\(L_{S}=10\\\\), and applying it to environments with '\n",
      "                        'noise \\\\(\\\\sigma=0.1\\\\), \\\\(0.3\\\\), \\\\(1.0\\\\), \\\\(3.0\\\\). The '\n",
      "                        'trajectories of the three components of estimated states by the observer '\n",
      "                        'are plotted against the true states in Fig. 6, within a time horizon of '\n",
      "                        '\\\\(10\\\\) time units. Naturally, when \\\\(\\\\sigma\\\\) is low, the state '\n",
      "                        'estimates can well track the true states and capture the trends in the '\n",
      "                        'correct directions; as \\\\(\\\\sigma\\\\) increases, the accuracy is lowered '\n",
      "                        'and the signals constructed by the observer are more noisy, occasionally '\n",
      "                        'yielding incorrect directions of evolution (e.g., on \\\\(3<t<4\\\\) or '\n",
      "                        '\\\\(8<t<9\\\\), where the states swing between the two foils of the Lorenz '\n",
      "                        'attractor). Overall, the state estimates mollifies the true state '\n",
      "                        'trajectories, which is due to the structure of our KKL observer - a '\n",
      "                        'linear filter (LTI system) as the state dynamics and a Lipschitz-bounded '\n",
      "                        'neural network as the static output map.',\n",
      "                'value': 'IV Case Study'},\n",
      "               {'children': [],\n",
      "                'header': 'h2',\n",
      "                'text': 'This work leverages the recent tools of Lipschitz-bounded neural networks '\n",
      "                        'for the synthesis of nonlinear state observers in a model-free setting. '\n",
      "                        'The observer, which has a Kazantzis-Kravaris structure, turns out to have '\n",
      "                        'a provable generalization performance that is related to the Lipschitz '\n",
      "                        'constant of the trained neural network (which represents the mapping from '\n",
      "                        'the observer states to the plant states). As such, by varying the '\n",
      "                        'Lipschitz bound and re-training the neural network, the optimal training '\n",
      "                        'result can yield the minimum generalized state observation error. The '\n",
      "                        'importance of bounding the Lipschitz constant has been demonstrated by a '\n",
      "                        'numerical case study on the Lorenz system.\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 4: Loss and Lipschitz constants under different prior Lipschitz '\n",
      "                        'bounds. (Blue wedges: training loss, blue circles: validation loss, green '\n",
      "                        'circles: prior Lipschitz bound; green wedges: posterior Lipschitz '\n",
      "                        'bound.)\\n'\n",
      "                        '\\n'\n",
      "                        'Fig. 5: Errors of noiselessly trained observers in noisy environments.\\n'\n",
      "                        'We implicitly assumed here that a simulator of the dynamics is available, '\n",
      "                        \"so that the true states' trajectories can be used to train the neural \"\n",
      "                        'network. However, such ground truth for supervised learning may not '\n",
      "                        'actually exist in real applications, i.e., only inputs and outputs are '\n",
      "                        'recorded, yet a state observation mechanism is still needed or desired '\n",
      "                        \"for feedback control. To this end, the author's recent work [32] proposed \"\n",
      "                        'a data-driven KKL observer by appending a kernel dimensionality reduction '\n",
      "                        'scheme to the LTI dynamics, thus obtaining estimates that are '\n",
      "                        'diffeomorphic to the states.\\n'\n",
      "                        '\\n'\n",
      "                        'Also, the current approach is yet restricted to autonomous systems. For '\n",
      "                        'control purposes, it should be further extended to non-autonomous ones, '\n",
      "                        'where the Bernard-Andrieu observer structure [18] is anticipated. Also, '\n",
      "                        'the application of such data-driven state observers to learning '\n",
      "                        'control-relevant properties of nonlinear dynamical systems and controller '\n",
      "                        'synthesis [33, 34] is undergoing active research.',\n",
      "                'value': 'V Conclusions and Discussions'}],\n",
      "  'header': 'h1',\n",
      "  'text': '',\n",
      "  'value': 'Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural '\n",
      "           'Networks'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(hierarchical_structure, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_texts(node):\n",
    "    texts = [node[\"text\"]]\n",
    "    for child in node[\"children\"]:\n",
    "        texts.extend(get_node_texts(child))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 Synthesis of Data-Driven Nonlinear State Observers using Lipschitz-Bounded Neural Networks\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 II Preliminaries 2\n",
      "h2 III Analysis on the Generalized Loss 0\n",
      "h2 IV Case Study 0\n",
      "h2 V Conclusions and Discussions 0\n"
     ]
    }
   ],
   "source": [
    "## Top Section\n",
    "top_section = hierarchical_structure[0]\n",
    "header_type = top_section[\"header\"]\n",
    "section_name = top_section[\"value\"]\n",
    "print(header_type, section_name)\n",
    "\n",
    "\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = []\n",
    "for section in top_section[\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    if section_name.lower()==\"abstract\":\n",
    "        continue\n",
    "    \n",
    "    section_text = get_node_texts(section)\n",
    "    section_texts.append(section_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4958, 9149, 7740, 5915, 1977]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(\"\\n\".join(x)) for x in section_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': 'h2',\n",
       " 'value': 'II Preliminaries',\n",
       " 'children': [{'header': 'h3',\n",
       "   'value': '_KKL Observer_',\n",
       "   'children': [],\n",
       "   'text': 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.'},\n",
       "  {'header': 'h3',\n",
       "   'value': '_Lipschitz-Bounded Neural Networks_',\n",
       "   'children': [],\n",
       "   'text': 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.'}],\n",
       " 'text': 'We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_section[\"children\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We consider a nonlinear autonomous system:\\n\\n\\\\[\\\\dot{x}(t)=f(x(t)),\\\\quad y(t)=h(x(t)) \\\\tag{1}\\\\]\\n\\nwhere \\\\(x(t)\\\\in\\\\mathcal{X}\\\\subseteq\\\\mathbb{R}^{n}\\\\) is the vector of states and \\\\(y(t)\\\\in\\\\mathbb{R}^{m}\\\\) represents the outputs. For simplicity, we will consider \\\\(m=1\\\\). It is assumed that \\\\(f\\\\) and \\\\(h\\\\) are smooth on \\\\(\\\\mathcal{X}\\\\) to guarantee existence and uniqueness of solution but unknown for model-based synthesis.',\n",
       " 'For nonlinear systems, KKL observer generalizes the notion of Luenberger observers that were restricted to linear systems [14], providing a generic method for state observation with mild assumptions to guarantee existence. Specifically, the KKL observer for (1) is expressed as\\n\\n\\\\[\\\\dot{z}(t)=Az(t)+By(t),\\\\quad\\\\hat{x}(t)=T^{\\\\dagger}(z(t)). \\\\tag{2}\\\\]\\n\\nHere the observer states \\\\(z\\\\in\\\\mathbb{R}^{n_{z}}\\\\) has an LTI dynamics. The matrices \\\\(A\\\\) and \\\\(B\\\\) are chosen under the requirements of (i) controllability of \\\\((A,B)\\\\) should be controllable, (ii) Hurwitz property of \\\\(A\\\\), and (iii) sufficiently high dimension of \\\\(z\\\\) (\\\\(n_{z}\\\\)), which should be at least \\\\(n+1\\\\) if \\\\((A,B)\\\\) is complex [17] and at least \\\\(2n+1\\\\) if \\\\((A,B)\\\\) is real [29]. The mapping from the observer states \\\\(z\\\\) to the state estimates \\\\(\\\\hat{x}\\\\) is a static one, \\\\(T^{\\\\dagger}\\\\), which is the left-pseudoinverse of a nonlinear immersion \\\\(T\\\\) (i.e., a differentiable injection satisfying \\\\(T^{\\\\dagger}\\\\circ T=\\\\mathsf{id}\\\\)). This immersion \\\\(T\\\\) should satisfy the following PDE:\\n\\n\\\\[\\\\frac{\\\\partial T}{\\\\partial x}(x)f(x)=AT(x)+Bh(x),\\\\quad\\\\forall x\\\\in\\\\mathcal{X}, \\\\tag{3}\\\\]\\n\\nwhere \\\\(\\\\partial T/\\\\partial x\\\\) denotes the Jacobian matrix of \\\\(T\\\\). It can be easily verified that under the above PDE, \\\\(dT(x)/dt=AT(x)+By\\\\), and thus \\\\(z-T(x)\\\\) has an exponentially decaying dynamics, as \\\\(A\\\\) is Hurwitz.\\n\\nThe conditions for the existence of a KKL observer, namely the solution to its defining PDE (3), have been established based on the condition of backward distinguishability. In below, we denote the solution to the ODEs \\\\(\\\\dot{x}=f(x)\\\\) at time \\\\(t\\\\) with initial condition \\\\(x(0)=\\\\xi\\\\) as \\\\(\\\\Phi_{t}(\\\\xi)\\\\). For any open set \\\\(\\\\mathcal{O}\\\\) in \\\\(\\\\mathcal{X}\\\\), denote the backward time instant after which the solution does not escape this region by \\\\(\\\\varsigma_{\\\\mathcal{O}}(\\\\xi)=\\\\inf\\\\{t|\\\\Phi_{t}(\\\\xi)\\\\in\\\\mathcal{O}\\\\}\\\\). Also denote \\\\(\\\\mathcal{O}+\\\\epsilon:=\\\\{\\\\xi+\\\\eta|\\\\xi\\\\in\\\\mathcal{O},\\\\|\\\\eta\\\\|<\\\\epsilon\\\\}\\\\).\\n\\n**Definition 1** (Backward distinguishability).: _The system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable if for any distinct \\\\(\\\\xi,\\\\xi^{\\\\prime}\\\\in\\\\mathcal{X}\\\\) there exists a negative \\\\(t>\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon}(\\\\xi)\\\\wedge\\\\varsigma_{\\\\mathcal{O}+\\\\epsilon} (\\\\xi^{\\\\prime})\\\\) such that \\\\(h(\\\\Phi_{t}(\\\\xi))\\\\neq h(\\\\Phi_{t}(\\\\xi^{\\\\prime}))\\\\)._\\n\\n**Fact 1** (Existence of KKL observer, cf. Brivadis et al. [29]).: _Assume that there is an open \\\\(\\\\mathcal{O}\\\\subseteq\\\\bar{\\\\mathcal{X}}\\\\) and a positive constant \\\\(\\\\epsilon\\\\) such that the system (1) is \\\\((\\\\mathcal{O},\\\\epsilon)\\\\)-backward distinguishable. Then there exists a constant \\\\(\\\\rho>0\\\\) such that for all but a Lebesgue-zero-measure set of \\\\((A,B)\\\\in\\\\mathbb{R}^{(2n+1)\\\\times(2n+1)}\\\\times\\\\mathbb{R}^{(2n+1)}\\\\), if \\\\(A+\\\\rho I\\\\) Hurwitz, then there exists an immersion \\\\(T:\\\\mathcal{O}\\\\rightarrow\\\\mathbb{R}^{(2n+1)}\\\\) solving the PDEs (3)._\\n\\nThe above theorem clarifies that as long as the spectrum of \\\\(A\\\\) is restricted to the left of \\\\(-\\\\rho+i\\\\mathbb{R}\\\\), the LTI dynamics in the KKL observer can be almost arbitrarily assigned. Once \\\\((A,B)\\\\) are chosen, the remaining question for synthesis a KKL observer (2) is to numerically determine the solution. In view of the computational challenge in directly solving the PDEs (3) and the recent trend of handling the problem by neural approaches [19, 20, 21], this work will seek to approximate \\\\(T^{\\\\dagger}\\\\) by a neural network. Yet, instead of using a vanilla multi-layer perceptron architecture, a Lipschitz-bounded neural network will be adopted, which safeguards the generalization performance of state observation, which will be discussed in SSIII. This overall idea is illustrated in Fig. 1.',\n",
       " 'Consider a \\\\(\\\\nu\\\\)-layer neural network \\\\(\\\\hat{x}=S(z,\\\\theta)\\\\) with all parameters denoted as a single vector \\\\(\\\\theta\\\\). Without loss of generality, assume that the activation function (element-wise applied to vectors) is \\\\(\\\\sigma:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}\\\\), with slope bounded in \\\\([0,1]\\\\) (in this work, rectified linear units (ReLU) are used to prevent gradient decay in BP training). The neural network then can be expressed as\\n\\n\\\\[\\\\begin{split}& z^{\\\\ell+1}=\\\\sigma(W^{\\\\ell}z^{\\\\ell}+b^{\\\\ell}),\\\\ \\\\ \\\\ell=0,\\\\ldots,\\\\nu-1\\\\\\\\ & z^{0}=z,\\\\quad\\\\hat{x}=W^{\\\\nu}z^{\\\\nu}+b^{\\\\nu}.\\\\end{split} \\\\tag{4}\\\\]\\n\\nwhere \\\\(W^{0},\\\\ldots,W^{\\\\nu}\\\\) are the weight matrices and \\\\(b^{0},\\\\ldots,b^{\\\\nu}\\\\) are the biases. In total there are \\\\(\\\\nu\\\\) activation layers inserted between \\\\(\\\\nu+1\\\\) fully connected layers. \\\\(z\\\\) represents the inputs to the neural network and \\\\(\\\\hat{x}\\\\) is the output vector, as we will use such a neural network to approximate the \\\\(T^{\\\\dagger}\\\\) mapping in the KKL observer.\\n\\nGiven a neural network with fixed parameters \\\\(\\\\theta=(W^{0},b^{0},\\\\ldots,W^{\\\\nu},b^{\\\\nu})\\\\), a rough estimate of the Lipschitz\\n\\nFig. 1: KKL observer with a Lipschitz-bounded neural network to be trained.\\nconstant of \\\\(S\\\\) can be obviously obtained as\\n\\n\\\\[L_{S}(\\\\theta)=\\\\prod_{\\\\ell=0}^{\\\\nu}\\\\|W^{\\\\ell}\\\\|_{2}, \\\\tag{5}\\\\]\\n\\nwhere \\\\(\\\\|\\\\cdot\\\\|_{2}\\\\) for a matrix refers to its operator norm induced by the \\\\(\\\\ell_{2}\\\\)-norm of vectors, i.e., its largest singular value. To reduce the conservativeness, Fazlyab et al. [25] leverages the control-theoretic tool of integral quadratic constraints to formulate the Lipschitz bound condition as a linear matrix inequality, thus estimating the Lipschitz constants and training Lipschitz-bounded neural networks through solving semidefinite programming problems [27]. The pertinent matrix size, however, proportionally scales with the total number of neurons, which results in high computational complexity unless the neural network is very small.\\n\\nThe recent work of Wang and Manchester [28] proposed a _direct parameterization_ approach to accommodate Lipschitz bound by a special design of the neural network architecture instead of imposing extra parameter constraints. By this approach, the training of neural networks is an unconstrained optimization problem and is thus amenable to the typical, computationally lightweight back-propagation (BP) routine. Wang-Manchester direct parameterization is conceptually related to, and arguably motivated by, the theory of controller parameterization [30, 31].\\n\\n**Definition 2** (\\\\(1\\\\)-Lipschitz sandwich layer, cf. [28]).: _Given parameters \\\\(X\\\\in\\\\mathbb{R}^{d\\\\times d}\\\\), \\\\(Y\\\\in\\\\mathbb{R}^{c\\\\times d}\\\\), \\\\(s\\\\in\\\\mathbb{R}^{d}\\\\), and \\\\(b\\\\in\\\\mathbb{R}^{d}\\\\), a \\\\(1\\\\)-Lipschitz sandwich layer is defined as such a mapping \\\\(\\\\Xi:\\\\mathbb{R}^{c}\\\\rightarrow\\\\mathbb{R}^{d}\\\\) that maps any \\\\(h\\\\in\\\\mathbb{R}^{c}\\\\) into a \\\\(\\\\Xi(h;X,Y,s,b)\\\\in\\\\mathbb{R}^{d}\\\\) according to the following formulas:_\\n\\n\\\\[Z =X-X^{\\\\top}+Y^{\\\\top}Y,\\\\ \\\\Psi_{s}=\\\\mathrm{diag}(e^{s}) \\\\tag{6}\\\\] \\\\[M_{X,Y} =\\\\left[(I+Z)^{-1}(I-Z)\\\\right]^{\\\\top},\\\\] \\\\[N_{X,Y} =\\\\left[-2Y(I+Z)^{-1}\\\\right]^{\\\\top},\\\\] \\\\[\\\\Xi(h) =\\\\sqrt{2}M_{X,Y}^{\\\\top}\\\\Psi_{s}\\\\sigma(\\\\sqrt{2}\\\\Psi_{s}^{-1}N_{X, Y}h+b).\\\\]\\n\\nIt turns out that the Lipschitz constant of the above-defined sandwich layer is guaranteed to be upper bounded by \\\\(1\\\\)[28, Theorem 3.3]. The mapping from the input \\\\(h\\\\) to the output \\\\(\\\\Xi(h)\\\\) can be regarded as comprising of an activation layer in the midst of two fully connected layers with related parameters. The operation from \\\\((X,Y)\\\\) to \\\\((M,N)\\\\) is known as the _Cayley transform_. The structure and the parameters of a sandwich layer is shown in Fig. 2.\\n\\nThus, by stacking a number of such sandwich layers after a scaling by \\\\(\\\\sqrt{\\\\gamma}\\\\) and before a non-activated half-sandwich layer (meaning a layer containing only the terms in the parentheses of \\\\(\\\\Xi\\\\) as in Equation (6)), a neural network with Lipschitz bound \\\\(\\\\gamma\\\\) can be obtained, for any provided \\\\(\\\\gamma>0\\\\).\\n\\n**Definition 3** (Wang-Manchester network).: _In this work, we refer to Wang-Manchester network, \\\\(S(\\\\cdot|\\\\theta)\\\\), by a neural network in the following architecture:_\\n\\n\\\\[h^{0} =\\\\sqrt{\\\\gamma}z; \\\\tag{7}\\\\] \\\\[h^{\\\\ell+1} =\\\\Xi(h^{\\\\ell};X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}),\\\\ \\\\ell=0,1,\\\\ldots,\\\\nu-1;\\\\] \\\\[\\\\hat{x} =\\\\sqrt{\\\\gamma}N_{X^{\\\\nu},Y^{\\\\nu}}h^{\\\\nu}+b^{\\\\nu}.\\\\]\\n\\n_Here the parameters include_\\n\\n\\\\[\\\\theta=\\\\{X^{\\\\ell},Y^{\\\\ell},s^{\\\\ell},b^{\\\\ell}\\\\}_{\\\\ell=0}^{\\\\nu-1}\\\\cup\\\\{X^{\\\\nu}, Y^{\\\\nu},b^{\\\\nu}\\\\}\\\\]\\n\\n_which can be trained in an unconstrained way using back-propagation. The inputs and outputs of the network are \\\\(z\\\\) and \\\\(\\\\hat{x}\\\\), respectively._\\n\\nThe above-defined Wang-Manchester network satisfies \\\\(\\\\|S(\\\\cdot|\\\\theta)\\\\|_{\\\\mathrm{Lip}}\\\\leq\\\\gamma\\\\). In this work, the network is defined and trained with data using PyTorch (version 2.0.1) on Google Colaboratory, which allows the auto-differentiation of a user-defined loss function with respect to the neural network parameters for the parameters to be iteratively updated.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_texts = get_node_texts(top_section[\"children\"][2])\n",
    "print(len(section_texts))\n",
    "section_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section count test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7792/10000 [00:00<00:00, 10003.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR 5786 - [{'header': 'h2', 'value': 'Abstract', 'children': [{'header': 'h6', 'value': 'Contents', 'children': [], 'text': '* 1 Introduction\\n* 2 Model and Method\\n\\t* 2.1 Model\\n\\t* 2.2 Method\\n\\t* 2.3 Dynamical Correlation Functions\\n\\t* 2.4 Current-current correlation function\\n* 3 Correlation functions\\n\\t* 3.1 \\\\(T=0\\\\)'}], 'text': \"**Using variational matrix product states, we analyze the finite temperature behavior of a half-filled periodic Anderson model in one dimension, a prototypical model of a Kondo insulator. We present an extensive analysis of single-particle Green's functions, two-particle Green's functions, and transport functions creating a broad picture of the low-temperature properties. We confirm the existence of energetically low-lying spin excitations in this model and study their energy-momentum dispersion and temperature dependence. We demonstrate that charge-charge correlations at the Fermi energy exhibit a different temperature dependence than spin-spin correlations. While energetically low-lying spin excitations emerge approximately at the Kondo temperature, which exponentially depends on the interaction strength, charge correlations vanish already at high temperatures. Furthermore, we analyze the charge and thermal conductivity at finite temperatures by calculating the time-dependent current-current correlation functions. While both charge and thermal conductivity can be fitted for all interaction strengths by gapped systems with a renormalized band gap, the gap in the system describing the thermal conductivity is generally smaller than the system describing the charge conductivity. Thus, two-particle correlations affect the charge and heat conductivities in a different way resulting in a temperature region where the charge conductivity of this one-dimensional Kondo insulator is already decreasing while the heat conductivity is still increasing.**\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 9774.77it/s]\n"
     ]
    }
   ],
   "source": [
    "num_sections = []\n",
    "for idx in tqdm(range(df.shape[0])):\n",
    "    text = df.iloc[idx]['markdown']\n",
    "    hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "    \n",
    "    # has H1 Title \n",
    "    if len(hierarchical_structure)==1 and hierarchical_structure[0]['header']=='h1':\n",
    "        num_section = 0\n",
    "        top_section = hierarchical_structure[0]\n",
    "        for section in top_section[\"children\"]:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    elif len(hierarchical_structure)>1:\n",
    "        num_section = 0\n",
    "        for section in hierarchical_structure:\n",
    "            header_type = section[\"header\"]\n",
    "            section_name = section[\"value\"]\n",
    "            if section_name.lower()==\"abstract\":\n",
    "                continue\n",
    "            num_section+=1\n",
    "        num_sections.append(num_section)\n",
    "    else:\n",
    "        print(\"ERR {} - {}\".format(idx, hierarchical_structure, len(hierarchical_structure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX 43 AVG 5.901490149014902 MIN 0\n"
     ]
    }
   ],
   "source": [
    "num_sections_np = np.array(num_sections)\n",
    "print(\"MAX {} AVG {} MIN {}\".format(num_sections_np.max(), num_sections_np.mean(), num_sections_np.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sections_np[num_sections_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  27,   54,   88,  160,  190,  218,  250,  259,  271,  304,  344,\n",
       "         384,  521,  523,  524,  563,  571,  624,  742,  760,  820,  868,\n",
       "        1006, 1095, 1147, 1208, 1232, 1237, 1263, 1297, 1336, 1382, 1430,\n",
       "        1434, 1543, 1602, 1609, 1662, 1674, 1678, 1691, 1736, 1960, 2005,\n",
       "        2090, 2097, 2118, 2165, 2192, 2344, 2408, 2455, 2512, 2541, 2570,\n",
       "        2607, 2635, 2684, 2774, 2803, 2823, 2860, 2861, 2955, 3068, 3122,\n",
       "        3235, 3240, 3308, 3319, 3336, 3376, 3386, 3432, 3459, 3699, 3709,\n",
       "        3804, 3859, 3953, 3975, 4083, 4222, 4241, 4274, 4275, 4304, 4321,\n",
       "        4417, 4431, 4474, 4596, 4625, 4672, 4803, 4807, 4862, 4874, 4897,\n",
       "        4914, 5020, 5041, 5059, 5101, 5121, 5176, 5193, 5204, 5205, 5246,\n",
       "        5374, 5387, 5427, 5436, 5482, 5496, 5512, 5535, 5556, 5580, 5614,\n",
       "        5628, 5634, 5642, 5672, 5685, 5727, 5738, 5744, 5791, 5863, 5900,\n",
       "        5913, 5984, 6027, 6051, 6063, 6141, 6216, 6258, 6267, 6287, 6302,\n",
       "        6368, 6393, 6403, 6541, 6546, 6581, 6613, 6619, 6634, 6705, 6784,\n",
       "        6889, 6901, 6924, 6928, 6969, 7034, 7037, 7110, 7134, 7172, 7258,\n",
       "        7265, 7410, 7448, 7467, 7586, 7625, 7665, 7673, 7758, 7867, 7973,\n",
       "        7989, 8044, 8137, 8142, 8153, 8157, 8197, 8210, 8295, 8308, 8314,\n",
       "        8328, 8400, 8501, 8535, 8606, 8611, 8672, 8731, 8745, 8775, 8833,\n",
       "        8902, 8909, 8947, 8965, 8996, 9056, 9085, 9092, 9113, 9162, 9177,\n",
       "        9178, 9215, 9216, 9224, 9239, 9250, 9277, 9293, 9301, 9307, 9322,\n",
       "        9346, 9371, 9412, 9429, 9492, 9505, 9514, 9540, 9561, 9571, 9575,\n",
       "        9603, 9640, 9664, 9713, 9773, 9814, 9853, 9881, 9911, 9965]),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_sections_np==2).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Heterodyne measurement of sidebands and frequency combs: a derivation\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "A mathematical description of heterodyne measurement of an optical frequency comb is presented. It is shown that for a signal beam containing many frequency teeth, the amplitude and phase of each tooth can be determined from the beatnote generated when the signal is interfered with a local oscillator with known offset frequency.\n",
      "\n",
      "## I Introduction\n",
      "\n",
      "Optical heterodyne detection is a commonly used method for measurement of amplitude and phase of spectral components of an optical beam [1; 2; 3; 4; 5]. Despite its frequent usage, complete and concise mathematical descriptions of the heterodyne measurement process are difficult to come by, with many sources simply stating a non-generalised final result [6; 7]. The lack of a readily available comprehensive description can make it difficult to deeply understand the method, including underlying assumptions, which increases the chance of experimental or analytical errors.\n",
      "\n",
      "Here, we present a complete and concise derivation of optical heterodyne measurement of a beam consisting of regularly spaced frequency components. Such beams are commonly generated using electro-optic modulators, and ultrafast laser techniques, and where the number components is large, the optical field is referred to as a frequency comb. We attempt to use consistant notation, and where appropriate, give a physical interpretation to the mathematical results.\n",
      "\n",
      "At a given position any electric field strength can be written as\n",
      "\n",
      "\\[E(t)=\\frac{1}{2}\\mathcal{E}(t)e^{-\\mathrm{i}\\omega_{0}t}+\\frac{1}{2}\\mathcal{ E}^{*}(t)e^{\\mathrm{i}\\omega_{0}t} \\tag{1}\\]\n",
      "\n",
      "where \\(\\mathcal{E}(t)\\) is the complex envelope function, \\(\\mathcal{E}^{*}\\) is its complex conjugate, and \\(\\omega_{0}\\) is the reference angular frequency. The choice of reference frequency is completely arbitrary, and can be positive or negative. However, the reference is _usually_ chosen so that the variation in time of \\(\\mathcal{E}(t)\\) is as small as possible. In practice, the reference frequency is often taken as the carrier frequency of a beam, so the complex envelope fully represents only the modulations to this carrier (both in phase, amplitude, and any additional frequency components).\n",
      "\n",
      "The intensity of a given electric field is given by\n",
      "\n",
      "\\[I(t)=c\\varepsilon\\frac{1}{T}\\int_{-T/2}^{T/2}E^{*}(t)E(t)\\mathrm{d}t, \\tag{2}\\]\n",
      "\n",
      "where \\(T\\) is an integer number of periods of the optical cycle, with minimum one period.\n",
      "\n",
      "Subbing equation 1 into this expression yields:\n",
      "\n",
      "\\[I(t) =\\frac{c\\varepsilon}{4T}\\int_{-T/2}^{T/2}\\left[\\mathcal{E}^{*}(t) \\mathcal{E}(t)+\\mathcal{E}(t)\\mathcal{E}^{*}(t)+\\mathcal{E}^{2}(t)e^{-\\mathrm{ i}2\\omega_{0}t}+\\mathcal{E}^{*2}(t)e^{\\mathrm{i}2\\omega_{0}t}\\right] \\mathrm{d}t \\tag{3}\\] \\[=\\frac{c\\varepsilon}{2T}\\int_{-T/2}^{T/2}\\mathcal{E}^{*}(t) \\mathcal{E}(t)\\mathrm{d}t+\\frac{c\\varepsilon}{4T}\\int_{-T/2}^{T/2}\\left[ \\mathcal{E}^{2}(t)e^{-\\mathrm{i}2\\omega_{0}t}+\\mathcal{E}^{*2}(t)e^{\\mathrm{ i}2\\omega_{0}t}\\right]\\mathrm{d}t \\tag{4}\\]\n",
      "\n",
      "If we have chosen \\(\\omega_{0}\\) appropriately such that \\(\\mathcal{E}\\) is slowly varying in time, the expression in the first integral can be pulled out of the integral, and the integral evaluates to \\(T\\). The two terms on the right oscillate at twice the optical frequency, and so will integrate to zero. Note this definition of intensity breaks down where the amplitudes vary significantly over the time scale of an optical cycle, such as with ultra-short laser pulses.\n",
      "\n",
      "Averaging over the fast oscillations gives a convenient expression for intensity written in terms of the complex amplitudes:\n",
      "\n",
      "\\[I(t) =\\frac{c\\varepsilon}{2}\\mathcal{E}^{*}(t)\\mathcal{E}(t) \\tag{5}\\] \\[=\\frac{c\\varepsilon}{2}|\\mathcal{E}(t)|^{2}. \\tag{6}\\]\n",
      "Now, when we interfere two beams, we will have the signal \\(E_{\\rm sig}(t)\\) and the local oscillator \\(E_{\\rm LO}(t)\\) fields. The signal can be written as\n",
      "\n",
      "\\[E_{\\rm sig}(t)=\\frac{1}{2}\\mathcal{E}_{\\rm sig}(t)e^{-\\mathrm{i}\\omega_{0}t}+ \\frac{1}{2}\\mathcal{E}_{\\rm sig}^{*}(t)e^{\\mathrm{i}\\omega_{0}t}. \\tag{7}\\]\n",
      "\n",
      "A frequency comb with tooth spacing \\(\\omega_{\\rm SB}\\) ('SB' is signifies'side band'), is written as a sum of fields each with a constant amplitude and a frequency that differs by an integer multiple of \\(\\omega_{\\rm SB}\\). For compactness, a reference frequency can be pulled out of each term, and the total signal field can be written as equation 7, where the complex envelope is given by:\n",
      "\n",
      "\\[\\mathcal{E}_{\\rm sig}(t)=\\sum_{n}a_{n}e^{-\\mathrm{i}(m\\omega_{\\rm SB}t+\\phi_{n })} \\tag{8}\\]\n",
      "\n",
      "where \\(n\\) can take any integer value (positive, negative or zero), \\(a_{n}\\) is the real amplitude of the \\(n^{\\rm th}\\) comb tooth, and \\(\\phi_{n}\\) is the corresponding phase of that frequency component (cf. A4). Note that this is simply a general expression that represents a frequency comb, it is not a recipe for how to generate one. It is well known that modulating either the phase or amplitude of a carrier periodically puts sidebands on that carrier, but here we are simply concerned with how to represent (and then measure) a field that _does_ have evenly spaced sidebands.\n",
      "\n",
      "The full signal electric field is therefore written as:\n",
      "\n",
      "\\[E_{\\rm sig}(t)=\\frac{1}{2}\\sum_{n}a_{n}\\left[e^{-\\mathrm{i}(m\\omega_{\\rm SB}t +\\phi_{n})}e^{-\\mathrm{i}\\omega_{0}t}+e^{\\mathrm{i}(n\\omega_{\\rm SB}t+\\phi_{n })}e^{\\mathrm{i}\\omega_{0}t}\\right]. \\tag{9}\\]\n",
      "\n",
      "In a heterodyne measurement, the signal beam is combined with a local oscillator beam, which is shifted in angular frequency relative to the signal carrier by an amount \\(\\Delta\\omega\\). The complex envelope can therefore be written as:\n",
      "\n",
      "\\[\\mathcal{E}_{\\rm LO}(t)=be^{-\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}, \\tag{10}\\]\n",
      "\n",
      "where \\(b\\) is the local oscillator real amplitude.\n",
      "\n",
      "The full local oscillator electric field can then be written as:\n",
      "\n",
      "\\[E_{\\rm LO}(t)=\\frac{b}{2}\\left[e^{-\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}e ^{-\\mathrm{i}\\omega_{0}t}+e^{\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}e^{ \\mathrm{i}\\omega_{0}t}\\right]. \\tag{11}\\]\n",
      "\n",
      "Now, when the signal and local oscillator beams are combines on a beamsplitter, the output of a single port is just the sum of their fields. We will only be interested in a single port, so the phase shift introduced by reflection of a mirror is irrelevant to us and will be ignored (as will the halving of their amplitudes). The result is:\n",
      "\n",
      "\\[E_{\\rm tot}(t) =E_{\\rm sig}(t)+E_{\\rm LO}(t) \\tag{12}\\] \\[=\\frac{1}{2}\\left[\\sum_{n}a_{n}e^{-\\mathrm{i}(n\\omega_{\\rm SB}t+ \\phi_{n})}+be^{-\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}\\right]e^{-\\mathrm{i }\\omega_{0}t}+\\frac{1}{2}\\left[\\sum_{n}a_{n}e^{\\mathrm{i}(m\\omega_{\\rm SB}t+ \\phi_{n})}+be^{\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}\\right]e^{\\mathrm{i} \\omega_{0}t} \\tag{13}\\]\n",
      "\n",
      "where the terms have been grouped by pulling out their common exponential factor.\n",
      "\n",
      "We can see that equation 13 is in the form of equation 1, where the complex envelope function is given by the term in the square brackets. We can therefore immediately write down the resulting time varying intensity for the combined field by substituting the envelope and its conjugate into equation 5. Note that when calculation the intensity the summations over the signal teeth will multiply and hence the summations must be performed separately. The index label of one summation is therefore changed to \\(m\\).\n",
      "\n",
      "\\[I_{\\rm tot}(t) =\\frac{c\\varepsilon}{2}\\left[\\sum_{n}a_{n}e^{-\\mathrm{i}(n\\omega _{\\rm SB}t+\\phi_{n})}+be^{-\\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}\\right] \\times\\left[\\sum_{m}a_{m}e^{\\mathrm{i}(m\\omega_{\\rm SB}t+\\phi_{m})}+be^{ \\mathrm{i}(\\Delta\\omega t+\\phi_{\\rm LO})}\\right] \\tag{14}\\] \\[=\\frac{c\\varepsilon}{2}\\left\\{b^{2}+\\sum_{n,m}a_{n}a_{m}e^{ \\mathrm{i}[(m-n)\\omega_{\\rm SB}t+\\phi_{m}-\\phi_{n}]}+\\sum_{m}a_{m}be^{\\mathrm{ i}[(m\\omega_{\\rm SB}-\\Delta\\omega)t+\\phi_{m}-\\phi_{\\rm LO}]}+\\sum_{n}a_{n}be^{- \\mathrm{i}[(n\\omega_{\\rm SB}-\\Delta\\omega)t+\\phi_{n}-\\phi_{\\rm LO}]}\\right\\}\\] (15) \\[=\\frac{c\\varepsilon}{2}\\left\\{b^{2}+\\sum_{n}a_{n}^{2}+\\sum_{ \\begin{subarray}{c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}e^{\\mathrm{i}[(m-n)\\omega_{\\rm SB}t+\\phi_{m}- \\phi_{n}]}+\\sum_{n}a_{n}be^{\\mathrm{i}[(n\\omega_{\\rm SB}-\\Delta\\omega)t+\\phi _{n}-\\phi_{\\rm LO}]}+\\sum_{n}a_{n}be^{-\\mathrm{i}[(n\\omega_{\\rm SB}-\\Delta \\omega)t+\\phi_{n}-\\phi_{\\rm LO}]}\\right\\} \\tag{16}\\]\n",
      "So, equation 16 tells us exactly what the _intensity_ of the combined field will be at a given point in time. Clearly the intensity will vary periodically in time so this is commonly referred to as the _beat note_, although in the case of a signal beam which is made up of many comb teeth, there will be multiple frequency components present.\n",
      "\n",
      "We are often primarily interested in knowing something about these different frequency components, so a common way to analyse the heterodyne signal is using a spectrum analyser to display at the power spectrum of the photocurrent from a photodiode. The photocurrent is directly proportional to intensity, so the generated power spectrum is directly proportional to the power spectrum of the intensity. A spectrum analyser simply Fourier transforms the signal, and then displays the amplitude (or power, which is proportional to the square of the amplitude), so it is useful to see what the analytic form is of the Fourier transform of the time varying intensity, \\(\\tilde{I}(\\omega)\\):\n",
      "\n",
      "\\[\\tilde{I}(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\int I(t)e^{-\\mathrm{i}\\omega t}\\mathrm{ d}t, \\tag{17}\\]\n",
      "\n",
      "where the integral is understood to be over \\(-\\infty\\) to \\(\\infty\\).\n",
      "\n",
      "Substituting equation 16 into the Fourier transform yields:\n",
      "\n",
      "\\[\\tilde{I}_{\\mathrm{tot}}(\\omega) =\\frac{c\\varepsilon}{2\\sqrt{2\\pi}}\\int\\Big{\\{}b^{2}+\\sum_{n}a_{n} ^{2}+\\sum_{\\begin{subarray}{c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}e^{\\mathrm{i}[(m-n)\\omega_{\\mathrm{SB}}t+\\phi _{m}-\\phi_{n}]}\\] \\[\\qquad\\qquad+\\sum_{n}a_{n}be^{\\mathrm{i}[(n\\omega_{\\mathrm{SB}}- \\Delta\\omega)t+\\phi_{n}-\\phi_{\\mathrm{LO}}]}+\\sum_{n}a_{n}be^{-\\mathrm{i}[(n \\omega_{\\mathrm{SB}}-\\Delta\\omega)t+\\phi_{n}-\\phi_{\\mathrm{LO}}]}\\Big{\\}}e^{- \\mathrm{i}\\omega t}\\mathrm{d}t \\tag{18}\\] \\[=\\frac{c\\varepsilon}{2\\sqrt{2\\pi}}\\Big{\\{}\\left(b^{2}+\\sum_{n}a_ {n}^{2}\\right)\\int e^{-\\mathrm{i}\\omega t}\\mathrm{d}t+\\sum_{\\begin{subarray}{ c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}\\int e^{\\mathrm{i}[(m-n)\\omega_{\\mathrm{SB}}t+ \\phi_{m}-\\phi_{n}]}e^{-\\mathrm{i}\\omega t}\\mathrm{d}t\\] \\[\\qquad\\qquad+\\sum_{n}a_{n}b\\int e^{\\mathrm{i}[(n\\omega_{\\mathrm{ SB}}-\\Delta\\omega)t+\\phi_{n}-\\phi_{\\mathrm{LO}}]}e^{-\\mathrm{i}\\omega t} \\mathrm{d}t+\\sum_{n}a_{n}b\\int e^{-\\mathrm{i}[(n\\omega_{\\mathrm{SB}}-\\Delta \\omega)t+\\phi_{n}-\\phi_{\\mathrm{LO}}]}e^{-\\mathrm{i}\\omega t}\\mathrm{d}t\\Big{\\}}\\] (19) \\[=\\frac{c\\varepsilon}{2\\sqrt{2\\pi}}\\Big{\\{}\\left(b^{2}+\\sum_{n}a_ {n}^{2}\\right)\\int e^{-\\mathrm{i}\\omega t}\\mathrm{d}t+\\sum_{\\begin{subarray}{ c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}e^{\\mathrm{i}(\\phi_{m}-\\phi_{n})}\\int e^{(m-n) \\omega_{\\mathrm{SB}}t}e^{-\\mathrm{i}\\omega t}\\mathrm{d}t\\] \\[\\qquad\\qquad+\\sum_{n}a_{n}be^{\\mathrm{i}(\\phi_{n}-\\phi_{\\mathrm{ LO}})}\\int e^{\\mathrm{i}(n\\omega_{\\mathrm{SB}}-\\Delta\\omega)t}e^{- \\mathrm{i}\\omega t}\\mathrm{d}t+\\sum_{n}a_{n}be^{-\\mathrm{i}(\\phi_{n}-\\phi_{ \\mathrm{LO}})}\\int e^{-\\mathrm{i}(n\\omega_{\\mathrm{SB}}-\\Delta\\omega)t}e^{- \\mathrm{i}\\omega t}\\mathrm{d}t\\Big{\\}} \\tag{20}\\]\n",
      "\n",
      "The Fourier integrals can be evaluated by noting that:\n",
      "\n",
      "\\[\\frac{1}{\\sqrt{2\\pi}}\\int e^{\\mathrm{i}\\alpha t}e^{-\\mathrm{i}\\omega t} \\mathrm{d}t=\\sqrt{2\\pi}\\,\\delta(\\omega-\\alpha), \\tag{21}\\]\n",
      "\n",
      "where \\(\\delta(\\omega)\\) is the Dirac delta function.\n",
      "\n",
      "Substituting this in equation 19, taking the corresponding value of \\(\\alpha\\) in each integrand gives:\n",
      "\n",
      "\\[\\tilde{I}_{\\mathrm{tot}}(\\omega) =\\frac{c\\varepsilon\\sqrt{2\\pi}}{2}\\Big{\\{}\\left(b^{2}+\\sum_{n}a_ {n}^{2}\\right)\\delta(\\omega)\\] \\[\\qquad\\qquad+\\sum_{\\begin{subarray}{c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}e^{\\mathrm{i}(\\phi_{m}-\\phi_{n})}\\delta( \\omega-[m-n]\\omega_{\\mathrm{SB}})\\] \\[\\qquad\\qquad+\\sum_{n}a_{n}be^{\\mathrm{i}(\\phi_{n}-\\phi_{\\mathrm{ LO}})}\\delta(\\omega-[n\\omega_{\\mathrm{SB}}-\\Delta\\omega])\\] \\[\\qquad\\qquad+\\sum_{n}a_{n}be^{-\\mathrm{i}(\\phi_{n}-\\phi_{ \\mathrm{LO}})}\\delta(\\omega+[n\\omega_{\\mathrm{SB}}-\\Delta\\omega])\\Big{\\}} \\tag{22}\\]\n",
      "\n",
      "Equation 22 describes three combs of teeth the in frequency domain, each with spacing \\(\\omega_{SB}\\), and a peak also at zero frequency representing the DC level. The two combs that sum only over \\(n\\) represent actual optical frequencies present in the signal beam. There are two of these combs because each actual unique signal comb tooth has a positive and negative frequency component when the original electric field is represented in a form such as A6.\n",
      "\n",
      "The term that sums over \\(n\\) and \\(m\\) represents the beatnotes formed when the signal beam comb teeth beat against _each other_. Different pairs of frequency components with equal frequency spacing will beat at the same frequency,\n",
      "and may add or subtract to that beatnote depending on their phase. For a set of sidebands produced by a phase only electro-optic modulator, the different phases between all frequency components add in a way so this \"cross comb\" does not show up at all.\n",
      "\n",
      "Depending on the number of teeth, the sideband spacing, and the local oscillator frequency offset, it is possible for teeth belonging to all three combs to overlap. It is generally undesirable for the teeth to overlap, since this prevents measurement of the amplitude and phase of individual of the individual frequency components that make up the signal beam frequency comb. Figures 1, 2, 3 and 4 show how combs can begin to intersect as the number of teeth get larger. Note that \\(\\Delta\\omega\\) has deliberately been chosen to be an integer plus one third times the sideband spacing, so that even though all three combs become interspersed, the individual comb teeth do not lie on top of one another. The amplitude of the signal comb teeth was was set to be a Gaussian simply as a visual aid.\n",
      "\n",
      "Equation 22 gives the Fourier amplitude at a given frequency, but in reality, any measurement we make of the Fourier amplitudes is over some small range of frequencies. In a spectrum analyser, this range is set by the resolution bandwidth RBW, and in a numerical discrete Fourier transform of a time domain signal, it is set by the spacing of the frequency array (which is the inverse of the total length of time sampled). So experimentally, to extract the actual value for the Fourier amplitude at some frequency \\(\\bar{\\omega}\\), we must integrate over some small frequency range : \\(\\omega=\\bar{\\omega}\\pm\\epsilon\\), and the resulting quantity will be denoted \\(\\tilde{I}_{\\rm tot}(\\bar{\\omega})\\). Integration over the Dirac deltas means that the resulting values of \\(\\tilde{I}_{\\rm tot}(\\bar{\\omega})\\) will be finite.\n",
      "\n",
      "Figure 1: Beatnote from comb with single tooth.\n",
      "\n",
      "Figure 3: Beatnote from comb with 10 teeth.\n",
      "\n",
      "Figure 2: Beatnote from comb with 3 teeth.\n",
      "\\[\\bar{I}_{\\rm tot}(\\bar{\\omega}) = \\int_{\\bar{\\omega}-\\epsilon}^{\\bar{\\omega}+\\epsilon}\\bar{I}_{\\rm tot }(\\omega)\\mathrm{d}\\omega \\tag{23}\\] \\[= \\frac{c\\varepsilon\\sqrt{2\\pi}}{2}\\Big{\\{}\\left(b^{2}+\\sum_{n}a_{n} ^{2}\\right)\\int_{\\bar{\\omega}-\\epsilon}^{\\bar{\\omega}+\\epsilon}\\delta(\\omega) \\mathrm{d}\\omega\\] (24) \\[\\qquad+\\sum_{\\begin{subarray}{c}n,m\\\\ n\\neq m\\end{subarray}}a_{n}a_{m}e^{\\mathrm{i}(\\phi_{n}-\\phi_{n})}\\int_{\\bar{ \\omega}-\\epsilon}^{\\bar{\\omega}+\\epsilon}\\delta(\\omega-[m-n]\\omega_{\\rm SB}) \\mathrm{d}\\omega\\] \\[\\qquad+\\sum_{n}a_{n}be^{\\mathrm{i}(\\phi_{n}-\\phi_{\\rm LO})}\\int_ {\\bar{\\omega}-\\epsilon}^{\\bar{\\omega}+\\epsilon}\\delta(\\omega-[n\\omega_{\\rm SB }-\\Delta\\omega])\\mathrm{d}\\omega\\] \\[\\qquad+\\sum_{n}a_{n}be^{-\\mathrm{i}(\\phi_{n}-\\phi_{\\rm LO})}\\int_ {\\bar{\\omega}-\\epsilon}^{\\bar{\\omega}+\\epsilon}\\delta(\\omega+[n\\omega_{\\rm SB }-\\Delta\\omega])\\mathrm{d}\\omega\\Big{\\}}\\]\n",
      "\n",
      "Equation 24 provides us with a simple method to determine the amplitude and phase of the optical signal comb teeth by measuring the radio frequency beat note. If the time domain radio signal is measured on an oscilloscope, it can be Fourier transformed numerically to show the radio-frequency combs. Assuming the teeth of the different combs are not overlapped then the Fourier amplitude of at the frequency of the \\(n\\)th tooth has a contribution from only a single term of equation 24. Under these conditions, the optical amplitude and phase of the \\(n\\)th tooth is related to the Fourier transform of the detected intensity simply by:\n",
      "\n",
      "\\[\\bar{\\bar{I}}_{\\rm tot}(\\bar{\\omega}_{n})=a_{n}be^{\\mathrm{i}(\\phi_{n}-\\phi_{ \\rm LO})}, \\tag{25}\\]\n",
      "\n",
      "so that the optical amplitude of the tooth is:\n",
      "\n",
      "\\[a_{n}=\\frac{|\\bar{\\bar{I}}_{\\rm tot}(\\bar{\\omega}_{n})|}{b}, \\tag{26}\\]\n",
      "\n",
      "and the optical phase of the tooth is:\n",
      "\n",
      "\\[\\phi_{n}=\\mathrm{Arg}[\\bar{\\bar{I}}_{\\rm tot}(\\bar{\\omega}_{n})]+\\phi_{\\rm LO}. \\tag{27}\\]\n",
      "\n",
      "It is worth noting that the optical phase of the local oscillator \\(\\phi_{\\rm LO}\\) will not usually be fixed in a heterodyne measurement. While it is certainly possible to set up some phase locking circuit by either feeding back to the laser or to a piezo controlled mirror, generally the \\(\\phi_{\\rm LO}\\) will drift over time, as is seen in any unlocked interferometer. Therefore, the recovered value of \\(\\phi_{n}\\) will also drift over time. However, so long as \\(\\phi_{\\rm LO}\\) stays constant over the time scale of a single measurement, then the _difference_ between all the \\(\\phi_{n}\\)s will always be measured to be the same, even though \\(\\phi_{\\rm LO}\\) may drift.\n",
      "\n",
      "A final word about the beat note formed by the comb teeth beating against each: just because there is a comb, _does not_ mean you will actually observe any modulation of the intensity. Looking at the second term in equation 22 (the term responsible for teeth beating with each other), it can be seen that pairs of \\(n,m\\) with the same difference, do not necessarily have the same phase. If the phase of different pairs is not the same, then it is possible (indeed likely) that subsequent pairs will not all add in a way that increases the magnitude, and may totally cancel each other out. This is the case when a beam is phase modulated using an EOM. If the beam intensity is subsequently measured with only a photodiode, no intensity modulation is seen at all. However beating with a frequency shifted local oscillator reveals that there may be many other frequency components present.\n",
      "\n",
      "Figure 4: Beatnote from comb with 30 teeth.\n",
      "## Appendix A Complex representation of a real wave\n",
      "\n",
      "The electric component of a electromagnetic wave propagating in the positive \\(x\\) direction can be written as:\n",
      "\n",
      "\\[E(x,t)=E_{0}(x,t)\\cos{(kx-\\omega t+\\phi)}, \\tag{10}\\]\n",
      "\n",
      "where \\(E_{0}(x,t)\\) is a real, possibly time varying amplitude, \\(k\\) is the wave number, and \\(\\phi\\) is some constant phase offset.\n",
      "\n",
      "The cosine can be written in complex exponential form:\n",
      "\n",
      "\\[E(x,t) =\\frac{E_{0}(x,t)}{2}\\left(e^{\\mathrm{i}(kx-\\omega t+\\phi)}+e^{- \\mathrm{i}(kx-\\omega t+\\phi)}\\right) \\tag{11}\\] \\[=\\frac{E_{0}(x,t)e^{\\mathrm{i}(kx+\\phi)}}{2}e^{-\\mathrm{i}\\omega t }+\\frac{E_{0}(x,t)e^{-\\mathrm{i}(kx+\\phi)}}{2}e^{\\mathrm{i}\\omega t}. \\tag{12}\\]\n",
      "\n",
      "Now, if we no longer care about the position dependence of the field, we can drop the explicit dependence on \\(x\\), and simply note that the position would add some phase offset, in exactly the same way that \\(\\phi\\) does. The terms preceding the time dependent exponential can therefor just be written as a single complex valued amplitude \\(\\mathcal{E}(t)\\), noting that the two coefficients have the same magnitude, and negative phase (ie, they are the complex conjugate of one another):\n",
      "\n",
      "\\[\\mathcal{E}(t) =E_{0}(x,t)e^{\\mathrm{i}(kx+\\phi)} \\tag{13}\\] \\[\\mathcal{E}^{*}(t) =E_{0}(x,t)e^{-\\mathrm{i}(kx+\\phi)}. \\tag{14}\\]\n",
      "\n",
      "Substitution into equation 12 yields out desired form for the electric field:\n",
      "\n",
      "\\[E(t)=\\frac{1}{2}\\mathcal{E}(t)e^{-\\mathrm{i}\\omega t}+\\frac{1}{2}\\mathcal{E}^ {*}(t)e^{\\mathrm{i}\\omega t} \\tag{15}\\]\n",
      "\n",
      "Now, there are a couple of good questions about why we want the electric field represented in this form. Firstly, why didn't we just leave it with a cosine as in equation 10 where everything was real? This is easy to answer: multiplication and integration etc. with complex exponentials is much, much easier (you don't need an encyclopaedia of trig identities in your head). The second, more subtle question, is why don't we just work with the equation in the form of equation 11, where the amplitude is real? The first part of the answer is that we don't want to keep writing the \\(kx+\\phi\\) part of the exponent, since we already said that we don't care about position dependence. The obvious next question is then: 'if this just adds some constant phase, why don't you just set this to zero so that the amplitudes would be real?' In many cases you can, since you actually won't care about the phase, but you do loose generality by doing this. In order to keep the equation totally general, the coefficients (\\(\\mathcal{E}\\)) are made to be complex so they can have any phase, and the relationship between the coefficients is enforced by observing one is the conjugate of the other. In many cases you might actually care about the position dependence, \\(kx\\), or the initial phase \\(\\phi\\), and these absolutely can be left in remaining exponential term. The purpose then of the complex amplitude is that it can represent _ANY_ modulation of the reference wave, including additions of other phase or frequency components that you might wish to introduce, a property which is made use of in equation 8.\n",
      "\n",
      "Finally, it is worth noting that there are two alternative (but equivalent) ways of writing equation 15 that are in common use:\n",
      "\n",
      "\\[E(t) =\\frac{1}{2}\\mathcal{E}(t)e^{-\\mathrm{i}\\omega t}+\\mathrm{c.c.} \\tag{16}\\] \\[=\\mathrm{Re}\\left\\{\\mathcal{E}(t)e^{-\\mathrm{i}\\omega t}\\right\\}\\] (17) \\[=|\\mathcal{E}(t)|\\cos{\\Big{(}-\\omega t+\\mathrm{Arg}\\big{(} \\mathcal{E}(t)\\big{)}} \\tag{18}\\]\n",
      "\n",
      "where c.c. is short for 'complex conjugate', \\(\\mathrm{Re}\\{\\}\\) means to take the real part of the expression, and \\(\\mathrm{Arg}\\) returns the phase of a complex number. Generally, since it is known that the final value of the electric field _must_ be real, then any equation involving the field will _always_ contain the sum of two expressions which are complex conjugates of one another. Therefore, considerable time (and paper) can be saved by conducting _all_ calculations with only one of the pair of expressions, then at the end of the calculation, the full expression can be written out simply by adding on the conjugate. I personally like holding onto both terms, since when doing atomic physics, often approximations are made (like the rotating wave approximation), where certain terms are thrown away. Keeping track of all terms makes these approximations more intuitive and easier to follow in my opinion. Equation 18 is shown to make clear the\n",
      "relationship to a regular real cosine, and also to illustrate the purpose of putting factors of 1/2 in forms like equation 11, ie. including factors of 1/2 makes the magnitude of the complex amplitude equal to the real amplitude.\n",
      "\n",
      "3\n",
      "h6 Abstract 0\n",
      "h2 I Introduction 0\n",
      "h2 Appendix A Complex representation of a real wave 0\n"
     ]
    }
   ],
   "source": [
    "# idx = 7843 ## 43 sections\n",
    "# https://arxiv.org/pdf/2308.03803\n",
    "\n",
    "idx = 27 ## 2 sections\n",
    "# https://arxiv.org/pdf/2301.09285\n",
    "text = df.iloc[idx]['markdown']\n",
    "print(text)\n",
    "hierarchical_structure = parse_markdown_hierarchy(text)\n",
    "print(len(hierarchical_structure[0]['children']))\n",
    "hierarchical_structure\n",
    "\n",
    "for section in hierarchical_structure[0][\"children\"]:\n",
    "    header_type = section[\"header\"]\n",
    "    section_name = section[\"value\"]\n",
    "    print(header_type, section_name, len(section[\"children\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.720e+02, 2.650e+02, 2.410e+02, 4.140e+02, 1.091e+03, 1.983e+03,\n",
       "        2.100e+03, 0.000e+00, 1.565e+03, 9.420e+02, 5.270e+02, 2.620e+02,\n",
       "        1.390e+02, 7.600e+01, 0.000e+00, 4.600e+01, 2.800e+01, 1.600e+01,\n",
       "        9.000e+00, 7.000e+00, 5.000e+00, 0.000e+00, 3.000e+00, 2.000e+00,\n",
       "        2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([ 0.  ,  0.86,  1.72,  2.58,  3.44,  4.3 ,  5.16,  6.02,  6.88,\n",
       "         7.74,  8.6 ,  9.46, 10.32, 11.18, 12.04, 12.9 , 13.76, 14.62,\n",
       "        15.48, 16.34, 17.2 , 18.06, 18.92, 19.78, 20.64, 21.5 , 22.36,\n",
       "        23.22, 24.08, 24.94, 25.8 , 26.66, 27.52, 28.38, 29.24, 30.1 ,\n",
       "        30.96, 31.82, 32.68, 33.54, 34.4 , 35.26, 36.12, 36.98, 37.84,\n",
       "        38.7 , 39.56, 40.42, 41.28, 42.14, 43.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(num_sections, bins = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
