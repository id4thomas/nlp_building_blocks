{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def convert_docling_to_target_keep_body_order(doc):\n",
    "    \"\"\"\n",
    "    Convert a DoclingDocument JSON to the desired TARGET format,\n",
    "    preserving the order in doc[\"body\"][\"children\"]\n",
    "    and flattening out groups.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We'll store results in target_items\n",
    "    target_items = []\n",
    "    \n",
    "    # We assume doc[\"body\"][\"children\"] is an array of refs: e.g. {\"$ref\": \"#/texts/0\"}, {\"$ref\": \"#/pictures/0\"}, etc.\n",
    "    body_children = doc.get(\"body\", {}).get(\"children\", [])\n",
    "    \n",
    "    # For easy reference, let's keep the texts, pictures, groups, etc.\n",
    "    texts = doc.get(\"texts\", [])\n",
    "    pictures = doc.get(\"pictures\", [])\n",
    "    groups = doc.get(\"groups\", [])\n",
    "    \n",
    "    def process_text_obj(text_obj):\n",
    "        \"\"\"Convert a single text_obj to a dict in the desired format.\"\"\"\n",
    "        item = {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": text_obj.get(\"text\", \"\")\n",
    "        }\n",
    "        # Derive page_idx from text_obj.prov if present\n",
    "        prov = text_obj.get(\"prov\", [])\n",
    "        if prov:\n",
    "            item[\"page_idx\"] = prov[0].get(\"page_no\", None)\n",
    "        # If it's a section_header, store its level\n",
    "        if text_obj.get(\"label\") == \"section_header\":\n",
    "            item[\"text_level\"] = text_obj.get(\"level\", 1)\n",
    "        return item\n",
    "\n",
    "    def process_picture_obj(pic_obj):\n",
    "        \"\"\"Convert a single picture_obj to a dict in the desired format.\"\"\"\n",
    "        item = {\n",
    "            \"type\": \"image\",\n",
    "            # You can handle base64 decoding if you want; here we just use a placeholder path\n",
    "            \"img_path\": \"images/dummy.png\",\n",
    "            \"img_caption\": [],\n",
    "            \"img_footnote\": []\n",
    "        }\n",
    "        # Page index\n",
    "        prov_list = pic_obj.get(\"prov\", [])\n",
    "        if prov_list:\n",
    "            item[\"page_idx\"] = prov_list[0].get(\"page_no\", None)\n",
    "\n",
    "        # Captions are references to texts in docling, so we need to fetch them\n",
    "        captions_list = pic_obj.get(\"captions\", [])\n",
    "        for caption_ref in captions_list:\n",
    "            if \"$ref\" in caption_ref:\n",
    "                ref_path = caption_ref[\"$ref\"]\n",
    "                # Typically #/texts/<index>\n",
    "                if ref_path.startswith(\"#/texts/\"):\n",
    "                    idx_str = ref_path.split(\"/\")[-1]\n",
    "                    try:\n",
    "                        idx_int = int(idx_str)\n",
    "                        caption_text_obj = texts[idx_int]\n",
    "                        item[\"img_caption\"].append(caption_text_obj.get(\"text\", \"\"))\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                # if for some reason it's inline text\n",
    "                item[\"img_caption\"].append(caption_ref.get(\"text\", \"\"))\n",
    "\n",
    "        # Footnotes\n",
    "        footnotes_list = pic_obj.get(\"footnotes\", [])\n",
    "        for footnote_ref in footnotes_list:\n",
    "            if \"$ref\" in footnote_ref:\n",
    "                ref_path = footnote_ref[\"$ref\"]\n",
    "                if ref_path.startswith(\"#/texts/\"):\n",
    "                    idx_str = ref_path.split(\"/\")[-1]\n",
    "                    try:\n",
    "                        idx_int = int(idx_str)\n",
    "                        footnote_text_obj = texts[idx_int]\n",
    "                        item[\"img_footnote\"].append(footnote_text_obj.get(\"text\", \"\"))\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                item[\"img_footnote\"].append(footnote_ref.get(\"text\", \"\"))\n",
    "\n",
    "        return item\n",
    "\n",
    "    def process_group_obj(group_obj):\n",
    "        \"\"\"\n",
    "        Return a list of final items flattened from the group's children.\n",
    "        So if the group has references to texts or pictures, we convert them\n",
    "        in the same manner as if they were in the body top-level.\n",
    "        \"\"\"\n",
    "        flattened = []\n",
    "        group_children = group_obj.get(\"children\", [])\n",
    "        for child_ref in group_children:\n",
    "            if \"$ref\" in child_ref:\n",
    "                ref_path = child_ref[\"$ref\"]\n",
    "                if ref_path.startswith(\"#/texts/\"):\n",
    "                    idx_str = ref_path.split(\"/\")[-1]\n",
    "                    try:\n",
    "                        idx_int = int(idx_str)\n",
    "                        text_obj = texts[idx_int]\n",
    "                        flattened.append(process_text_obj(text_obj))\n",
    "                    except:\n",
    "                        pass\n",
    "                elif ref_path.startswith(\"#/pictures/\"):\n",
    "                    idx_str = ref_path.split(\"/\")[-1]\n",
    "                    try:\n",
    "                        idx_int = int(idx_str)\n",
    "                        pic_obj = pictures[idx_int]\n",
    "                        flattened.append(process_picture_obj(pic_obj))\n",
    "                    except:\n",
    "                        pass\n",
    "                elif ref_path.startswith(\"#/groups/\"):\n",
    "                    idx_str = ref_path.split(\"/\")[-1]\n",
    "                    try:\n",
    "                        idx_int = int(idx_str)\n",
    "                        nested_group_obj = groups[idx_int]\n",
    "                        # recursively flatten\n",
    "                        flattened.extend(process_group_obj(nested_group_obj))\n",
    "                    except:\n",
    "                        pass\n",
    "        return flattened\n",
    "\n",
    "    # Now we walk over body_children in order\n",
    "    for child_ref in body_children:\n",
    "        if \"$ref\" in child_ref:\n",
    "            ref_path = child_ref[\"$ref\"]\n",
    "            if ref_path.startswith(\"#/texts/\"):\n",
    "                # text\n",
    "                idx_str = ref_path.split(\"/\")[-1]\n",
    "                try:\n",
    "                    idx_int = int(idx_str)\n",
    "                    text_obj = texts[idx_int]\n",
    "                    target_items.append(process_text_obj(text_obj))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            elif ref_path.startswith(\"#/pictures/\"):\n",
    "                # picture\n",
    "                idx_str = ref_path.split(\"/\")[-1]\n",
    "                try:\n",
    "                    idx_int = int(idx_str)\n",
    "                    pic_obj = pictures[idx_int]\n",
    "                    target_items.append(process_picture_obj(pic_obj))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            elif ref_path.startswith(\"#/groups/\"):\n",
    "                # group\n",
    "                idx_str = ref_path.split(\"/\")[-1]\n",
    "                try:\n",
    "                    idx_int = int(idx_str)\n",
    "                    group_obj = groups[idx_int]\n",
    "                    # flatten\n",
    "                    group_flattened = process_group_obj(group_obj)\n",
    "                    target_items.extend(group_flattened)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Now we have a flattened list of items in the order they appear in body.children\n",
    "    return target_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['schema_name', 'version', 'name', 'origin', 'furniture', 'body', 'groups', 'texts', 'pictures', 'tables', 'key_value_items', 'pages'])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/docling/1706.03762v7/figure_export_without_table_structure/1706.03762v7-with-image-refs.json\", \"r\") as f:\n",
    "    doc = json.load(f)\n",
    "print(doc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'$ref': '#/texts/0'},\n",
       " {'$ref': '#/texts/1'},\n",
       " {'$ref': '#/texts/2'},\n",
       " {'$ref': '#/texts/3'},\n",
       " {'$ref': '#/texts/4'},\n",
       " {'$ref': '#/texts/5'},\n",
       " {'$ref': '#/texts/6'},\n",
       " {'$ref': '#/groups/0'},\n",
       " {'$ref': '#/texts/11'},\n",
       " {'$ref': '#/texts/12'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[\"body\"][\"children\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUP: {'self_ref': '#/groups/0', 'parent': {'$ref': '#/body'}, 'children': [{'$ref': '#/texts/7'}, {'$ref': '#/texts/8'}, {'$ref': '#/texts/9'}, {'$ref': '#/texts/10'}], 'name': 'group', 'label': 'key_value_area'}\n",
      "{'self_ref': '#/texts/7', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 126.882, 't': 508.153, 'r': 210.552, 'b': 475.27699999999993, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 46]}], 'orig': 'Llion Jones ∗ Google Research llion@google.com', 'text': 'Llion Jones ∗ Google Research llion@google.com'}\n",
      "{'self_ref': '#/texts/8', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 235.407, 't': 508.153, 'r': 339.994, 'b': 475.27699999999993, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 61]}], 'orig': 'Aidan N. Gomez ∗ † University of Toronto aidan@cs.toronto.edu', 'text': 'Aidan N. Gomez ∗ † University of Toronto aidan@cs.toronto.edu'}\n",
      "{'self_ref': '#/texts/9', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 364.849, 't': 506.182, 'r': 485.115, 'b': 475.278, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 50]}], 'orig': 'Łukasz Kaiser Google Brain lukaszkaiser@google.com', 'text': 'Łukasz Kaiser Google Brain lukaszkaiser@google.com'}\n",
      "{'self_ref': '#/texts/10', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 455.842, 't': 508.153, 'r': 459.92400000000004, 'b': 501.57, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}], 'orig': '∗', 'text': '∗'}\n"
     ]
    }
   ],
   "source": [
    "## Group Example\n",
    "# doc['body']['children'][7]\n",
    "print(\"GROUP:\",doc['groups'][0])\n",
    "\n",
    "for i in [7,8,9,10]:\n",
    "    print(doc['texts'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = convert_docling_to_target_keep_body_order(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'text',\n",
       " 'text': 'Llion Jones ∗ Google Research llion@google.com',\n",
       " 'page_idx': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'arXiv:1706.03762v7  [cs.CL]  2 Aug 2023',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Attention Is All You Need',\n",
       "  'page_idx': 1,\n",
       "  'text_level': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Ashish Vaswani ∗ Google Brain avaswani@google.com',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Noam Shazeer ∗ Google Brain noam@google.com',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Niki Parmar ∗ Google Research nikip@google.com',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Jakob Uszkoreit ∗ Google Research usz@google.com',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Llion Jones ∗ Google Research llion@google.com',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Aidan N. Gomez ∗ † University of Toronto aidan@cs.toronto.edu',\n",
       "  'page_idx': 1},\n",
       " {'type': 'text',\n",
       "  'text': 'Łukasz Kaiser Google Brain lukaszkaiser@google.com',\n",
       "  'page_idx': 1}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 0, 'text': 'Attention Is All You Need'},\n",
       " {'idx': 1, 'text': 'Abstract'},\n",
       " {'idx': 2, 'text': '1 Introduction'},\n",
       " {'idx': 3, 'text': '2 Background'},\n",
       " {'idx': 4, 'text': '3 Model Architecture'},\n",
       " {'idx': 5, 'text': '3.1 Encoder and Decoder Stacks'},\n",
       " {'idx': 6, 'text': '3.2 Attention'},\n",
       " {'idx': 7, 'text': 'Scaled Dot-Product Attention'},\n",
       " {'idx': 8, 'text': '3.2.1 Scaled Dot-Product Attention'},\n",
       " {'idx': 9, 'text': '3.2.2 Multi-Head Attention'},\n",
       " {'idx': 10, 'text': '3.2.3 Applications of Attention in our Model'},\n",
       " {'idx': 11, 'text': '3.3 Position-wise Feed-Forward Networks'},\n",
       " {'idx': 12, 'text': '3.4 Embeddings and Softmax'},\n",
       " {'idx': 13, 'text': '3.5 Positional Encoding'},\n",
       " {'idx': 14, 'text': '4 Why Self-Attention'},\n",
       " {'idx': 15, 'text': '5 Training'},\n",
       " {'idx': 16, 'text': '5.1 Training Data and Batching'},\n",
       " {'idx': 17, 'text': '5.2 Hardware and Schedule'},\n",
       " {'idx': 18, 'text': '5.3 Optimizer'},\n",
       " {'idx': 19, 'text': '5.4 Regularization'},\n",
       " {'idx': 20, 'text': '6 Results'},\n",
       " {'idx': 21, 'text': '6.1 Machine Translation'},\n",
       " {'idx': 22, 'text': '6.2 Model Variations'},\n",
       " {'idx': 23, 'text': '6.3 English Constituency Parsing'},\n",
       " {'idx': 24, 'text': '7 Conclusion'},\n",
       " {'idx': 25, 'text': 'References'},\n",
       " {'idx': 26, 'text': 'Attention Visualizations Input-Input Layer5'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identified headings\n",
    "header_items = []\n",
    "header_idx = 0\n",
    "for item in results:\n",
    "    if 'text_level' in item:\n",
    "        header_item = {\n",
    "            \"idx\": header_idx,\n",
    "            \"text\": item['text']\n",
    "        }\n",
    "        header_items.append(header_item)\n",
    "        header_idx+=1\n",
    "\n",
    "header_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
