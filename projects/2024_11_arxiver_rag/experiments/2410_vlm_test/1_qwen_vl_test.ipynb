{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "\twith open(image_path, \"rb\") as image_file:\n",
    "\t\treturn base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Client\n",
    "base_url = \"http://localhost:8010\"\n",
    "model = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=f\"{base_url}/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "def get_response(messages):\n",
    "\tstart = time.time()\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmodel=model,\n",
    "\t\tmessages=messages,\n",
    "\t\tmax_tokens=4096,\n",
    "\t\ttemperature=0.1\n",
    "\t)\n",
    "\tend = time.time()\n",
    "\tprint(\"Time: {:.3f}\".format(end-start))\n",
    "\tprint(response.choices[0])\n",
    "\tgenerated_message = response.choices[0].message.content\n",
    "\treturn generated_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = \"2305.00379\"\n",
    "page_num = 0\n",
    "page1_img = encode_image(f\"cache/pdf2img/{article_id}/{page_num}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test messages\n",
    "instruction = '''Read the abstract of the paper and summarize it into bullet points\n",
    "Return like the following JSON\n",
    "{\"point\": [\"...\", ...]}'''\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": [\n",
    "\t\t\t{\"type\": \"text\",\"text\": instruction},\n",
    "\t\t\t{\"type\": \"image_url\",\"image_url\": {\"url\": f\"data:image/jpeg;base64,{page1_img}\"}}\n",
    "\t\t]\n",
    "\t}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.053\n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"point\": [\\n    \"The paper proposes a Dual-Path Cooperative Filtering (DCF) model for image completion.\",\\n    \"The DCF model uses Fast Fourier Convolution to extract multi-level features and predict dynamic kernels.\",\\n    \"The model aims to fill in missing information while preserving local structure and generating visually realistic content.\",\\n    \"Experiments on three challenging image completion datasets show that the proposed DCF outperforms state-of-the-art methods.\",\\n    \"The paper addresses the limitations of existing image completion methods, such as poor cross-scene generalization and blurry artifacts.\",\\n    \"The DCF model is designed to have a strong capacity to generalize across regions that are missing.\",\\n    \"The paper compares the DCF model to baseline methods like RFRNet, JPGNet, and LaMa, showing that it generates high-fidelity and more realistic images.\"\\n  ]\\n}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)\n"
     ]
    }
   ],
   "source": [
    "response = get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"point\": [\n",
      "\t\t\"The paper proposes a Dual-Path Cooperative Filtering (DCF) model for image completion.\",\n",
      "\t\t\"The DCF model uses Fast Fourier Convolution to extract multi-level features and predict dynamic kernels.\",\n",
      "\t\t\"The model aims to fill in missing information while preserving local structure and generating visually realistic content.\",\n",
      "\t\t\"Experiments on three challenging image completion datasets show that the proposed DCF outperforms state-of-the-art methods.\",\n",
      "\t\t\"The paper addresses the limitations of existing image completion methods, such as poor cross-scene generalization and blurry artifacts.\",\n",
      "\t\t\"The DCF model is designed to have a strong capacity to generalize across regions that are missing.\",\n",
      "\t\t\"The paper compares the DCF model to baseline methods like RFRNet, JPGNet, and LaMa, showing that it generates high-fidelity and more realistic images.\"\n",
      "\t]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_dict = json.loads(response)\n",
    "print(json.dumps(response_dict, indent = \"\\t\", ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
