{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7bfacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-mini-2025-08-07-dev\n",
      "Prompt: try2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "from schema import NerResult\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_REASOINING_EFFORT = os.getenv(\"OPENAI_REASOINING_EFFORT\")\n",
    "print(OPENAI_MODEL)\n",
    "\n",
    "PROMPT_NAME = os.getenv(\"PROMPT_NAME\")\n",
    "print(\"Prompt:\", PROMPT_NAME)\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=OPENAI_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "if OPENAI_API_KEY is None or OPENAI_BASE_URL is None:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY or OPENAI_BASE_URL environment variable is not set\")\n",
    "\n",
    "# 예시: openai 설정\n",
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.api_base = OPENAI_BASE_URL\n",
    "\n",
    "# ——————————————\n",
    "# 2. YAML 템플릿 읽기 함수\n",
    "def load_prompt_template(yaml_path: str) -> dict:\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tpl = yaml.safe_load(f)\n",
    "    return tpl\n",
    "\n",
    "# ——————————————\n",
    "# 3. OpenAI 비동기 호출 함수\n",
    "async def call_openai_for_ner(instruction: str, prompt: str) -> NerResult:\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    # 비동기 호출 (예시로 openai.ChatCompletion.acreate 사용)\n",
    "    response = await client.responses.parse(\n",
    "        model=OPENAI_MODEL,\n",
    "        input=messages,\n",
    "        text_format=NerResult,\n",
    "        reasoning={\"effort\": OPENAI_REASOINING_EFFORT}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "async def extract(text: List[str], yaml_template_path: str):\n",
    "    tpl = load_prompt_template(yaml_template_path)\n",
    "    instruction = tpl['prompt']['developer']\n",
    "    # YAML 템플릿의 prompt 부분에 텍스트 삽입\n",
    "    prompt = tpl[\"prompt\"][\"user1\"].replace(\"{TEXT}\", text)\n",
    "    response = await call_openai_for_ner(instruction, prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f8a24",
   "metadata": {},
   "source": [
    "# 1. Generate Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4550db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103464, 11) Index(['file_id', 'doc_id', 'title', 'author', 'publisher', 'date', 'topic',\n",
      "       'original_topic', 'sentence_ids', 'sentence_offsets', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"NIKL_NEWSPAPER_2023_CSV\"\n",
    "fname = \"NEWSPAPER_2022_1\"\n",
    "\n",
    "df = pd.read_parquet(f\"source/{dataset_name}/{fname}.parquet\")\n",
    "print(df.shape, df.columns)\n",
    "\n",
    "prompt_path = f\"prompt/{PROMPT_NAME}.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8389ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "n = 32\n",
    "sample = df.sample(n)\n",
    "texts = sample.text.values.tolist()\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98641e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:33<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "tasks = [extract(text, prompt_path) for text in texts]\n",
    "responses = await tqdm.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630040d8",
   "metadata": {},
   "source": [
    "# 2. Process Usages\n",
    "## try2\n",
    "```\n",
    "[gpt-5-mini-minimal]\n",
    "Avg Input Tokens 2756.156 Output Tokens 1714.812\n",
    "Max Input Tokens 3604.000 Output Tokens 3396.000\n",
    "\n",
    "gpt-5-mini-minimal per 1K samples Avg $4.119 Max $7.693\n",
    "NEWSPAPER_2022_1 103464 samples gpt-5-mini-minimal Avg $426.133 Max $795.949\n",
    "\n",
    "[gpt-5-nano-minimal]\n",
    "Avg Input Tokens 2807.594 Output Tokens 1174.375\n",
    "Max Input Tokens 3795.000 Output Tokens 2543.000\n",
    "\n",
    "gpt-5-nano-minimal per 1K samples Avg $0.610 Max $1.207\n",
    "NEWSPAPER_2022_1 103464 samples gpt-5-nano-minimal Avg $63.126 Max $124.876\n",
    "```\n",
    "\n",
    "## Baseline:\n",
    "\n",
    "gpt-5-nano (minimal)\n",
    "```\n",
    "per 1K samples Avg $1.024 Max $2.723\n",
    "NEWSPAPER_2022_1 103464 samples Avg $105.896 Max $281.707\n",
    "```\n",
    "\n",
    "gpt-5-mini (minimal)\n",
    "```\n",
    "gpt-5-mini per 1K samples Avg $5.118 Max $13.614\n",
    "NEWSPAPER_2022_1 103464 samples gpt-5-mini Avg $529.479 Max $1408.533\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2d741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Input Tokens 2756.156 Output Tokens 1714.812\n",
      "Max Input Tokens 3604.000 Output Tokens 3396.000\n"
     ]
    }
   ],
   "source": [
    "input_tokens = []\n",
    "output_tokens = []\n",
    "\n",
    "for response in responses:\n",
    "    usage = response.usage\n",
    "    input_tokens.append(usage.input_tokens)\n",
    "    output_tokens.append(usage.output_tokens)\n",
    "\n",
    "avg_input_tokens = sum(input_tokens)/32\n",
    "avg_output_tokens = sum(output_tokens)/32\n",
    "\n",
    "print(f\"Avg Input Tokens {avg_input_tokens:.3f} Output Tokens {avg_output_tokens:.3f}\")\n",
    "print(f\"Max Input Tokens {max(input_tokens):.3f} Output Tokens {max(output_tokens):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da63b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricings = {\n",
    "    \"gpt-5-mini\": {\n",
    "        \"input\": 0.25,\n",
    "        \"output\": 2.0\n",
    "    },\n",
    "    \"gpt-5-nano\": {\n",
    "        \"input\": 0.05,\n",
    "        \"output\": 0.4\n",
    "    }\n",
    "}\n",
    "# 1M: 1_000_000\n",
    "\n",
    "def calculate_price(model, input_tokens, output_tokens, n):\n",
    "    input_price = n*(input_tokens/1_000_000)*pricings[model][\"input\"]\n",
    "    output_price = n*(output_tokens/1_000_000)*pricings[model][\"output\"]\n",
    "    return input_price+output_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75222095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-mini-minimal per 1K samples Avg $4.119 Max $7.693\n"
     ]
    }
   ],
   "source": [
    "pricing_n=1000\n",
    "pricing_model = \"gpt-5-nano\"\n",
    "pricing_model = \"gpt-5-mini\"\n",
    "\n",
    "avg_price = calculate_price(pricing_model, avg_input_tokens, avg_output_tokens, n=pricing_n)\n",
    "max_price = calculate_price(pricing_model, max(input_tokens), max(output_tokens), n=pricing_n)\n",
    "\n",
    "print(f\"{pricing_model}-{OPENAI_REASOINING_EFFORT} per 1K samples Avg ${avg_price:.3f} Max ${max_price:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726c77df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWSPAPER_2022_1 103464 samples gpt-5-mini-minimal Avg $426.133 Max $795.949\n"
     ]
    }
   ],
   "source": [
    "df_avg_price = (df.shape[0]/1000)*avg_price\n",
    "df_max_price = (df.shape[0]/1000)*max_price\n",
    "\n",
    "print(f\"{fname} {df.shape[0]} samples {pricing_model}-{OPENAI_REASOINING_EFFORT} Avg ${df_avg_price:.3f} Max ${df_max_price:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7f7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if not os.path.exists(f\"sample/{PROMPT_NAME}-{OPENAI_MODEL}-{OPENAI_REASOINING_EFFORT}\"):\n",
    "    os.makedirs(f\"sample/{PROMPT_NAME}-{OPENAI_MODEL}-{OPENAI_REASOINING_EFFORT}\")\n",
    "for i in range(sample.shape[0]):\n",
    "    row = sample.iloc[i]\n",
    "    doc_id = row['doc_id']\n",
    "    with open(f\"sample/{PROMPT_NAME}-{OPENAI_MODEL}-{OPENAI_REASOINING_EFFORT}/{doc_id}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(responses[i].model_dump(), ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c4feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
