{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ffd672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5.1 none\n",
      "Prompt: try2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "\n",
    "from schema import NerResult\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_REASOINING_EFFORT = os.getenv(\"OPENAI_REASOINING_EFFORT\")\n",
    "print(OPENAI_MODEL, OPENAI_REASOINING_EFFORT)\n",
    "\n",
    "PROMPT_NAME = os.getenv(\"PROMPT_NAME\")\n",
    "print(\"Prompt:\", PROMPT_NAME)\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=OPENAI_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "if OPENAI_API_KEY is None or OPENAI_BASE_URL is None:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY or OPENAI_BASE_URL environment variable is not set\")\n",
    "\n",
    "# 예시: openai 설정\n",
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.api_base = OPENAI_BASE_URL\n",
    "\n",
    "# ——————————————\n",
    "# 2. YAML 템플릿 읽기 함수\n",
    "def load_prompt_template(yaml_path: str) -> dict:\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tpl = yaml.safe_load(f)\n",
    "    return tpl\n",
    "\n",
    "# ——————————————\n",
    "# 3. OpenAI 비동기 호출 함수\n",
    "async def call_openai_for_ner(instruction: str, prompt: str) -> NerResult:\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"주어진 텍스트에서 명명된 객체 인식(NER)을 수행합니다.\"},\n",
    "        {\"role\": \"developer\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    # 비동기 호출 (예시로 openai.ChatCompletion.acreate 사용)\n",
    "    response = await client.responses.parse(\n",
    "        model=OPENAI_MODEL,\n",
    "        input=messages,\n",
    "        text_format=NerResult,\n",
    "        reasoning={\"effort\": OPENAI_REASOINING_EFFORT}\n",
    "    )\n",
    "    print(response.usage)\n",
    "    ner_result = response.output_parsed\n",
    "    return ner_result\n",
    "\n",
    "# —\n",
    "# 4. 여러 텍스트에 대해 처리하고 DataFrame 변환\n",
    "async def process_texts(texts: List[str], yaml_template_path: str) -> pd.DataFrame:\n",
    "    tpl = load_prompt_template(yaml_template_path)\n",
    "    records = []\n",
    "    instruction = tpl['prompt']['developer']\n",
    "    \n",
    "    tasks = []\n",
    "    for txt in texts:\n",
    "        # YAML 템플릿의 prompt 부분에 텍스트 삽입\n",
    "        prompt = tpl[\"prompt\"][\"user1\"].replace(\"{TEXT}\", txt)\n",
    "        task = call_openai_for_ner(instruction, prompt)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    results = await tqdm.gather(*tasks)\n",
    "    for ner_res in results:\n",
    "        for ent in ner_res.entities:\n",
    "            records.append({\n",
    "                \"tagged_text\": ner_res.tagged_text,\n",
    "                \"entity_value\": ent.value,\n",
    "                \"entity_label\": ent.label.value,\n",
    "                # \"entity_sentence\": ent.sentence\n",
    "            })\n",
    "        df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ad5503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103464, 11) Index(['file_id', 'doc_id', 'title', 'author', 'publisher', 'date', 'topic',\n",
      "       'original_topic', 'sentence_ids', 'sentence_offsets', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"NIKL_NEWSPAPER_2023_CSV\"\n",
    "fname = \"NEWSPAPER_2022_1\"\n",
    "\n",
    "df = pd.read_parquet(f\"source/{dataset_name}/{fname}.parquet\")\n",
    "print(df.shape, df.columns)\n",
    "\n",
    "prompt_path = f\"prompt/{PROMPT_NAME}.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8096670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "사회       33513\n",
       "경제       16340\n",
       "정치       15751\n",
       "생활       15104\n",
       "스포츠       7564\n",
       "IT/과학     5248\n",
       "문화        4048\n",
       "미용/건강     3819\n",
       "연예        2077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a57d86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "sample = df.sample(n)\n",
    "texts = sample.text.values.tolist()\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466c550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:38,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=2537, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=639, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:20<00:30, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=2760, input_tokens_details=InputTokensDetails(cached_tokens=2048), output_tokens=1196, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:20<00:11,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=2782, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=1535, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=4317)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:22<00:04,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=2642, input_tokens_details=InputTokensDetails(cached_tokens=2048), output_tokens=1424, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=4066)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=2832, input_tokens_details=InputTokensDetails(cached_tokens=2048), output_tokens=1602, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=4434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = await process_texts(texts, prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79645f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try2-gpt-5.1-none\n"
     ]
    }
   ],
   "source": [
    "print(f\"{PROMPT_NAME}-{OPENAI_MODEL}-{OPENAI_REASOINING_EFFORT}\")\n",
    "result.to_csv(f\"results/sample/{PROMPT_NAME}-{OPENAI_MODEL}-{OPENAI_REASOINING_EFFORT}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4010a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
